{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74e4101d",
   "metadata": {},
   "source": [
    "# Setup enviorment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8fa46cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data reading in Dataframe format and data preprocessing\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Linear algebra operations\n",
    "import numpy as np\n",
    "\n",
    "# Machine learning models and preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Sequential, layers, callbacks\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional\n",
    "\n",
    "# Epiweek\n",
    "from epiweeks import Week, Year\n",
    "\n",
    "# Date\n",
    "from datetime import date as convert_to_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab13cb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71c05944",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = 'Embeddings/embeddings_vae_1024features.csv'\n",
    "labels = 'Tabular_data/Label_CSV_All_Municipality.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8cc222",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c83bc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epiweek_from_date(image_date):\n",
    "    date = image_date.split('-')\n",
    "    \n",
    "    # Get year as int\n",
    "    year = ''.join(filter(str.isdigit, date[0]))\n",
    "    year = int(year)\n",
    "    \n",
    "    # Get month as int\n",
    "    month = ''.join(filter(str.isdigit, date[1]))\n",
    "    month = int(month)\n",
    "    \n",
    "    # Get day as int\n",
    "    day = ''.join(filter(str.isdigit, date[2]))\n",
    "    day = int(day)\n",
    "    \n",
    "    # Get epiweek:\n",
    "    date = convert_to_date(year, month, day)\n",
    "    epiweek = str(Week.fromdate(date))\n",
    "    epiweek = int(epiweek)\n",
    "    \n",
    "    return epiweek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed9b112",
   "metadata": {},
   "source": [
    "### 1. Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7361a46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_features(path, Municipality = None):\n",
    "    df = pd.read_csv(path)\n",
    "    #df.Date = pd.to_datetime(df.Date)\n",
    "    \n",
    "    if Municipality:\n",
    "        print('Obtaining dataframe for the city of Medellin only...')\n",
    "        df = df[df['Municipality Code'] == Municipality]\n",
    "        \n",
    "    df.Date = df.Date.apply(epiweek_from_date)\n",
    "    \n",
    "    df = df.sort_values(by=['Date'])\n",
    "    \n",
    "    df = df.set_index('Date')\n",
    "    \n",
    "    if Municipality:\n",
    "        df.drop(columns=['Municipality Code'], inplace=True)\n",
    "        \n",
    "    df.index.name = None\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95ef35e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining dataframe for the city of Medellin only...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1014</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201544</th>\n",
       "      <td>-0.046489</td>\n",
       "      <td>-1.407201</td>\n",
       "      <td>-1.148883</td>\n",
       "      <td>0.836687</td>\n",
       "      <td>-0.190778</td>\n",
       "      <td>1.802231</td>\n",
       "      <td>0.517497</td>\n",
       "      <td>-1.146697</td>\n",
       "      <td>0.119171</td>\n",
       "      <td>1.544828</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.678144</td>\n",
       "      <td>-0.036498</td>\n",
       "      <td>-0.303533</td>\n",
       "      <td>0.248490</td>\n",
       "      <td>-0.811357</td>\n",
       "      <td>-0.832925</td>\n",
       "      <td>-0.739305</td>\n",
       "      <td>-0.295200</td>\n",
       "      <td>-0.038603</td>\n",
       "      <td>0.485674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201545</th>\n",
       "      <td>0.327904</td>\n",
       "      <td>-0.701594</td>\n",
       "      <td>0.306197</td>\n",
       "      <td>-0.796750</td>\n",
       "      <td>-1.037395</td>\n",
       "      <td>0.857556</td>\n",
       "      <td>0.167456</td>\n",
       "      <td>1.642044</td>\n",
       "      <td>-0.473234</td>\n",
       "      <td>0.181270</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.897844</td>\n",
       "      <td>-0.661285</td>\n",
       "      <td>-1.146673</td>\n",
       "      <td>-1.234707</td>\n",
       "      <td>-0.184185</td>\n",
       "      <td>-0.140669</td>\n",
       "      <td>-2.367193</td>\n",
       "      <td>-0.463623</td>\n",
       "      <td>-0.668936</td>\n",
       "      <td>-0.233073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201546</th>\n",
       "      <td>-1.634988</td>\n",
       "      <td>-0.882196</td>\n",
       "      <td>0.291420</td>\n",
       "      <td>-2.686286</td>\n",
       "      <td>-0.684004</td>\n",
       "      <td>-0.407912</td>\n",
       "      <td>1.827255</td>\n",
       "      <td>0.327352</td>\n",
       "      <td>0.987357</td>\n",
       "      <td>0.781570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.906685</td>\n",
       "      <td>1.372330</td>\n",
       "      <td>-0.333867</td>\n",
       "      <td>0.728862</td>\n",
       "      <td>-0.005498</td>\n",
       "      <td>-0.743434</td>\n",
       "      <td>0.597319</td>\n",
       "      <td>0.195301</td>\n",
       "      <td>-0.850010</td>\n",
       "      <td>0.492581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201547</th>\n",
       "      <td>1.789035</td>\n",
       "      <td>0.854698</td>\n",
       "      <td>-2.904163</td>\n",
       "      <td>-1.008464</td>\n",
       "      <td>-0.165688</td>\n",
       "      <td>0.597984</td>\n",
       "      <td>0.142369</td>\n",
       "      <td>0.164123</td>\n",
       "      <td>1.069377</td>\n",
       "      <td>0.236612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254610</td>\n",
       "      <td>-0.536157</td>\n",
       "      <td>-0.424962</td>\n",
       "      <td>0.685125</td>\n",
       "      <td>-0.029501</td>\n",
       "      <td>0.095485</td>\n",
       "      <td>0.379560</td>\n",
       "      <td>-0.297148</td>\n",
       "      <td>-1.211405</td>\n",
       "      <td>0.443391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201548</th>\n",
       "      <td>-0.983180</td>\n",
       "      <td>0.145126</td>\n",
       "      <td>0.720849</td>\n",
       "      <td>1.524544</td>\n",
       "      <td>0.620878</td>\n",
       "      <td>-1.807810</td>\n",
       "      <td>0.340521</td>\n",
       "      <td>0.781281</td>\n",
       "      <td>-0.395229</td>\n",
       "      <td>-0.769379</td>\n",
       "      <td>...</td>\n",
       "      <td>1.562922</td>\n",
       "      <td>0.585608</td>\n",
       "      <td>-0.675990</td>\n",
       "      <td>0.232964</td>\n",
       "      <td>0.788353</td>\n",
       "      <td>0.147064</td>\n",
       "      <td>0.094748</td>\n",
       "      <td>-0.206415</td>\n",
       "      <td>1.170020</td>\n",
       "      <td>0.276934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201848</th>\n",
       "      <td>-0.177821</td>\n",
       "      <td>0.800357</td>\n",
       "      <td>0.158949</td>\n",
       "      <td>2.573438</td>\n",
       "      <td>1.615337</td>\n",
       "      <td>-0.998008</td>\n",
       "      <td>1.096824</td>\n",
       "      <td>-0.023870</td>\n",
       "      <td>-0.667530</td>\n",
       "      <td>-1.929526</td>\n",
       "      <td>...</td>\n",
       "      <td>2.209477</td>\n",
       "      <td>0.241274</td>\n",
       "      <td>-1.311355</td>\n",
       "      <td>0.955204</td>\n",
       "      <td>0.006918</td>\n",
       "      <td>0.715542</td>\n",
       "      <td>-0.870650</td>\n",
       "      <td>-0.205803</td>\n",
       "      <td>0.835786</td>\n",
       "      <td>1.692061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201849</th>\n",
       "      <td>-0.306444</td>\n",
       "      <td>1.308680</td>\n",
       "      <td>1.067536</td>\n",
       "      <td>-0.931025</td>\n",
       "      <td>-1.046062</td>\n",
       "      <td>2.075529</td>\n",
       "      <td>-0.501223</td>\n",
       "      <td>-2.267342</td>\n",
       "      <td>0.095569</td>\n",
       "      <td>-0.845871</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.447275</td>\n",
       "      <td>0.293684</td>\n",
       "      <td>-1.791375</td>\n",
       "      <td>-0.086890</td>\n",
       "      <td>0.917567</td>\n",
       "      <td>0.631528</td>\n",
       "      <td>-2.004170</td>\n",
       "      <td>0.267849</td>\n",
       "      <td>1.151415</td>\n",
       "      <td>-1.051147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201850</th>\n",
       "      <td>-0.151392</td>\n",
       "      <td>0.071449</td>\n",
       "      <td>0.356428</td>\n",
       "      <td>0.259774</td>\n",
       "      <td>-0.383608</td>\n",
       "      <td>1.065443</td>\n",
       "      <td>0.450759</td>\n",
       "      <td>0.322183</td>\n",
       "      <td>-1.307717</td>\n",
       "      <td>-0.181305</td>\n",
       "      <td>...</td>\n",
       "      <td>1.033319</td>\n",
       "      <td>0.951084</td>\n",
       "      <td>0.638319</td>\n",
       "      <td>-0.277678</td>\n",
       "      <td>0.032450</td>\n",
       "      <td>-0.329121</td>\n",
       "      <td>-0.322632</td>\n",
       "      <td>-1.898407</td>\n",
       "      <td>-0.602611</td>\n",
       "      <td>-0.267056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201851</th>\n",
       "      <td>-0.793142</td>\n",
       "      <td>-0.539722</td>\n",
       "      <td>-1.165816</td>\n",
       "      <td>-0.199017</td>\n",
       "      <td>2.244849</td>\n",
       "      <td>0.917043</td>\n",
       "      <td>-0.467799</td>\n",
       "      <td>0.353362</td>\n",
       "      <td>1.053764</td>\n",
       "      <td>0.443968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.882802</td>\n",
       "      <td>-0.827243</td>\n",
       "      <td>-0.127070</td>\n",
       "      <td>-1.308614</td>\n",
       "      <td>-1.632518</td>\n",
       "      <td>1.059085</td>\n",
       "      <td>1.047949</td>\n",
       "      <td>-2.762428</td>\n",
       "      <td>-0.955669</td>\n",
       "      <td>0.913588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201852</th>\n",
       "      <td>-0.393870</td>\n",
       "      <td>1.455486</td>\n",
       "      <td>-0.128889</td>\n",
       "      <td>-0.788440</td>\n",
       "      <td>0.381879</td>\n",
       "      <td>0.022924</td>\n",
       "      <td>0.543938</td>\n",
       "      <td>-0.070586</td>\n",
       "      <td>-0.623824</td>\n",
       "      <td>-0.382842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.705277</td>\n",
       "      <td>0.204254</td>\n",
       "      <td>-0.124967</td>\n",
       "      <td>0.008888</td>\n",
       "      <td>0.031512</td>\n",
       "      <td>2.580178</td>\n",
       "      <td>-0.813275</td>\n",
       "      <td>-0.418657</td>\n",
       "      <td>-0.572518</td>\n",
       "      <td>-0.936024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165 rows × 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "201544 -0.046489 -1.407201 -1.148883  0.836687 -0.190778  1.802231  0.517497   \n",
       "201545  0.327904 -0.701594  0.306197 -0.796750 -1.037395  0.857556  0.167456   \n",
       "201546 -1.634988 -0.882196  0.291420 -2.686286 -0.684004 -0.407912  1.827255   \n",
       "201547  1.789035  0.854698 -2.904163 -1.008464 -0.165688  0.597984  0.142369   \n",
       "201548 -0.983180  0.145126  0.720849  1.524544  0.620878 -1.807810  0.340521   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "201848 -0.177821  0.800357  0.158949  2.573438  1.615337 -0.998008  1.096824   \n",
       "201849 -0.306444  1.308680  1.067536 -0.931025 -1.046062  2.075529 -0.501223   \n",
       "201850 -0.151392  0.071449  0.356428  0.259774 -0.383608  1.065443  0.450759   \n",
       "201851 -0.793142 -0.539722 -1.165816 -0.199017  2.244849  0.917043 -0.467799   \n",
       "201852 -0.393870  1.455486 -0.128889 -0.788440  0.381879  0.022924  0.543938   \n",
       "\n",
       "               7         8         9  ...      1014      1015      1016  \\\n",
       "201544 -1.146697  0.119171  1.544828  ... -0.678144 -0.036498 -0.303533   \n",
       "201545  1.642044 -0.473234  0.181270  ... -0.897844 -0.661285 -1.146673   \n",
       "201546  0.327352  0.987357  0.781570  ...  0.906685  1.372330 -0.333867   \n",
       "201547  0.164123  1.069377  0.236612  ...  0.254610 -0.536157 -0.424962   \n",
       "201548  0.781281 -0.395229 -0.769379  ...  1.562922  0.585608 -0.675990   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "201848 -0.023870 -0.667530 -1.929526  ...  2.209477  0.241274 -1.311355   \n",
       "201849 -2.267342  0.095569 -0.845871  ... -2.447275  0.293684 -1.791375   \n",
       "201850  0.322183 -1.307717 -0.181305  ...  1.033319  0.951084  0.638319   \n",
       "201851  0.353362  1.053764  0.443968  ...  0.882802 -0.827243 -0.127070   \n",
       "201852 -0.070586 -0.623824 -0.382842  ...  0.705277  0.204254 -0.124967   \n",
       "\n",
       "            1017      1018      1019      1020      1021      1022      1023  \n",
       "201544  0.248490 -0.811357 -0.832925 -0.739305 -0.295200 -0.038603  0.485674  \n",
       "201545 -1.234707 -0.184185 -0.140669 -2.367193 -0.463623 -0.668936 -0.233073  \n",
       "201546  0.728862 -0.005498 -0.743434  0.597319  0.195301 -0.850010  0.492581  \n",
       "201547  0.685125 -0.029501  0.095485  0.379560 -0.297148 -1.211405  0.443391  \n",
       "201548  0.232964  0.788353  0.147064  0.094748 -0.206415  1.170020  0.276934  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "201848  0.955204  0.006918  0.715542 -0.870650 -0.205803  0.835786  1.692061  \n",
       "201849 -0.086890  0.917567  0.631528 -2.004170  0.267849  1.151415 -1.051147  \n",
       "201850 -0.277678  0.032450 -0.329121 -0.322632 -1.898407 -0.602611 -0.267056  \n",
       "201851 -1.308614 -1.632518  1.059085  1.047949 -2.762428 -0.955669  0.913588  \n",
       "201852  0.008888  0.031512  2.580178 -0.813275 -0.418657 -0.572518 -0.936024  \n",
       "\n",
       "[165 rows x 1024 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df = read_features(path=embeddings, Municipality='Medellín')\n",
    "features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00b113a",
   "metadata": {},
   "source": [
    "### 2. Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77cde5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epiweek(name):\n",
    "    \n",
    "    # Get week\n",
    "    week = name.split('/')[1]\n",
    "    week = week.replace('w','')\n",
    "    week = int(week)\n",
    "    \n",
    "    # Year\n",
    "    year = name.split('/')[0]\n",
    "    year = int(year)\n",
    "    \n",
    "    epiweek = Week(year, week)\n",
    "    \n",
    "    epiweek = str(epiweek)\n",
    "    epiweek = int(epiweek)\n",
    "\n",
    "    return epiweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ac8c380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_labels(path, Municipality = None):\n",
    "    df = pd.read_csv(path)\n",
    "    if df.shape[1] > 678:\n",
    "        df = pd.concat([df[['Municipality code', 'Municipality']], df.iloc[:,-676:]], axis=1)\n",
    "        cols = df.iloc[:, 2:].columns\n",
    "        new_cols = df.iloc[:, 2:].columns.to_series().apply(get_epiweek)\n",
    "        df = df.rename(columns=dict(zip(cols, new_cols))) \n",
    "        \n",
    "    if 'Label_CSV_All_Municipality' in path:\n",
    "        # Get Columns\n",
    "        df = df[['epiweek', 'Municipality code', 'Municipality', 'final_cases_label']]\n",
    "        \n",
    "        # change epiweek format\n",
    "        df.epiweek = df.epiweek.apply(get_epiweek)\n",
    "        \n",
    "        # Remove duplicates\n",
    "        df = df[df.duplicated(['epiweek','Municipality code','Municipality']) == False]\n",
    "        \n",
    "        # Replace Increase, decrease, stable to numerical:\n",
    "        \"\"\"\n",
    "        - Stable = 0\n",
    "        - Increased = 1 \n",
    "        - Decreased = 2\n",
    "        \"\"\"\n",
    "        df.final_cases_label = df.final_cases_label.replace({'Stable': 0, 'Increased': 1, 'Decreased': 2})\n",
    "        \n",
    "        # Create table\n",
    "        df = df.pivot(index=['Municipality code', 'Municipality'], columns='epiweek', values='final_cases_label')\n",
    "\n",
    "        # Reset Index:\n",
    "        df = df.reset_index()\n",
    "    \n",
    "    if Municipality:\n",
    "        df = df[df['Municipality'] == Municipality]\n",
    "        df.drop(columns=['Municipality code'], inplace=True)\n",
    "        df.rename(columns={'Municipality': 'Municipality Code'}, inplace=True)\n",
    "    \n",
    "        df = df.set_index('Municipality Code')\n",
    "        df = df.T\n",
    "\n",
    "        df.columns.name = None\n",
    "        df.index.name = None\n",
    "        \n",
    "        df.columns = ['Labels']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44935eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201601</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201602</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201603</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201604</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201605</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201848</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201849</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201850</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201851</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201852</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0  1  2\n",
       "201601  1  0  0\n",
       "201602  0  1  0\n",
       "201603  0  0  1\n",
       "201604  1  0  0\n",
       "201605  1  0  0\n",
       "...    .. .. ..\n",
       "201848  1  0  0\n",
       "201849  0  0  1\n",
       "201850  0  1  0\n",
       "201851  1  0  0\n",
       "201852  1  0  0\n",
       "\n",
       "[156 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df = read_labels(path=labels, Municipality='Medellín')\n",
    "labels_df_orig = labels_df\n",
    "labels_df = pd.get_dummies(labels_df['Labels'])\n",
    "labels_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b5e7cd",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d60d82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labels = labels_df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1801f382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201601</th>\n",
       "      <td>1.287487</td>\n",
       "      <td>-0.688955</td>\n",
       "      <td>-0.794426</td>\n",
       "      <td>-1.238838</td>\n",
       "      <td>1.239369</td>\n",
       "      <td>1.784700</td>\n",
       "      <td>-0.000341</td>\n",
       "      <td>0.525795</td>\n",
       "      <td>0.363034</td>\n",
       "      <td>0.825218</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.439056</td>\n",
       "      <td>0.675143</td>\n",
       "      <td>-1.017167</td>\n",
       "      <td>-0.206480</td>\n",
       "      <td>-0.043412</td>\n",
       "      <td>-1.014832</td>\n",
       "      <td>-1.435265</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201602</th>\n",
       "      <td>-1.399851</td>\n",
       "      <td>-0.211775</td>\n",
       "      <td>1.341302</td>\n",
       "      <td>0.132593</td>\n",
       "      <td>-0.097550</td>\n",
       "      <td>0.159015</td>\n",
       "      <td>-1.474547</td>\n",
       "      <td>-1.294940</td>\n",
       "      <td>1.222341</td>\n",
       "      <td>-0.381582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.420181</td>\n",
       "      <td>-1.341189</td>\n",
       "      <td>-0.138499</td>\n",
       "      <td>-1.804684</td>\n",
       "      <td>-0.662659</td>\n",
       "      <td>0.475712</td>\n",
       "      <td>0.201907</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201603</th>\n",
       "      <td>-0.405975</td>\n",
       "      <td>0.289439</td>\n",
       "      <td>-0.377020</td>\n",
       "      <td>-0.355364</td>\n",
       "      <td>-1.054876</td>\n",
       "      <td>0.712196</td>\n",
       "      <td>0.927682</td>\n",
       "      <td>-0.470455</td>\n",
       "      <td>-0.252064</td>\n",
       "      <td>1.062808</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.587504</td>\n",
       "      <td>0.340662</td>\n",
       "      <td>0.299123</td>\n",
       "      <td>0.405674</td>\n",
       "      <td>-2.638784</td>\n",
       "      <td>0.780803</td>\n",
       "      <td>-1.659373</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201604</th>\n",
       "      <td>0.844463</td>\n",
       "      <td>-1.315463</td>\n",
       "      <td>2.082394</td>\n",
       "      <td>2.693551</td>\n",
       "      <td>-1.234441</td>\n",
       "      <td>1.570999</td>\n",
       "      <td>0.279815</td>\n",
       "      <td>0.831815</td>\n",
       "      <td>-0.229177</td>\n",
       "      <td>-0.052932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.959280</td>\n",
       "      <td>-0.753616</td>\n",
       "      <td>1.713913</td>\n",
       "      <td>1.536158</td>\n",
       "      <td>-1.955070</td>\n",
       "      <td>0.051035</td>\n",
       "      <td>-1.663397</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201605</th>\n",
       "      <td>-0.541275</td>\n",
       "      <td>0.475828</td>\n",
       "      <td>0.136089</td>\n",
       "      <td>0.335247</td>\n",
       "      <td>1.387429</td>\n",
       "      <td>0.863202</td>\n",
       "      <td>-1.643587</td>\n",
       "      <td>-0.673929</td>\n",
       "      <td>-0.331307</td>\n",
       "      <td>-1.289601</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.362812</td>\n",
       "      <td>-0.104197</td>\n",
       "      <td>-0.509349</td>\n",
       "      <td>0.104454</td>\n",
       "      <td>-3.172053</td>\n",
       "      <td>0.055130</td>\n",
       "      <td>0.444714</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201848</th>\n",
       "      <td>-0.177821</td>\n",
       "      <td>0.800357</td>\n",
       "      <td>0.158949</td>\n",
       "      <td>2.573438</td>\n",
       "      <td>1.615337</td>\n",
       "      <td>-0.998008</td>\n",
       "      <td>1.096824</td>\n",
       "      <td>-0.023870</td>\n",
       "      <td>-0.667530</td>\n",
       "      <td>-1.929526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.955204</td>\n",
       "      <td>0.006918</td>\n",
       "      <td>0.715542</td>\n",
       "      <td>-0.870650</td>\n",
       "      <td>-0.205803</td>\n",
       "      <td>0.835786</td>\n",
       "      <td>1.692061</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201849</th>\n",
       "      <td>-0.306444</td>\n",
       "      <td>1.308680</td>\n",
       "      <td>1.067536</td>\n",
       "      <td>-0.931025</td>\n",
       "      <td>-1.046062</td>\n",
       "      <td>2.075529</td>\n",
       "      <td>-0.501223</td>\n",
       "      <td>-2.267342</td>\n",
       "      <td>0.095569</td>\n",
       "      <td>-0.845871</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086890</td>\n",
       "      <td>0.917567</td>\n",
       "      <td>0.631528</td>\n",
       "      <td>-2.004170</td>\n",
       "      <td>0.267849</td>\n",
       "      <td>1.151415</td>\n",
       "      <td>-1.051147</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201850</th>\n",
       "      <td>-0.151392</td>\n",
       "      <td>0.071449</td>\n",
       "      <td>0.356428</td>\n",
       "      <td>0.259774</td>\n",
       "      <td>-0.383608</td>\n",
       "      <td>1.065443</td>\n",
       "      <td>0.450759</td>\n",
       "      <td>0.322183</td>\n",
       "      <td>-1.307717</td>\n",
       "      <td>-0.181305</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.277678</td>\n",
       "      <td>0.032450</td>\n",
       "      <td>-0.329121</td>\n",
       "      <td>-0.322632</td>\n",
       "      <td>-1.898407</td>\n",
       "      <td>-0.602611</td>\n",
       "      <td>-0.267056</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201851</th>\n",
       "      <td>-0.793142</td>\n",
       "      <td>-0.539722</td>\n",
       "      <td>-1.165816</td>\n",
       "      <td>-0.199017</td>\n",
       "      <td>2.244849</td>\n",
       "      <td>0.917043</td>\n",
       "      <td>-0.467799</td>\n",
       "      <td>0.353362</td>\n",
       "      <td>1.053764</td>\n",
       "      <td>0.443968</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.308614</td>\n",
       "      <td>-1.632518</td>\n",
       "      <td>1.059085</td>\n",
       "      <td>1.047949</td>\n",
       "      <td>-2.762428</td>\n",
       "      <td>-0.955669</td>\n",
       "      <td>0.913588</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201852</th>\n",
       "      <td>-0.393870</td>\n",
       "      <td>1.455486</td>\n",
       "      <td>-0.128889</td>\n",
       "      <td>-0.788440</td>\n",
       "      <td>0.381879</td>\n",
       "      <td>0.022924</td>\n",
       "      <td>0.543938</td>\n",
       "      <td>-0.070586</td>\n",
       "      <td>-0.623824</td>\n",
       "      <td>-0.382842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008888</td>\n",
       "      <td>0.031512</td>\n",
       "      <td>2.580178</td>\n",
       "      <td>-0.813275</td>\n",
       "      <td>-0.418657</td>\n",
       "      <td>-0.572518</td>\n",
       "      <td>-0.936024</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 1027 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "201601  1.287487 -0.688955 -0.794426 -1.238838  1.239369  1.784700 -0.000341   \n",
       "201602 -1.399851 -0.211775  1.341302  0.132593 -0.097550  0.159015 -1.474547   \n",
       "201603 -0.405975  0.289439 -0.377020 -0.355364 -1.054876  0.712196  0.927682   \n",
       "201604  0.844463 -1.315463  2.082394  2.693551 -1.234441  1.570999  0.279815   \n",
       "201605 -0.541275  0.475828  0.136089  0.335247  1.387429  0.863202 -1.643587   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "201848 -0.177821  0.800357  0.158949  2.573438  1.615337 -0.998008  1.096824   \n",
       "201849 -0.306444  1.308680  1.067536 -0.931025 -1.046062  2.075529 -0.501223   \n",
       "201850 -0.151392  0.071449  0.356428  0.259774 -0.383608  1.065443  0.450759   \n",
       "201851 -0.793142 -0.539722 -1.165816 -0.199017  2.244849  0.917043 -0.467799   \n",
       "201852 -0.393870  1.455486 -0.128889 -0.788440  0.381879  0.022924  0.543938   \n",
       "\n",
       "               7         8         9  ...      1017      1018      1019  \\\n",
       "201601  0.525795  0.363034  0.825218  ... -0.439056  0.675143 -1.017167   \n",
       "201602 -1.294940  1.222341 -0.381582  ... -0.420181 -1.341189 -0.138499   \n",
       "201603 -0.470455 -0.252064  1.062808  ... -0.587504  0.340662  0.299123   \n",
       "201604  0.831815 -0.229177 -0.052932  ...  0.959280 -0.753616  1.713913   \n",
       "201605 -0.673929 -0.331307 -1.289601  ... -0.362812 -0.104197 -0.509349   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "201848 -0.023870 -0.667530 -1.929526  ...  0.955204  0.006918  0.715542   \n",
       "201849 -2.267342  0.095569 -0.845871  ... -0.086890  0.917567  0.631528   \n",
       "201850  0.322183 -1.307717 -0.181305  ... -0.277678  0.032450 -0.329121   \n",
       "201851  0.353362  1.053764  0.443968  ... -1.308614 -1.632518  1.059085   \n",
       "201852 -0.070586 -0.623824 -0.382842  ...  0.008888  0.031512  2.580178   \n",
       "\n",
       "            1020      1021      1022      1023  0  1  2  \n",
       "201601 -0.206480 -0.043412 -1.014832 -1.435265  1  0  0  \n",
       "201602 -1.804684 -0.662659  0.475712  0.201907  0  1  0  \n",
       "201603  0.405674 -2.638784  0.780803 -1.659373  0  0  1  \n",
       "201604  1.536158 -1.955070  0.051035 -1.663397  1  0  0  \n",
       "201605  0.104454 -3.172053  0.055130  0.444714  1  0  0  \n",
       "...          ...       ...       ...       ... .. .. ..  \n",
       "201848 -0.870650 -0.205803  0.835786  1.692061  1  0  0  \n",
       "201849 -2.004170  0.267849  1.151415 -1.051147  0  0  1  \n",
       "201850 -0.322632 -1.898407 -0.602611 -0.267056  0  1  0  \n",
       "201851  1.047949 -2.762428 -0.955669  0.913588  1  0  0  \n",
       "201852 -0.813275 -0.418657 -0.572518 -0.936024  1  0  0  \n",
       "\n",
       "[156 rows x 1027 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the two dataframes based on the date values\n",
    "dengue_df = features_df.merge(labels_df, how='inner', left_index=True, right_index=True)\n",
    "dengue_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54266e6",
   "metadata": {},
   "source": [
    "### Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "435e9a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, train_percentage = 80):\n",
    "    # We need a sequence so we can't split randomly\n",
    "    # To divide into Train and test we have to calculate the train percentage of the dataset:\n",
    "    size = df.shape[0]\n",
    "    split = int(size*(train_percentage/100))\n",
    "    \n",
    "    \"\"\" Train \"\"\"\n",
    "    # We will train with 1st percentage % of data and test with the rest\n",
    "    train_df = df.iloc[:split,:] ## percentage % train\n",
    "    \n",
    "    \"\"\" Test \"\"\"\n",
    "    test_df = df.iloc[split:,:] # 100 - percentage % test\n",
    "    \n",
    "    print(f'The train shape is: {train_df.shape}')\n",
    "    print(f'The test shape is: {test_df.shape}')\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c573d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train shape is: (124, 1027)\n",
      "The test shape is: (32, 1027)\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(dengue_df, train_percentage = 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8624ed8a",
   "metadata": {},
   "source": [
    "### Normalize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7760de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize train data and create the scaler\n",
    "def normalize_train_features(df, feature_range=(-1, 1), n_labels=None):\n",
    "    \n",
    "    if n_labels:\n",
    "        n_features = df.shape[1] - n_labels\n",
    "    \n",
    "    scalers = {}\n",
    "    # For each column in the dataframe\n",
    "    for i, column in enumerate(df.columns):\n",
    "        if n_labels:\n",
    "            if i >= n_features:\n",
    "                break\n",
    "        # Get values of the column\n",
    "        values = df[column].values.reshape(-1,1)\n",
    "        # Generate a new scaler\n",
    "        scaler = MinMaxScaler(feature_range=feature_range)\n",
    "        # Fit the scaler just for that column\n",
    "        scaled_column = scaler.fit_transform(values)\n",
    "        # Add the scaled column to the dataframe\n",
    "        scaled_column = np.reshape(scaled_column, len(scaled_column))\n",
    "        df[column] = scaled_column\n",
    "        \n",
    "        # Save the scaler of the column\n",
    "        scalers['scaler_' + column] = scaler\n",
    "        \n",
    "    print(f' Min values are: ')\n",
    "    print(df.min())\n",
    "    print(f' Max values are: ')\n",
    "    print(df.max())\n",
    "        \n",
    "    return df, scalers\n",
    "\n",
    "\n",
    "\"\"\" If you want to use the same scaler used in train, you can use this function\"\"\"\n",
    "def normalize_test_features(df, scalers=None, n_labels=None):\n",
    "    \n",
    "    if not scalers:\n",
    "        raise TypeError(\"You should provide a list of scalers.\")\n",
    "    \n",
    "    if n_labels:\n",
    "        n_features = df.shape[1] - n_labels\n",
    "    \n",
    "    for i, column in enumerate(df.columns):\n",
    "        if n_labels:\n",
    "            if i >= n_features:\n",
    "                break\n",
    "        # Get values of the column\n",
    "        values = df[column].values.reshape(-1,1)\n",
    "        # Take the scaler of that column\n",
    "        scaler = scalers['scaler_' + column]\n",
    "        # Scale values\n",
    "        scaled_column = scaler.transform(values)\n",
    "        scaled_column = np.reshape(scaled_column,len(scaled_column))\n",
    "        # Add the scaled values to the df\n",
    "        df[column] = scaled_column\n",
    "        \n",
    "    print(f' Min values are: ')\n",
    "    print(df.min())\n",
    "    print(f' Max values are: ')\n",
    "    print(df.max())\n",
    "        \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38ed82fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Min values are: \n",
      "0      -1.0\n",
      "1      -1.0\n",
      "2      -1.0\n",
      "3      -1.0\n",
      "4      -1.0\n",
      "       ... \n",
      "1022   -1.0\n",
      "1023   -1.0\n",
      "0       0.0\n",
      "1       0.0\n",
      "2       0.0\n",
      "Length: 1027, dtype: float64\n",
      " Max values are: \n",
      "0       1.0\n",
      "1       1.0\n",
      "2       1.0\n",
      "3       1.0\n",
      "4       1.0\n",
      "       ... \n",
      "1022    1.0\n",
      "1023    1.0\n",
      "0       1.0\n",
      "1       1.0\n",
      "2       1.0\n",
      "Length: 1027, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201601</th>\n",
       "      <td>0.717415</td>\n",
       "      <td>-0.264619</td>\n",
       "      <td>-0.512345</td>\n",
       "      <td>-0.596061</td>\n",
       "      <td>0.474445</td>\n",
       "      <td>0.534150</td>\n",
       "      <td>-0.046372</td>\n",
       "      <td>-0.033960</td>\n",
       "      <td>0.317819</td>\n",
       "      <td>0.237751</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.131012</td>\n",
       "      <td>0.127058</td>\n",
       "      <td>-0.319972</td>\n",
       "      <td>0.037591</td>\n",
       "      <td>0.106643</td>\n",
       "      <td>-0.352494</td>\n",
       "      <td>-0.615821</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201602</th>\n",
       "      <td>-0.419614</td>\n",
       "      <td>-0.077807</td>\n",
       "      <td>0.419405</td>\n",
       "      <td>-0.042335</td>\n",
       "      <td>0.008382</td>\n",
       "      <td>-0.073435</td>\n",
       "      <td>-0.675073</td>\n",
       "      <td>-0.723629</td>\n",
       "      <td>0.606674</td>\n",
       "      <td>-0.262004</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.122372</td>\n",
       "      <td>-0.760683</td>\n",
       "      <td>-0.018953</td>\n",
       "      <td>-0.522950</td>\n",
       "      <td>-0.092673</td>\n",
       "      <td>0.164985</td>\n",
       "      <td>0.116053</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201603</th>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.118415</td>\n",
       "      <td>-0.330244</td>\n",
       "      <td>-0.239351</td>\n",
       "      <td>-0.325351</td>\n",
       "      <td>0.133311</td>\n",
       "      <td>0.349401</td>\n",
       "      <td>-0.411326</td>\n",
       "      <td>0.111055</td>\n",
       "      <td>0.336141</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.198964</td>\n",
       "      <td>-0.020205</td>\n",
       "      <td>0.130970</td>\n",
       "      <td>0.252293</td>\n",
       "      <td>-0.728723</td>\n",
       "      <td>0.270905</td>\n",
       "      <td>-0.716005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201604</th>\n",
       "      <td>0.529969</td>\n",
       "      <td>-0.509892</td>\n",
       "      <td>0.742719</td>\n",
       "      <td>0.991672</td>\n",
       "      <td>-0.387949</td>\n",
       "      <td>0.454282</td>\n",
       "      <td>0.073106</td>\n",
       "      <td>0.081956</td>\n",
       "      <td>0.118748</td>\n",
       "      <td>-0.125905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509073</td>\n",
       "      <td>-0.501989</td>\n",
       "      <td>0.615657</td>\n",
       "      <td>0.648789</td>\n",
       "      <td>-0.508657</td>\n",
       "      <td>0.017548</td>\n",
       "      <td>-0.717804</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201605</th>\n",
       "      <td>-0.056345</td>\n",
       "      <td>0.191385</td>\n",
       "      <td>-0.106391</td>\n",
       "      <td>0.039488</td>\n",
       "      <td>0.526060</td>\n",
       "      <td>0.189748</td>\n",
       "      <td>-0.747163</td>\n",
       "      <td>-0.488399</td>\n",
       "      <td>0.084417</td>\n",
       "      <td>-0.638029</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096112</td>\n",
       "      <td>-0.216066</td>\n",
       "      <td>-0.146001</td>\n",
       "      <td>0.146645</td>\n",
       "      <td>-0.900364</td>\n",
       "      <td>0.018970</td>\n",
       "      <td>0.224596</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1027 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "201601  0.717415 -0.264619 -0.512345 -0.596061  0.474445  0.534150 -0.046372   \n",
       "201602 -0.419614 -0.077807  0.419405 -0.042335  0.008382 -0.073435 -0.675073   \n",
       "201603  0.000901  0.118415 -0.330244 -0.239351 -0.325351  0.133311  0.349401   \n",
       "201604  0.529969 -0.509892  0.742719  0.991672 -0.387949  0.454282  0.073106   \n",
       "201605 -0.056345  0.191385 -0.106391  0.039488  0.526060  0.189748 -0.747163   \n",
       "\n",
       "               7         8         9  ...      1017      1018      1019  \\\n",
       "201601 -0.033960  0.317819  0.237751  ... -0.131012  0.127058 -0.319972   \n",
       "201602 -0.723629  0.606674 -0.262004  ... -0.122372 -0.760683 -0.018953   \n",
       "201603 -0.411326  0.111055  0.336141  ... -0.198964 -0.020205  0.130970   \n",
       "201604  0.081956  0.118748 -0.125905  ...  0.509073 -0.501989  0.615657   \n",
       "201605 -0.488399  0.084417 -0.638029  ... -0.096112 -0.216066 -0.146001   \n",
       "\n",
       "            1020      1021      1022      1023  0  1  2  \n",
       "201601  0.037591  0.106643 -0.352494 -0.615821  1  0  0  \n",
       "201602 -0.522950 -0.092673  0.164985  0.116053  0  1  0  \n",
       "201603  0.252293 -0.728723  0.270905 -0.716005  0  0  1  \n",
       "201604  0.648789 -0.508657  0.017548 -0.717804  1  0  0  \n",
       "201605  0.146645 -0.900364  0.018970  0.224596  1  0  0  \n",
       "\n",
       "[5 rows x 1027 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_range = (-1, 1)\n",
    "\n",
    "# Scale train:\n",
    "train_df, scalers = normalize_train_features(train_df, feature_range=feature_range, n_labels=n_labels)\n",
    "\n",
    "#print(f'The scalers are: {scalers}')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29ce1746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Min values are: \n",
      "0      -0.611774\n",
      "1      -0.698647\n",
      "2      -1.492308\n",
      "3      -0.577689\n",
      "4      -0.528444\n",
      "          ...   \n",
      "1022   -0.468700\n",
      "1023   -1.009303\n",
      "0       0.000000\n",
      "1       0.000000\n",
      "2       0.000000\n",
      "Length: 1027, dtype: float64\n",
      " Max values are: \n",
      "0       0.798543\n",
      "1       0.992657\n",
      "2       0.376680\n",
      "3       0.943176\n",
      "4       0.824965\n",
      "          ...   \n",
      "1022    0.451219\n",
      "1023    0.782204\n",
      "0       1.000000\n",
      "1       1.000000\n",
      "2       1.000000\n",
      "Length: 1027, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201821</th>\n",
       "      <td>0.084599</td>\n",
       "      <td>0.542881</td>\n",
       "      <td>-0.384070</td>\n",
       "      <td>-0.080906</td>\n",
       "      <td>0.138302</td>\n",
       "      <td>0.078038</td>\n",
       "      <td>-0.007716</td>\n",
       "      <td>-0.031384</td>\n",
       "      <td>-0.545694</td>\n",
       "      <td>-0.072470</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.699482</td>\n",
       "      <td>0.136318</td>\n",
       "      <td>0.328906</td>\n",
       "      <td>0.342614</td>\n",
       "      <td>0.063277</td>\n",
       "      <td>0.219823</td>\n",
       "      <td>0.294464</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201822</th>\n",
       "      <td>0.798543</td>\n",
       "      <td>0.992657</td>\n",
       "      <td>-0.493325</td>\n",
       "      <td>-0.416277</td>\n",
       "      <td>0.266510</td>\n",
       "      <td>-0.591903</td>\n",
       "      <td>0.565659</td>\n",
       "      <td>-0.179126</td>\n",
       "      <td>0.237211</td>\n",
       "      <td>0.382436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201944</td>\n",
       "      <td>-0.673409</td>\n",
       "      <td>-0.036940</td>\n",
       "      <td>-0.021246</td>\n",
       "      <td>0.060466</td>\n",
       "      <td>0.102064</td>\n",
       "      <td>0.112100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201823</th>\n",
       "      <td>0.247549</td>\n",
       "      <td>-0.247999</td>\n",
       "      <td>0.253891</td>\n",
       "      <td>0.300498</td>\n",
       "      <td>0.187533</td>\n",
       "      <td>-0.202666</td>\n",
       "      <td>-0.067352</td>\n",
       "      <td>-0.504047</td>\n",
       "      <td>0.361369</td>\n",
       "      <td>0.378615</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.290135</td>\n",
       "      <td>0.185387</td>\n",
       "      <td>0.484507</td>\n",
       "      <td>-0.645408</td>\n",
       "      <td>-0.595917</td>\n",
       "      <td>-0.186724</td>\n",
       "      <td>-0.197858</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201824</th>\n",
       "      <td>0.420624</td>\n",
       "      <td>0.373608</td>\n",
       "      <td>-0.799224</td>\n",
       "      <td>0.511320</td>\n",
       "      <td>-0.279726</td>\n",
       "      <td>-0.603021</td>\n",
       "      <td>0.154349</td>\n",
       "      <td>-0.543294</td>\n",
       "      <td>0.365547</td>\n",
       "      <td>0.051451</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053085</td>\n",
       "      <td>-0.549938</td>\n",
       "      <td>0.159301</td>\n",
       "      <td>0.492040</td>\n",
       "      <td>-0.004100</td>\n",
       "      <td>0.447210</td>\n",
       "      <td>-0.103205</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201825</th>\n",
       "      <td>0.155971</td>\n",
       "      <td>-0.698647</td>\n",
       "      <td>0.350023</td>\n",
       "      <td>-0.577689</td>\n",
       "      <td>0.674053</td>\n",
       "      <td>-0.199004</td>\n",
       "      <td>0.069916</td>\n",
       "      <td>-0.071021</td>\n",
       "      <td>0.025623</td>\n",
       "      <td>-0.410628</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.164270</td>\n",
       "      <td>0.157324</td>\n",
       "      <td>-0.432406</td>\n",
       "      <td>0.355685</td>\n",
       "      <td>0.165775</td>\n",
       "      <td>0.352219</td>\n",
       "      <td>0.450566</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1027 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "201821  0.084599  0.542881 -0.384070 -0.080906  0.138302  0.078038 -0.007716   \n",
       "201822  0.798543  0.992657 -0.493325 -0.416277  0.266510 -0.591903  0.565659   \n",
       "201823  0.247549 -0.247999  0.253891  0.300498  0.187533 -0.202666 -0.067352   \n",
       "201824  0.420624  0.373608 -0.799224  0.511320 -0.279726 -0.603021  0.154349   \n",
       "201825  0.155971 -0.698647  0.350023 -0.577689  0.674053 -0.199004  0.069916   \n",
       "\n",
       "               7         8         9  ...      1017      1018      1019  \\\n",
       "201821 -0.031384 -0.545694 -0.072470  ... -0.699482  0.136318  0.328906   \n",
       "201822 -0.179126  0.237211  0.382436  ...  0.201944 -0.673409 -0.036940   \n",
       "201823 -0.504047  0.361369  0.378615  ... -0.290135  0.185387  0.484507   \n",
       "201824 -0.543294  0.365547  0.051451  ... -0.053085 -0.549938  0.159301   \n",
       "201825 -0.071021  0.025623 -0.410628  ... -0.164270  0.157324 -0.432406   \n",
       "\n",
       "            1020      1021      1022      1023  0  1  2  \n",
       "201821  0.342614  0.063277  0.219823  0.294464  1  0  0  \n",
       "201822 -0.021246  0.060466  0.102064  0.112100  1  0  0  \n",
       "201823 -0.645408 -0.595917 -0.186724 -0.197858  1  0  0  \n",
       "201824  0.492040 -0.004100  0.447210 -0.103205  1  0  0  \n",
       "201825  0.355685  0.165775  0.352219  0.450566  1  0  0  \n",
       "\n",
       "[5 rows x 1027 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale test:\n",
    "test_df = normalize_test_features(test_df, scalers=scalers, n_labels=n_labels)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dc617d",
   "metadata": {},
   "source": [
    "### Prepare data for time series supervised learning (function to create sliding window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c439cbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for time series\n",
    "\n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d99d3d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-10)</th>\n",
       "      <th>var2(t-10)</th>\n",
       "      <th>var3(t-10)</th>\n",
       "      <th>var4(t-10)</th>\n",
       "      <th>var5(t-10)</th>\n",
       "      <th>var6(t-10)</th>\n",
       "      <th>var7(t-10)</th>\n",
       "      <th>var8(t-10)</th>\n",
       "      <th>var9(t-10)</th>\n",
       "      <th>var10(t-10)</th>\n",
       "      <th>...</th>\n",
       "      <th>var1018(t)</th>\n",
       "      <th>var1019(t)</th>\n",
       "      <th>var1020(t)</th>\n",
       "      <th>var1021(t)</th>\n",
       "      <th>var1022(t)</th>\n",
       "      <th>var1023(t)</th>\n",
       "      <th>var1024(t)</th>\n",
       "      <th>var1025(t)</th>\n",
       "      <th>var1026(t)</th>\n",
       "      <th>var1027(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201611</th>\n",
       "      <td>0.717415</td>\n",
       "      <td>-0.264619</td>\n",
       "      <td>-0.512345</td>\n",
       "      <td>-0.596061</td>\n",
       "      <td>0.474445</td>\n",
       "      <td>0.534150</td>\n",
       "      <td>-0.046372</td>\n",
       "      <td>-0.033960</td>\n",
       "      <td>0.317819</td>\n",
       "      <td>0.237751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148737</td>\n",
       "      <td>-0.063537</td>\n",
       "      <td>0.342771</td>\n",
       "      <td>-0.026400</td>\n",
       "      <td>0.267312</td>\n",
       "      <td>-0.061181</td>\n",
       "      <td>-0.022407</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201612</th>\n",
       "      <td>-0.419614</td>\n",
       "      <td>-0.077807</td>\n",
       "      <td>0.419405</td>\n",
       "      <td>-0.042335</td>\n",
       "      <td>0.008382</td>\n",
       "      <td>-0.073435</td>\n",
       "      <td>-0.675073</td>\n",
       "      <td>-0.723629</td>\n",
       "      <td>0.606674</td>\n",
       "      <td>-0.262004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.515570</td>\n",
       "      <td>-0.123022</td>\n",
       "      <td>-0.496992</td>\n",
       "      <td>0.268676</td>\n",
       "      <td>0.079583</td>\n",
       "      <td>0.241669</td>\n",
       "      <td>-0.595634</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201613</th>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.118415</td>\n",
       "      <td>-0.330244</td>\n",
       "      <td>-0.239351</td>\n",
       "      <td>-0.325351</td>\n",
       "      <td>0.133311</td>\n",
       "      <td>0.349401</td>\n",
       "      <td>-0.411326</td>\n",
       "      <td>0.111055</td>\n",
       "      <td>0.336141</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.126848</td>\n",
       "      <td>0.661713</td>\n",
       "      <td>0.153685</td>\n",
       "      <td>0.229164</td>\n",
       "      <td>-0.463973</td>\n",
       "      <td>0.053713</td>\n",
       "      <td>-0.975594</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201614</th>\n",
       "      <td>0.529969</td>\n",
       "      <td>-0.509892</td>\n",
       "      <td>0.742719</td>\n",
       "      <td>0.991672</td>\n",
       "      <td>-0.387949</td>\n",
       "      <td>0.454282</td>\n",
       "      <td>0.073106</td>\n",
       "      <td>0.081956</td>\n",
       "      <td>0.118748</td>\n",
       "      <td>-0.125905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285252</td>\n",
       "      <td>-0.459350</td>\n",
       "      <td>0.118487</td>\n",
       "      <td>0.717821</td>\n",
       "      <td>0.011011</td>\n",
       "      <td>-0.017436</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201615</th>\n",
       "      <td>-0.056345</td>\n",
       "      <td>0.191385</td>\n",
       "      <td>-0.106391</td>\n",
       "      <td>0.039488</td>\n",
       "      <td>0.526060</td>\n",
       "      <td>0.189748</td>\n",
       "      <td>-0.747163</td>\n",
       "      <td>-0.488399</td>\n",
       "      <td>0.084417</td>\n",
       "      <td>-0.638029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.502082</td>\n",
       "      <td>-0.235513</td>\n",
       "      <td>0.015692</td>\n",
       "      <td>0.535678</td>\n",
       "      <td>0.225521</td>\n",
       "      <td>0.046232</td>\n",
       "      <td>0.145397</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201816</th>\n",
       "      <td>0.161418</td>\n",
       "      <td>0.059350</td>\n",
       "      <td>-0.407217</td>\n",
       "      <td>-0.322475</td>\n",
       "      <td>0.280339</td>\n",
       "      <td>0.312166</td>\n",
       "      <td>0.115440</td>\n",
       "      <td>-0.833810</td>\n",
       "      <td>-0.187396</td>\n",
       "      <td>-0.351217</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353747</td>\n",
       "      <td>0.397505</td>\n",
       "      <td>0.451361</td>\n",
       "      <td>-0.138578</td>\n",
       "      <td>-0.306785</td>\n",
       "      <td>0.371796</td>\n",
       "      <td>-0.192488</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201817</th>\n",
       "      <td>0.887821</td>\n",
       "      <td>-0.180743</td>\n",
       "      <td>-0.405007</td>\n",
       "      <td>-0.110293</td>\n",
       "      <td>-0.760965</td>\n",
       "      <td>0.572115</td>\n",
       "      <td>-0.546911</td>\n",
       "      <td>-0.084733</td>\n",
       "      <td>0.133753</td>\n",
       "      <td>-0.301270</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.207863</td>\n",
       "      <td>0.403494</td>\n",
       "      <td>0.488648</td>\n",
       "      <td>-0.299530</td>\n",
       "      <td>-0.063334</td>\n",
       "      <td>0.803492</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201818</th>\n",
       "      <td>0.554046</td>\n",
       "      <td>0.137046</td>\n",
       "      <td>0.084558</td>\n",
       "      <td>0.011125</td>\n",
       "      <td>-0.421474</td>\n",
       "      <td>-0.790012</td>\n",
       "      <td>-0.537559</td>\n",
       "      <td>0.433995</td>\n",
       "      <td>0.491965</td>\n",
       "      <td>0.484942</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.160777</td>\n",
       "      <td>-0.014544</td>\n",
       "      <td>0.017891</td>\n",
       "      <td>0.102530</td>\n",
       "      <td>0.360620</td>\n",
       "      <td>-0.128165</td>\n",
       "      <td>-0.316256</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201819</th>\n",
       "      <td>0.149763</td>\n",
       "      <td>-0.577400</td>\n",
       "      <td>-0.319449</td>\n",
       "      <td>-0.402680</td>\n",
       "      <td>-0.085460</td>\n",
       "      <td>-0.189519</td>\n",
       "      <td>-0.881927</td>\n",
       "      <td>0.317386</td>\n",
       "      <td>-0.189051</td>\n",
       "      <td>0.544778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.255767</td>\n",
       "      <td>-0.741897</td>\n",
       "      <td>0.086524</td>\n",
       "      <td>0.102446</td>\n",
       "      <td>0.620181</td>\n",
       "      <td>0.121715</td>\n",
       "      <td>0.747221</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201820</th>\n",
       "      <td>0.588307</td>\n",
       "      <td>0.007995</td>\n",
       "      <td>0.317992</td>\n",
       "      <td>-0.042756</td>\n",
       "      <td>0.269775</td>\n",
       "      <td>-0.396270</td>\n",
       "      <td>-0.482307</td>\n",
       "      <td>-0.231678</td>\n",
       "      <td>0.376478</td>\n",
       "      <td>0.264857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.502141</td>\n",
       "      <td>-0.403143</td>\n",
       "      <td>-0.062169</td>\n",
       "      <td>-0.114325</td>\n",
       "      <td>-0.087839</td>\n",
       "      <td>0.094620</td>\n",
       "      <td>-0.479982</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 11297 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        var1(t-10)  var2(t-10)  var3(t-10)  var4(t-10)  var5(t-10)  \\\n",
       "201611    0.717415   -0.264619   -0.512345   -0.596061    0.474445   \n",
       "201612   -0.419614   -0.077807    0.419405   -0.042335    0.008382   \n",
       "201613    0.000901    0.118415   -0.330244   -0.239351   -0.325351   \n",
       "201614    0.529969   -0.509892    0.742719    0.991672   -0.387949   \n",
       "201615   -0.056345    0.191385   -0.106391    0.039488    0.526060   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "201816    0.161418    0.059350   -0.407217   -0.322475    0.280339   \n",
       "201817    0.887821   -0.180743   -0.405007   -0.110293   -0.760965   \n",
       "201818    0.554046    0.137046    0.084558    0.011125   -0.421474   \n",
       "201819    0.149763   -0.577400   -0.319449   -0.402680   -0.085460   \n",
       "201820    0.588307    0.007995    0.317992   -0.042756    0.269775   \n",
       "\n",
       "        var6(t-10)  var7(t-10)  var8(t-10)  var9(t-10)  var10(t-10)  ...  \\\n",
       "201611    0.534150   -0.046372   -0.033960    0.317819     0.237751  ...   \n",
       "201612   -0.073435   -0.675073   -0.723629    0.606674    -0.262004  ...   \n",
       "201613    0.133311    0.349401   -0.411326    0.111055     0.336141  ...   \n",
       "201614    0.454282    0.073106    0.081956    0.118748    -0.125905  ...   \n",
       "201615    0.189748   -0.747163   -0.488399    0.084417    -0.638029  ...   \n",
       "...            ...         ...         ...         ...          ...  ...   \n",
       "201816    0.312166    0.115440   -0.833810   -0.187396    -0.351217  ...   \n",
       "201817    0.572115   -0.546911   -0.084733    0.133753    -0.301270  ...   \n",
       "201818   -0.790012   -0.537559    0.433995    0.491965     0.484942  ...   \n",
       "201819   -0.189519   -0.881927    0.317386   -0.189051     0.544778  ...   \n",
       "201820   -0.396270   -0.482307   -0.231678    0.376478     0.264857  ...   \n",
       "\n",
       "        var1018(t)  var1019(t)  var1020(t)  var1021(t)  var1022(t)  \\\n",
       "201611    0.148737   -0.063537    0.342771   -0.026400    0.267312   \n",
       "201612    0.515570   -0.123022   -0.496992    0.268676    0.079583   \n",
       "201613   -0.126848    0.661713    0.153685    0.229164   -0.463973   \n",
       "201614    0.285252   -0.459350    0.118487    0.717821    0.011011   \n",
       "201615    0.502082   -0.235513    0.015692    0.535678    0.225521   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "201816    0.353747    0.397505    0.451361   -0.138578   -0.306785   \n",
       "201817   -1.000000   -0.207863    0.403494    0.488648   -0.299530   \n",
       "201818   -0.160777   -0.014544    0.017891    0.102530    0.360620   \n",
       "201819    0.255767   -0.741897    0.086524    0.102446    0.620181   \n",
       "201820    0.502141   -0.403143   -0.062169   -0.114325   -0.087839   \n",
       "\n",
       "        var1023(t)  var1024(t)  var1025(t)  var1026(t)  var1027(t)  \n",
       "201611   -0.061181   -0.022407           0           1           0  \n",
       "201612    0.241669   -0.595634           0           1           0  \n",
       "201613    0.053713   -0.975594           0           1           0  \n",
       "201614   -0.017436    1.000000           0           0           1  \n",
       "201615    0.046232    0.145397           0           1           0  \n",
       "...            ...         ...         ...         ...         ...  \n",
       "201816    0.371796   -0.192488           1           0           0  \n",
       "201817   -0.063334    0.803492           1           0           0  \n",
       "201818   -0.128165   -0.316256           1           0           0  \n",
       "201819    0.121715    0.747221           1           0           0  \n",
       "201820    0.094620   -0.479982           1           0           0  \n",
       "\n",
       "[114 rows x 11297 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# length of window\n",
    "days = 10\n",
    "\n",
    "# frame as supervised learning\n",
    "train = series_to_supervised(train_df, n_in=days)\n",
    "test = series_to_supervised(test_df, n_in=days)\n",
    "\n",
    "DataFrame(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0fff0f",
   "metadata": {},
   "source": [
    "### Features and Labels Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f35c37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_labels_set(timeseries_data, original_df, n_labels):\n",
    "    \n",
    "    \"\"\" Features \"\"\"\n",
    "    # We define the number of features as (features and labels)\n",
    "    n_features = original_df.shape[1]\n",
    "\n",
    "    # The features to train the model will be all except the values of the actual week \n",
    "    # We can't use other variables in week t because whe need to resample a a 3D Array\n",
    "    features_set = DataFrame(timeseries_data.values[:,:-n_features])\n",
    "    # Convert pandas data frame to np.array to reshape as 3D Array\n",
    "    features_set = features_set.to_numpy()\n",
    "    print(f'The shape of the features is {features_set.shape}')\n",
    "    \n",
    "    \"\"\" Labels \"\"\"\n",
    "    # We will use labels in last week \n",
    "    labels_set = DataFrame(timeseries_data.values[:,-n_labels:])\n",
    "    # Convert pandas data frame to np.array\n",
    "    labels_set = labels_set.to_numpy()\n",
    "    print(f'The shape of the labels is {labels_set.shape}')\n",
    "    \n",
    "    return features_set, labels_set, n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f84d9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "The shape of the features is (114, 10270)\n",
      "The shape of the labels is (114, 3)\n",
      "Test:\n",
      "The shape of the features is (22, 10270)\n",
      "The shape of the labels is (22, 3)\n"
     ]
    }
   ],
   "source": [
    "# Train features and labels set\n",
    "print('Train:')\n",
    "train_X, train_y, n_features = features_labels_set(timeseries_data=train, original_df=dengue_df, n_labels=n_labels)\n",
    "\n",
    "# Test features and labels set\n",
    "print('Test:')\n",
    "test_X, test_y, n_features = features_labels_set(timeseries_data=test, original_df=dengue_df, n_labels=n_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ad3036",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f317a3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_tensor(train_X, test_X, n_features):\n",
    "    print('The initial shapes are:')\n",
    "    print(f'The train shape is {train_X.shape}')\n",
    "    print(f'The test shape is {test_X.shape}')\n",
    "    \n",
    "    # reshape input to be 3D [samples, timesteps, features]\n",
    "    train_X = train_X.reshape((train_X.shape[0], days, n_features))\n",
    "    test_X = test_X.reshape((test_X.shape[0], days, n_features))\n",
    "    \n",
    "    print('-----------------------')\n",
    "    print('The Final shapes are:')\n",
    "    print(f'The train shape is {train_X.shape}')\n",
    "    print(f'The test shape is {test_X.shape}')\n",
    "    \n",
    "    return train_X, test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fcc42c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial shapes are:\n",
      "The train shape is (114, 10270)\n",
      "The test shape is (22, 10270)\n",
      "-----------------------\n",
      "The Final shapes are:\n",
      "The train shape is (114, 10, 1027)\n",
      "The test shape is (22, 10, 1027)\n"
     ]
    }
   ],
   "source": [
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X, test_X = reshape_tensor(train_X, test_X, n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc17abcf",
   "metadata": {},
   "source": [
    "# Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f90f28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Seed\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(120, dropout=0.1, input_shape=(train_X.shape[1], train_X.shape[2]), return_sequences=True))\n",
    "model.add(LSTM(240, dropout=0.1, input_shape=(train_X.shape[1], 120)))\n",
    "model.add(Dense(60))\n",
    "model.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71660fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 10, 120)           551040    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 240)               346560    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 60)                14460     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 183       \n",
      "=================================================================\n",
      "Total params: 912,243\n",
      "Trainable params: 912,243\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "opt = keras.optimizers.Adam()\n",
    "metric = tf.keras.metrics.AUC(name='auc', multi_label=True, num_labels=3)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=metric)\n",
    "\n",
    "# Print the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526035c7",
   "metadata": {},
   "source": [
    "### Imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da46745a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zeros: 113, ones: 20, twos: 23, total: 156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 1.3805309734513274, 1: 7.8, 2: 6.782608695652174}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_zeros = (labels_df_orig.to_numpy() == 0).sum()\n",
    "n_ones = (labels_df_orig.to_numpy() == 1).sum()\n",
    "n_twos = (labels_df_orig.to_numpy() == 2).sum()\n",
    "n_total = n_zeros + n_ones + n_twos\n",
    "\n",
    "weights = {0: n_total/n_zeros, 1: n_total/n_ones, 2: n_total/n_twos}\n",
    "print(f'zeros: {n_zeros}, ones: {n_ones}, twos: {n_twos}, total: {n_total}')\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7e3c78",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4842cf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# EarlyStopping:\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=20, \n",
    "        verbose=1, mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18d3e94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 - 3s - loss: 3.7328 - auc: 0.4496 - val_loss: 0.7102 - val_auc: 0.2094\n",
      "Epoch 2/50\n",
      "8/8 - 0s - loss: 3.7837 - auc: 0.6043 - val_loss: 1.1417 - val_auc: 0.4519\n",
      "Epoch 3/50\n",
      "8/8 - 0s - loss: 2.5620 - auc: 0.8332 - val_loss: 0.8855 - val_auc: 0.6350\n",
      "Epoch 4/50\n",
      "8/8 - 0s - loss: 2.2561 - auc: 0.8863 - val_loss: 0.7240 - val_auc: 0.7410\n",
      "Epoch 5/50\n",
      "8/8 - 0s - loss: 1.9261 - auc: 0.9082 - val_loss: 0.6284 - val_auc: 0.8952\n",
      "Epoch 6/50\n",
      "8/8 - 0s - loss: 1.6750 - auc: 0.9214 - val_loss: 0.4465 - val_auc: 0.9545\n",
      "Epoch 7/50\n",
      "8/8 - 0s - loss: 1.3882 - auc: 0.9425 - val_loss: 0.4455 - val_auc: 0.9006\n",
      "Epoch 8/50\n",
      "8/8 - 0s - loss: 1.3508 - auc: 0.9384 - val_loss: 1.0653 - val_auc: 0.5000\n",
      "Epoch 9/50\n",
      "8/8 - 0s - loss: 5.0970 - auc: 0.8144 - val_loss: 1.5885 - val_auc: 0.8104\n",
      "Epoch 10/50\n",
      "8/8 - 0s - loss: 1.7208 - auc: 0.9320 - val_loss: 1.2484 - val_auc: 0.7720\n",
      "Epoch 11/50\n",
      "8/8 - 0s - loss: 1.4151 - auc: 0.9610 - val_loss: 0.7555 - val_auc: 0.7549\n",
      "Epoch 12/50\n",
      "8/8 - 0s - loss: 1.2183 - auc: 0.9598 - val_loss: 0.5673 - val_auc: 0.6969\n",
      "Epoch 13/50\n",
      "8/8 - 0s - loss: 0.8980 - auc: 0.9769 - val_loss: 0.5022 - val_auc: 0.6961\n",
      "Epoch 14/50\n",
      "8/8 - 0s - loss: 0.6899 - auc: 0.9850 - val_loss: 0.4433 - val_auc: 0.7166\n",
      "Epoch 15/50\n",
      "8/8 - 0s - loss: 0.5438 - auc: 0.9881 - val_loss: 0.4709 - val_auc: 0.6857\n",
      "Epoch 16/50\n",
      "8/8 - 0s - loss: 0.4078 - auc: 0.9963 - val_loss: 0.5229 - val_auc: 0.7170\n",
      "Epoch 17/50\n",
      "8/8 - 0s - loss: 0.3092 - auc: 0.9985 - val_loss: 0.6074 - val_auc: 0.7725\n",
      "Epoch 18/50\n",
      "8/8 - 0s - loss: 0.2438 - auc: 0.9996 - val_loss: 0.5593 - val_auc: 0.7634\n",
      "Epoch 19/50\n",
      "8/8 - 0s - loss: 0.2793 - auc: 0.9989 - val_loss: 0.9610 - val_auc: 0.6047\n",
      "Epoch 20/50\n",
      "8/8 - 0s - loss: 0.7250 - auc: 0.9943 - val_loss: 0.6857 - val_auc: 0.8205\n",
      "Epoch 21/50\n",
      "8/8 - 0s - loss: 0.8177 - auc: 0.9868 - val_loss: 0.3922 - val_auc: 0.8514\n",
      "Epoch 22/50\n",
      "8/8 - 0s - loss: 0.5123 - auc: 0.9878 - val_loss: 0.5011 - val_auc: 0.8706\n",
      "Epoch 23/50\n",
      "8/8 - 0s - loss: 0.4301 - auc: 0.9962 - val_loss: 0.6163 - val_auc: 0.8251\n",
      "Epoch 24/50\n",
      "8/8 - 0s - loss: 0.2508 - auc: 1.0000 - val_loss: 0.4417 - val_auc: 0.8623\n",
      "Epoch 25/50\n",
      "8/8 - 0s - loss: 0.1822 - auc: 1.0000 - val_loss: 0.3892 - val_auc: 0.8852\n",
      "Epoch 26/50\n",
      "8/8 - 0s - loss: 0.1314 - auc: 1.0000 - val_loss: 0.3688 - val_auc: 0.8940\n",
      "Epoch 27/50\n",
      "8/8 - 0s - loss: 0.0819 - auc: 1.0000 - val_loss: 0.3583 - val_auc: 0.9023\n",
      "Epoch 28/50\n",
      "8/8 - 0s - loss: 0.0557 - auc: 1.0000 - val_loss: 0.3533 - val_auc: 0.9169\n",
      "Epoch 29/50\n",
      "8/8 - 0s - loss: 0.0411 - auc: 1.0000 - val_loss: 0.3506 - val_auc: 0.9199\n",
      "Epoch 30/50\n",
      "8/8 - 0s - loss: 0.0355 - auc: 1.0000 - val_loss: 0.3439 - val_auc: 0.9216\n",
      "Epoch 31/50\n",
      "8/8 - 0s - loss: 0.0255 - auc: 1.0000 - val_loss: 0.3424 - val_auc: 0.9216\n",
      "Epoch 32/50\n",
      "8/8 - 0s - loss: 0.0192 - auc: 1.0000 - val_loss: 0.3454 - val_auc: 0.9228\n",
      "Epoch 33/50\n",
      "8/8 - 0s - loss: 0.0186 - auc: 1.0000 - val_loss: 0.3339 - val_auc: 0.9199\n",
      "Epoch 34/50\n",
      "8/8 - 0s - loss: 0.0176 - auc: 1.0000 - val_loss: 0.3216 - val_auc: 0.9199\n",
      "Epoch 35/50\n",
      "8/8 - 0s - loss: 0.0118 - auc: 1.0000 - val_loss: 0.3243 - val_auc: 0.9211\n",
      "Epoch 36/50\n",
      "8/8 - 0s - loss: 0.0095 - auc: 1.0000 - val_loss: 0.3314 - val_auc: 0.9286\n",
      "Epoch 37/50\n",
      "8/8 - 0s - loss: 0.0099 - auc: 1.0000 - val_loss: 0.3424 - val_auc: 0.9366\n",
      "Epoch 38/50\n",
      "8/8 - 0s - loss: 0.0078 - auc: 1.0000 - val_loss: 0.3477 - val_auc: 0.9516\n",
      "Epoch 39/50\n",
      "8/8 - 0s - loss: 0.0073 - auc: 1.0000 - val_loss: 0.3451 - val_auc: 0.9575\n",
      "Epoch 40/50\n",
      "8/8 - 0s - loss: 0.0066 - auc: 1.0000 - val_loss: 0.3399 - val_auc: 0.9466\n",
      "Epoch 41/50\n",
      "8/8 - 0s - loss: 0.0051 - auc: 1.0000 - val_loss: 0.3420 - val_auc: 0.9466\n",
      "Epoch 42/50\n",
      "8/8 - 0s - loss: 0.0056 - auc: 1.0000 - val_loss: 0.3530 - val_auc: 0.9575\n",
      "Epoch 43/50\n",
      "8/8 - 0s - loss: 0.0047 - auc: 1.0000 - val_loss: 0.3565 - val_auc: 0.9533\n",
      "Epoch 44/50\n",
      "8/8 - 0s - loss: 0.0051 - auc: 1.0000 - val_loss: 0.3556 - val_auc: 0.9504\n",
      "Epoch 45/50\n",
      "8/8 - 0s - loss: 0.0040 - auc: 1.0000 - val_loss: 0.3548 - val_auc: 0.9533\n",
      "Epoch 46/50\n",
      "8/8 - 0s - loss: 0.0042 - auc: 1.0000 - val_loss: 0.3428 - val_auc: 0.9575\n",
      "Epoch 47/50\n",
      "8/8 - 0s - loss: 0.0039 - auc: 1.0000 - val_loss: 0.3322 - val_auc: 0.9516\n",
      "Epoch 48/50\n",
      "8/8 - 0s - loss: 0.0029 - auc: 1.0000 - val_loss: 0.3312 - val_auc: 0.9516\n",
      "Epoch 49/50\n",
      "8/8 - 0s - loss: 0.0032 - auc: 1.0000 - val_loss: 0.3384 - val_auc: 0.9516\n",
      "Epoch 50/50\n",
      "8/8 - 0s - loss: 0.0029 - auc: 1.0000 - val_loss: 0.3482 - val_auc: 0.9474\n"
     ]
    }
   ],
   "source": [
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size=16, validation_data=(test_X, test_y), verbose=2, shuffle=False, callbacks=[monitor], class_weight=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0e15919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab5eec8",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c83ad208",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "\n",
    "def test_model(model, test_X, test_y, scaler, rnn = None):\n",
    "    \n",
    "    # If model is a classical machine learning model and test_X is a 3D tensor, then convert to 2D\n",
    "    if not rnn and (len(test_X.shape) == 3):\n",
    "        test_X = test_X.reshape((test_X.shape[0], -1))\n",
    "    \n",
    "    # do the prediction\n",
    "    yhat = model.predict(test_X)\n",
    "    \n",
    "    # Convert yhat to one hot\n",
    "    yhat = np.array(tf.one_hot(tf.argmax(yhat, axis=1), depth = yhat.shape[1]))\n",
    "    \n",
    "    # Invert scaling for forecast\n",
    "    # Inverse Scaler\n",
    "    \n",
    "    # Predicted\n",
    "    if not rnn:\n",
    "        yhat = yhat.reshape(-1, 1)\n",
    "        \n",
    "    if not scaler:\n",
    "        return yhat, test_y\n",
    "        \n",
    "    inv_yhat = scaler.inverse_transform(yhat)\n",
    "    \n",
    "    # Real:\n",
    "    inv_y = scaler.inverse_transform(test_y)\n",
    "    \n",
    "    return inv_yhat, inv_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6f226284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With LSTM:\n",
    "inv_yhat_lstm, inv_y_lstm = test_model(model=model, test_X=test_X, test_y=test_y, scaler=None, rnn = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed29e78",
   "metadata": {},
   "source": [
    "# Calculate Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d36943e",
   "metadata": {},
   "source": [
    "# AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0128c855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.3482 - auc: 0.9474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.348244309425354, 'auc': 0.9474415183067322}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can also evaluate or predict on a dataset.\n",
    "print(\"Evaluate\")\n",
    "result = model.evaluate(test_X, test_y)\n",
    "dict(zip(model.metrics_names, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0520cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:generalml_p37_gpu_v1]",
   "language": "python",
   "name": "conda-env-generalml_p37_gpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
