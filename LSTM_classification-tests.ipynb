{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee22bd81",
   "metadata": {},
   "source": [
    "# Setup enviorment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32fcc75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data reading in Dataframe format and data preprocessing\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Linear algebra operations\n",
    "import numpy as np\n",
    "\n",
    "# Machine learning models and preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Sequential, layers, callbacks\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional\n",
    "\n",
    "# Epiweek\n",
    "from epiweeks import Week, Year\n",
    "\n",
    "# Date\n",
    "from datetime import date as convert_to_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "617c525f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5b80297",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = 'Embeddings/embeddings_vae_1024features.csv'\n",
    "labels = 'Tabular_data/Label_CSV_All_Municipality.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41f3e50",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b64c4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epiweek_from_date(image_date):\n",
    "    date = image_date.split('-')\n",
    "    \n",
    "    # Get year as int\n",
    "    year = ''.join(filter(str.isdigit, date[0]))\n",
    "    year = int(year)\n",
    "    \n",
    "    # Get month as int\n",
    "    month = ''.join(filter(str.isdigit, date[1]))\n",
    "    month = int(month)\n",
    "    \n",
    "    # Get day as int\n",
    "    day = ''.join(filter(str.isdigit, date[2]))\n",
    "    day = int(day)\n",
    "    \n",
    "    # Get epiweek:\n",
    "    date = convert_to_date(year, month, day)\n",
    "    epiweek = str(Week.fromdate(date))\n",
    "    epiweek = int(epiweek)\n",
    "    \n",
    "    return epiweek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c24f9e4",
   "metadata": {},
   "source": [
    "### 1. Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ae2bc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_features(path, Municipality = None):\n",
    "    df = pd.read_csv(path)\n",
    "    #df.Date = pd.to_datetime(df.Date)\n",
    "    \n",
    "    if Municipality:\n",
    "        print('Obtaining dataframe for the city of Medellin only...')\n",
    "        df = df[df['Municipality Code'] == Municipality]\n",
    "        \n",
    "    df.Date = df.Date.apply(epiweek_from_date)\n",
    "    \n",
    "    df = df.sort_values(by=['Date'])\n",
    "    \n",
    "    df = df.set_index('Date')\n",
    "    \n",
    "    if Municipality:\n",
    "        df.drop(columns=['Municipality Code'], inplace=True)\n",
    "        \n",
    "    df.index.name = None\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5949c1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining dataframe for the city of Medellin only...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1014</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201544</th>\n",
       "      <td>-0.046489</td>\n",
       "      <td>-1.407201</td>\n",
       "      <td>-1.148883</td>\n",
       "      <td>0.836687</td>\n",
       "      <td>-0.190778</td>\n",
       "      <td>1.802231</td>\n",
       "      <td>0.517497</td>\n",
       "      <td>-1.146697</td>\n",
       "      <td>0.119171</td>\n",
       "      <td>1.544828</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.678144</td>\n",
       "      <td>-0.036498</td>\n",
       "      <td>-0.303533</td>\n",
       "      <td>0.248490</td>\n",
       "      <td>-0.811357</td>\n",
       "      <td>-0.832925</td>\n",
       "      <td>-0.739305</td>\n",
       "      <td>-0.295200</td>\n",
       "      <td>-0.038603</td>\n",
       "      <td>0.485674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201545</th>\n",
       "      <td>0.327904</td>\n",
       "      <td>-0.701594</td>\n",
       "      <td>0.306197</td>\n",
       "      <td>-0.796750</td>\n",
       "      <td>-1.037395</td>\n",
       "      <td>0.857556</td>\n",
       "      <td>0.167456</td>\n",
       "      <td>1.642044</td>\n",
       "      <td>-0.473234</td>\n",
       "      <td>0.181270</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.897844</td>\n",
       "      <td>-0.661285</td>\n",
       "      <td>-1.146673</td>\n",
       "      <td>-1.234707</td>\n",
       "      <td>-0.184185</td>\n",
       "      <td>-0.140669</td>\n",
       "      <td>-2.367193</td>\n",
       "      <td>-0.463623</td>\n",
       "      <td>-0.668936</td>\n",
       "      <td>-0.233073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201546</th>\n",
       "      <td>-1.634988</td>\n",
       "      <td>-0.882196</td>\n",
       "      <td>0.291420</td>\n",
       "      <td>-2.686286</td>\n",
       "      <td>-0.684004</td>\n",
       "      <td>-0.407912</td>\n",
       "      <td>1.827255</td>\n",
       "      <td>0.327352</td>\n",
       "      <td>0.987357</td>\n",
       "      <td>0.781570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.906685</td>\n",
       "      <td>1.372330</td>\n",
       "      <td>-0.333867</td>\n",
       "      <td>0.728862</td>\n",
       "      <td>-0.005498</td>\n",
       "      <td>-0.743434</td>\n",
       "      <td>0.597319</td>\n",
       "      <td>0.195301</td>\n",
       "      <td>-0.850010</td>\n",
       "      <td>0.492581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201547</th>\n",
       "      <td>1.789035</td>\n",
       "      <td>0.854698</td>\n",
       "      <td>-2.904163</td>\n",
       "      <td>-1.008464</td>\n",
       "      <td>-0.165688</td>\n",
       "      <td>0.597984</td>\n",
       "      <td>0.142369</td>\n",
       "      <td>0.164123</td>\n",
       "      <td>1.069377</td>\n",
       "      <td>0.236612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254610</td>\n",
       "      <td>-0.536157</td>\n",
       "      <td>-0.424962</td>\n",
       "      <td>0.685125</td>\n",
       "      <td>-0.029501</td>\n",
       "      <td>0.095485</td>\n",
       "      <td>0.379560</td>\n",
       "      <td>-0.297148</td>\n",
       "      <td>-1.211405</td>\n",
       "      <td>0.443391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201548</th>\n",
       "      <td>-0.983180</td>\n",
       "      <td>0.145126</td>\n",
       "      <td>0.720849</td>\n",
       "      <td>1.524544</td>\n",
       "      <td>0.620878</td>\n",
       "      <td>-1.807810</td>\n",
       "      <td>0.340521</td>\n",
       "      <td>0.781281</td>\n",
       "      <td>-0.395229</td>\n",
       "      <td>-0.769379</td>\n",
       "      <td>...</td>\n",
       "      <td>1.562922</td>\n",
       "      <td>0.585608</td>\n",
       "      <td>-0.675990</td>\n",
       "      <td>0.232964</td>\n",
       "      <td>0.788353</td>\n",
       "      <td>0.147064</td>\n",
       "      <td>0.094748</td>\n",
       "      <td>-0.206415</td>\n",
       "      <td>1.170020</td>\n",
       "      <td>0.276934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201848</th>\n",
       "      <td>-0.177821</td>\n",
       "      <td>0.800357</td>\n",
       "      <td>0.158949</td>\n",
       "      <td>2.573438</td>\n",
       "      <td>1.615337</td>\n",
       "      <td>-0.998008</td>\n",
       "      <td>1.096824</td>\n",
       "      <td>-0.023870</td>\n",
       "      <td>-0.667530</td>\n",
       "      <td>-1.929526</td>\n",
       "      <td>...</td>\n",
       "      <td>2.209477</td>\n",
       "      <td>0.241274</td>\n",
       "      <td>-1.311355</td>\n",
       "      <td>0.955204</td>\n",
       "      <td>0.006918</td>\n",
       "      <td>0.715542</td>\n",
       "      <td>-0.870650</td>\n",
       "      <td>-0.205803</td>\n",
       "      <td>0.835786</td>\n",
       "      <td>1.692061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201849</th>\n",
       "      <td>-0.306444</td>\n",
       "      <td>1.308680</td>\n",
       "      <td>1.067536</td>\n",
       "      <td>-0.931025</td>\n",
       "      <td>-1.046062</td>\n",
       "      <td>2.075529</td>\n",
       "      <td>-0.501223</td>\n",
       "      <td>-2.267342</td>\n",
       "      <td>0.095569</td>\n",
       "      <td>-0.845871</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.447275</td>\n",
       "      <td>0.293684</td>\n",
       "      <td>-1.791375</td>\n",
       "      <td>-0.086890</td>\n",
       "      <td>0.917567</td>\n",
       "      <td>0.631528</td>\n",
       "      <td>-2.004170</td>\n",
       "      <td>0.267849</td>\n",
       "      <td>1.151415</td>\n",
       "      <td>-1.051147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201850</th>\n",
       "      <td>-0.151392</td>\n",
       "      <td>0.071449</td>\n",
       "      <td>0.356428</td>\n",
       "      <td>0.259774</td>\n",
       "      <td>-0.383608</td>\n",
       "      <td>1.065443</td>\n",
       "      <td>0.450759</td>\n",
       "      <td>0.322183</td>\n",
       "      <td>-1.307717</td>\n",
       "      <td>-0.181305</td>\n",
       "      <td>...</td>\n",
       "      <td>1.033319</td>\n",
       "      <td>0.951084</td>\n",
       "      <td>0.638319</td>\n",
       "      <td>-0.277678</td>\n",
       "      <td>0.032450</td>\n",
       "      <td>-0.329121</td>\n",
       "      <td>-0.322632</td>\n",
       "      <td>-1.898407</td>\n",
       "      <td>-0.602611</td>\n",
       "      <td>-0.267056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201851</th>\n",
       "      <td>-0.793142</td>\n",
       "      <td>-0.539722</td>\n",
       "      <td>-1.165816</td>\n",
       "      <td>-0.199017</td>\n",
       "      <td>2.244849</td>\n",
       "      <td>0.917043</td>\n",
       "      <td>-0.467799</td>\n",
       "      <td>0.353362</td>\n",
       "      <td>1.053764</td>\n",
       "      <td>0.443968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.882802</td>\n",
       "      <td>-0.827243</td>\n",
       "      <td>-0.127070</td>\n",
       "      <td>-1.308614</td>\n",
       "      <td>-1.632518</td>\n",
       "      <td>1.059085</td>\n",
       "      <td>1.047949</td>\n",
       "      <td>-2.762428</td>\n",
       "      <td>-0.955669</td>\n",
       "      <td>0.913588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201852</th>\n",
       "      <td>-0.393870</td>\n",
       "      <td>1.455486</td>\n",
       "      <td>-0.128889</td>\n",
       "      <td>-0.788440</td>\n",
       "      <td>0.381879</td>\n",
       "      <td>0.022924</td>\n",
       "      <td>0.543938</td>\n",
       "      <td>-0.070586</td>\n",
       "      <td>-0.623824</td>\n",
       "      <td>-0.382842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.705277</td>\n",
       "      <td>0.204254</td>\n",
       "      <td>-0.124967</td>\n",
       "      <td>0.008888</td>\n",
       "      <td>0.031512</td>\n",
       "      <td>2.580178</td>\n",
       "      <td>-0.813275</td>\n",
       "      <td>-0.418657</td>\n",
       "      <td>-0.572518</td>\n",
       "      <td>-0.936024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165 rows × 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "201544 -0.046489 -1.407201 -1.148883  0.836687 -0.190778  1.802231  0.517497   \n",
       "201545  0.327904 -0.701594  0.306197 -0.796750 -1.037395  0.857556  0.167456   \n",
       "201546 -1.634988 -0.882196  0.291420 -2.686286 -0.684004 -0.407912  1.827255   \n",
       "201547  1.789035  0.854698 -2.904163 -1.008464 -0.165688  0.597984  0.142369   \n",
       "201548 -0.983180  0.145126  0.720849  1.524544  0.620878 -1.807810  0.340521   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "201848 -0.177821  0.800357  0.158949  2.573438  1.615337 -0.998008  1.096824   \n",
       "201849 -0.306444  1.308680  1.067536 -0.931025 -1.046062  2.075529 -0.501223   \n",
       "201850 -0.151392  0.071449  0.356428  0.259774 -0.383608  1.065443  0.450759   \n",
       "201851 -0.793142 -0.539722 -1.165816 -0.199017  2.244849  0.917043 -0.467799   \n",
       "201852 -0.393870  1.455486 -0.128889 -0.788440  0.381879  0.022924  0.543938   \n",
       "\n",
       "               7         8         9  ...      1014      1015      1016  \\\n",
       "201544 -1.146697  0.119171  1.544828  ... -0.678144 -0.036498 -0.303533   \n",
       "201545  1.642044 -0.473234  0.181270  ... -0.897844 -0.661285 -1.146673   \n",
       "201546  0.327352  0.987357  0.781570  ...  0.906685  1.372330 -0.333867   \n",
       "201547  0.164123  1.069377  0.236612  ...  0.254610 -0.536157 -0.424962   \n",
       "201548  0.781281 -0.395229 -0.769379  ...  1.562922  0.585608 -0.675990   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "201848 -0.023870 -0.667530 -1.929526  ...  2.209477  0.241274 -1.311355   \n",
       "201849 -2.267342  0.095569 -0.845871  ... -2.447275  0.293684 -1.791375   \n",
       "201850  0.322183 -1.307717 -0.181305  ...  1.033319  0.951084  0.638319   \n",
       "201851  0.353362  1.053764  0.443968  ...  0.882802 -0.827243 -0.127070   \n",
       "201852 -0.070586 -0.623824 -0.382842  ...  0.705277  0.204254 -0.124967   \n",
       "\n",
       "            1017      1018      1019      1020      1021      1022      1023  \n",
       "201544  0.248490 -0.811357 -0.832925 -0.739305 -0.295200 -0.038603  0.485674  \n",
       "201545 -1.234707 -0.184185 -0.140669 -2.367193 -0.463623 -0.668936 -0.233073  \n",
       "201546  0.728862 -0.005498 -0.743434  0.597319  0.195301 -0.850010  0.492581  \n",
       "201547  0.685125 -0.029501  0.095485  0.379560 -0.297148 -1.211405  0.443391  \n",
       "201548  0.232964  0.788353  0.147064  0.094748 -0.206415  1.170020  0.276934  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "201848  0.955204  0.006918  0.715542 -0.870650 -0.205803  0.835786  1.692061  \n",
       "201849 -0.086890  0.917567  0.631528 -2.004170  0.267849  1.151415 -1.051147  \n",
       "201850 -0.277678  0.032450 -0.329121 -0.322632 -1.898407 -0.602611 -0.267056  \n",
       "201851 -1.308614 -1.632518  1.059085  1.047949 -2.762428 -0.955669  0.913588  \n",
       "201852  0.008888  0.031512  2.580178 -0.813275 -0.418657 -0.572518 -0.936024  \n",
       "\n",
       "[165 rows x 1024 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df = read_features(path=embeddings, Municipality='Medellín')\n",
    "features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaf84a8",
   "metadata": {},
   "source": [
    "### 2. Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcf81201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epiweek(name):\n",
    "    \n",
    "    # Get week\n",
    "    week = name.split('/')[1]\n",
    "    week = week.replace('w','')\n",
    "    week = int(week)\n",
    "    \n",
    "    # Year\n",
    "    year = name.split('/')[0]\n",
    "    year = int(year)\n",
    "    \n",
    "    epiweek = Week(year, week)\n",
    "    \n",
    "    epiweek = str(epiweek)\n",
    "    epiweek = int(epiweek)\n",
    "\n",
    "    return epiweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eca0969b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_labels(path, Municipality = None):\n",
    "    df = pd.read_csv(path)\n",
    "    if df.shape[1] > 678:\n",
    "        df = pd.concat([df[['Municipality code', 'Municipality']], df.iloc[:,-676:]], axis=1)\n",
    "        cols = df.iloc[:, 2:].columns\n",
    "        new_cols = df.iloc[:, 2:].columns.to_series().apply(get_epiweek)\n",
    "        df = df.rename(columns=dict(zip(cols, new_cols))) \n",
    "        \n",
    "    if 'Label_CSV_All_Municipality' in path:\n",
    "        # Get Columns\n",
    "        df = df[['epiweek', 'Municipality code', 'Municipality', 'final_cases_label']]\n",
    "        \n",
    "        # change epiweek format\n",
    "        df.epiweek = df.epiweek.apply(get_epiweek)\n",
    "        \n",
    "        # Remove duplicates\n",
    "        df = df[df.duplicated(['epiweek','Municipality code','Municipality']) == False]\n",
    "        \n",
    "        # Replace Increase, decrease, stable to numerical:\n",
    "        \"\"\"\n",
    "        - Stable = 0\n",
    "        - Increased = 1 \n",
    "        - Decreased = 2\n",
    "        \"\"\"\n",
    "        df.final_cases_label = df.final_cases_label.replace({'Stable': 0, 'Increased': 1, 'Decreased': 2})\n",
    "        \n",
    "        # Create table\n",
    "        df = df.pivot(index=['Municipality code', 'Municipality'], columns='epiweek', values='final_cases_label')\n",
    "\n",
    "        # Reset Index:\n",
    "        df = df.reset_index()\n",
    "    \n",
    "    if Municipality:\n",
    "        df = df[df['Municipality'] == Municipality]\n",
    "        df.drop(columns=['Municipality code'], inplace=True)\n",
    "        df.rename(columns={'Municipality': 'Municipality Code'}, inplace=True)\n",
    "    \n",
    "        df = df.set_index('Municipality Code')\n",
    "        df = df.T\n",
    "\n",
    "        df.columns.name = None\n",
    "        df.index.name = None\n",
    "        \n",
    "        df.columns = ['Labels']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fe59b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201601</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201602</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201603</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201604</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201605</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201848</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201849</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201850</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201851</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201852</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0  1  2\n",
       "201601  1  0  0\n",
       "201602  0  1  0\n",
       "201603  0  0  1\n",
       "201604  1  0  0\n",
       "201605  1  0  0\n",
       "...    .. .. ..\n",
       "201848  1  0  0\n",
       "201849  0  0  1\n",
       "201850  0  1  0\n",
       "201851  1  0  0\n",
       "201852  1  0  0\n",
       "\n",
       "[156 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df = read_labels(path=labels, Municipality='Medellín')\n",
    "labels_df_orig = labels_df\n",
    "labels_df = pd.get_dummies(labels_df['Labels'])\n",
    "labels_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1010e56f",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bdda7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labels = labels_df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46bd97ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201601</th>\n",
       "      <td>1.287487</td>\n",
       "      <td>-0.688955</td>\n",
       "      <td>-0.794426</td>\n",
       "      <td>-1.238838</td>\n",
       "      <td>1.239369</td>\n",
       "      <td>1.784700</td>\n",
       "      <td>-0.000341</td>\n",
       "      <td>0.525795</td>\n",
       "      <td>0.363034</td>\n",
       "      <td>0.825218</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.439056</td>\n",
       "      <td>0.675143</td>\n",
       "      <td>-1.017167</td>\n",
       "      <td>-0.206480</td>\n",
       "      <td>-0.043412</td>\n",
       "      <td>-1.014832</td>\n",
       "      <td>-1.435265</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201602</th>\n",
       "      <td>-1.399851</td>\n",
       "      <td>-0.211775</td>\n",
       "      <td>1.341302</td>\n",
       "      <td>0.132593</td>\n",
       "      <td>-0.097550</td>\n",
       "      <td>0.159015</td>\n",
       "      <td>-1.474547</td>\n",
       "      <td>-1.294940</td>\n",
       "      <td>1.222341</td>\n",
       "      <td>-0.381582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.420181</td>\n",
       "      <td>-1.341189</td>\n",
       "      <td>-0.138499</td>\n",
       "      <td>-1.804684</td>\n",
       "      <td>-0.662659</td>\n",
       "      <td>0.475712</td>\n",
       "      <td>0.201907</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201603</th>\n",
       "      <td>-0.405975</td>\n",
       "      <td>0.289439</td>\n",
       "      <td>-0.377020</td>\n",
       "      <td>-0.355364</td>\n",
       "      <td>-1.054876</td>\n",
       "      <td>0.712196</td>\n",
       "      <td>0.927682</td>\n",
       "      <td>-0.470455</td>\n",
       "      <td>-0.252064</td>\n",
       "      <td>1.062808</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.587504</td>\n",
       "      <td>0.340662</td>\n",
       "      <td>0.299123</td>\n",
       "      <td>0.405674</td>\n",
       "      <td>-2.638784</td>\n",
       "      <td>0.780803</td>\n",
       "      <td>-1.659373</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201604</th>\n",
       "      <td>0.844463</td>\n",
       "      <td>-1.315463</td>\n",
       "      <td>2.082394</td>\n",
       "      <td>2.693551</td>\n",
       "      <td>-1.234441</td>\n",
       "      <td>1.570999</td>\n",
       "      <td>0.279815</td>\n",
       "      <td>0.831815</td>\n",
       "      <td>-0.229177</td>\n",
       "      <td>-0.052932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.959280</td>\n",
       "      <td>-0.753616</td>\n",
       "      <td>1.713913</td>\n",
       "      <td>1.536158</td>\n",
       "      <td>-1.955070</td>\n",
       "      <td>0.051035</td>\n",
       "      <td>-1.663397</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201605</th>\n",
       "      <td>-0.541275</td>\n",
       "      <td>0.475828</td>\n",
       "      <td>0.136089</td>\n",
       "      <td>0.335247</td>\n",
       "      <td>1.387429</td>\n",
       "      <td>0.863202</td>\n",
       "      <td>-1.643587</td>\n",
       "      <td>-0.673929</td>\n",
       "      <td>-0.331307</td>\n",
       "      <td>-1.289601</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.362812</td>\n",
       "      <td>-0.104197</td>\n",
       "      <td>-0.509349</td>\n",
       "      <td>0.104454</td>\n",
       "      <td>-3.172053</td>\n",
       "      <td>0.055130</td>\n",
       "      <td>0.444714</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201848</th>\n",
       "      <td>-0.177821</td>\n",
       "      <td>0.800357</td>\n",
       "      <td>0.158949</td>\n",
       "      <td>2.573438</td>\n",
       "      <td>1.615337</td>\n",
       "      <td>-0.998008</td>\n",
       "      <td>1.096824</td>\n",
       "      <td>-0.023870</td>\n",
       "      <td>-0.667530</td>\n",
       "      <td>-1.929526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.955204</td>\n",
       "      <td>0.006918</td>\n",
       "      <td>0.715542</td>\n",
       "      <td>-0.870650</td>\n",
       "      <td>-0.205803</td>\n",
       "      <td>0.835786</td>\n",
       "      <td>1.692061</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201849</th>\n",
       "      <td>-0.306444</td>\n",
       "      <td>1.308680</td>\n",
       "      <td>1.067536</td>\n",
       "      <td>-0.931025</td>\n",
       "      <td>-1.046062</td>\n",
       "      <td>2.075529</td>\n",
       "      <td>-0.501223</td>\n",
       "      <td>-2.267342</td>\n",
       "      <td>0.095569</td>\n",
       "      <td>-0.845871</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086890</td>\n",
       "      <td>0.917567</td>\n",
       "      <td>0.631528</td>\n",
       "      <td>-2.004170</td>\n",
       "      <td>0.267849</td>\n",
       "      <td>1.151415</td>\n",
       "      <td>-1.051147</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201850</th>\n",
       "      <td>-0.151392</td>\n",
       "      <td>0.071449</td>\n",
       "      <td>0.356428</td>\n",
       "      <td>0.259774</td>\n",
       "      <td>-0.383608</td>\n",
       "      <td>1.065443</td>\n",
       "      <td>0.450759</td>\n",
       "      <td>0.322183</td>\n",
       "      <td>-1.307717</td>\n",
       "      <td>-0.181305</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.277678</td>\n",
       "      <td>0.032450</td>\n",
       "      <td>-0.329121</td>\n",
       "      <td>-0.322632</td>\n",
       "      <td>-1.898407</td>\n",
       "      <td>-0.602611</td>\n",
       "      <td>-0.267056</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201851</th>\n",
       "      <td>-0.793142</td>\n",
       "      <td>-0.539722</td>\n",
       "      <td>-1.165816</td>\n",
       "      <td>-0.199017</td>\n",
       "      <td>2.244849</td>\n",
       "      <td>0.917043</td>\n",
       "      <td>-0.467799</td>\n",
       "      <td>0.353362</td>\n",
       "      <td>1.053764</td>\n",
       "      <td>0.443968</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.308614</td>\n",
       "      <td>-1.632518</td>\n",
       "      <td>1.059085</td>\n",
       "      <td>1.047949</td>\n",
       "      <td>-2.762428</td>\n",
       "      <td>-0.955669</td>\n",
       "      <td>0.913588</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201852</th>\n",
       "      <td>-0.393870</td>\n",
       "      <td>1.455486</td>\n",
       "      <td>-0.128889</td>\n",
       "      <td>-0.788440</td>\n",
       "      <td>0.381879</td>\n",
       "      <td>0.022924</td>\n",
       "      <td>0.543938</td>\n",
       "      <td>-0.070586</td>\n",
       "      <td>-0.623824</td>\n",
       "      <td>-0.382842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008888</td>\n",
       "      <td>0.031512</td>\n",
       "      <td>2.580178</td>\n",
       "      <td>-0.813275</td>\n",
       "      <td>-0.418657</td>\n",
       "      <td>-0.572518</td>\n",
       "      <td>-0.936024</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 1027 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "201601  1.287487 -0.688955 -0.794426 -1.238838  1.239369  1.784700 -0.000341   \n",
       "201602 -1.399851 -0.211775  1.341302  0.132593 -0.097550  0.159015 -1.474547   \n",
       "201603 -0.405975  0.289439 -0.377020 -0.355364 -1.054876  0.712196  0.927682   \n",
       "201604  0.844463 -1.315463  2.082394  2.693551 -1.234441  1.570999  0.279815   \n",
       "201605 -0.541275  0.475828  0.136089  0.335247  1.387429  0.863202 -1.643587   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "201848 -0.177821  0.800357  0.158949  2.573438  1.615337 -0.998008  1.096824   \n",
       "201849 -0.306444  1.308680  1.067536 -0.931025 -1.046062  2.075529 -0.501223   \n",
       "201850 -0.151392  0.071449  0.356428  0.259774 -0.383608  1.065443  0.450759   \n",
       "201851 -0.793142 -0.539722 -1.165816 -0.199017  2.244849  0.917043 -0.467799   \n",
       "201852 -0.393870  1.455486 -0.128889 -0.788440  0.381879  0.022924  0.543938   \n",
       "\n",
       "               7         8         9  ...      1017      1018      1019  \\\n",
       "201601  0.525795  0.363034  0.825218  ... -0.439056  0.675143 -1.017167   \n",
       "201602 -1.294940  1.222341 -0.381582  ... -0.420181 -1.341189 -0.138499   \n",
       "201603 -0.470455 -0.252064  1.062808  ... -0.587504  0.340662  0.299123   \n",
       "201604  0.831815 -0.229177 -0.052932  ...  0.959280 -0.753616  1.713913   \n",
       "201605 -0.673929 -0.331307 -1.289601  ... -0.362812 -0.104197 -0.509349   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "201848 -0.023870 -0.667530 -1.929526  ...  0.955204  0.006918  0.715542   \n",
       "201849 -2.267342  0.095569 -0.845871  ... -0.086890  0.917567  0.631528   \n",
       "201850  0.322183 -1.307717 -0.181305  ... -0.277678  0.032450 -0.329121   \n",
       "201851  0.353362  1.053764  0.443968  ... -1.308614 -1.632518  1.059085   \n",
       "201852 -0.070586 -0.623824 -0.382842  ...  0.008888  0.031512  2.580178   \n",
       "\n",
       "            1020      1021      1022      1023  0  1  2  \n",
       "201601 -0.206480 -0.043412 -1.014832 -1.435265  1  0  0  \n",
       "201602 -1.804684 -0.662659  0.475712  0.201907  0  1  0  \n",
       "201603  0.405674 -2.638784  0.780803 -1.659373  0  0  1  \n",
       "201604  1.536158 -1.955070  0.051035 -1.663397  1  0  0  \n",
       "201605  0.104454 -3.172053  0.055130  0.444714  1  0  0  \n",
       "...          ...       ...       ...       ... .. .. ..  \n",
       "201848 -0.870650 -0.205803  0.835786  1.692061  1  0  0  \n",
       "201849 -2.004170  0.267849  1.151415 -1.051147  0  0  1  \n",
       "201850 -0.322632 -1.898407 -0.602611 -0.267056  0  1  0  \n",
       "201851  1.047949 -2.762428 -0.955669  0.913588  1  0  0  \n",
       "201852 -0.813275 -0.418657 -0.572518 -0.936024  1  0  0  \n",
       "\n",
       "[156 rows x 1027 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the two dataframes based on the date values\n",
    "dengue_df = features_df.merge(labels_df, how='inner', left_index=True, right_index=True)\n",
    "dengue_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ac6c60",
   "metadata": {},
   "source": [
    "### Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab9c8438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, train_percentage = 80):\n",
    "    # We need a sequence so we can't split randomly\n",
    "    # To divide into Train and test we have to calculate the train percentage of the dataset:\n",
    "    size = df.shape[0]\n",
    "    split = int(size*(train_percentage/100))\n",
    "    \n",
    "    \"\"\" Train \"\"\"\n",
    "    # We will train with 1st percentage % of data and test with the rest\n",
    "    train_df = df.iloc[:split,:] ## percentage % train\n",
    "    \n",
    "    \"\"\" Test \"\"\"\n",
    "    test_df = df.iloc[split:,:] # 100 - percentage % test\n",
    "    \n",
    "    print(f'The train shape is: {train_df.shape}')\n",
    "    print(f'The test shape is: {test_df.shape}')\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ee6ae77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train shape is: (124, 1027)\n",
      "The test shape is: (32, 1027)\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(dengue_df, train_percentage = 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bd65e0",
   "metadata": {},
   "source": [
    "### Normalize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74ef3e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize train data and create the scaler\n",
    "def normalize_train_features(df, feature_range=(-1, 1), n_labels=None):\n",
    "    \n",
    "    if n_labels:\n",
    "        n_features = df.shape[1] - n_labels\n",
    "    \n",
    "    scalers = {}\n",
    "    # For each column in the dataframe\n",
    "    for i, column in enumerate(df.columns):\n",
    "        if n_labels:\n",
    "            if i >= n_features:\n",
    "                break\n",
    "        # Get values of the column\n",
    "        values = df[column].values.reshape(-1,1)\n",
    "        # Generate a new scaler\n",
    "        scaler = MinMaxScaler(feature_range=feature_range)\n",
    "        # Fit the scaler just for that column\n",
    "        scaled_column = scaler.fit_transform(values)\n",
    "        # Add the scaled column to the dataframe\n",
    "        scaled_column = np.reshape(scaled_column, len(scaled_column))\n",
    "        df[column] = scaled_column\n",
    "        \n",
    "        # Save the scaler of the column\n",
    "        scalers['scaler_' + column] = scaler\n",
    "        \n",
    "    print(f' Min values are: ')\n",
    "    print(df.min())\n",
    "    print(f' Max values are: ')\n",
    "    print(df.max())\n",
    "        \n",
    "    return df, scalers\n",
    "\n",
    "\n",
    "\"\"\" If you want to use the same scaler used in train, you can use this function\"\"\"\n",
    "def normalize_test_features(df, scalers=None, n_labels=None):\n",
    "    \n",
    "    if not scalers:\n",
    "        raise TypeError(\"You should provide a list of scalers.\")\n",
    "    \n",
    "    if n_labels:\n",
    "        n_features = df.shape[1] - n_labels\n",
    "    \n",
    "    for i, column in enumerate(df.columns):\n",
    "        if n_labels:\n",
    "            if i >= n_features:\n",
    "                break\n",
    "        # Get values of the column\n",
    "        values = df[column].values.reshape(-1,1)\n",
    "        # Take the scaler of that column\n",
    "        scaler = scalers['scaler_' + column]\n",
    "        # Scale values\n",
    "        scaled_column = scaler.transform(values)\n",
    "        scaled_column = np.reshape(scaled_column,len(scaled_column))\n",
    "        # Add the scaled values to the df\n",
    "        df[column] = scaled_column\n",
    "        \n",
    "    print(f' Min values are: ')\n",
    "    print(df.min())\n",
    "    print(f' Max values are: ')\n",
    "    print(df.max())\n",
    "        \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b413861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Min values are: \n",
      "0      -1.0\n",
      "1      -1.0\n",
      "2      -1.0\n",
      "3      -1.0\n",
      "4      -1.0\n",
      "       ... \n",
      "1022   -1.0\n",
      "1023   -1.0\n",
      "0       0.0\n",
      "1       0.0\n",
      "2       0.0\n",
      "Length: 1027, dtype: float64\n",
      " Max values are: \n",
      "0       1.0\n",
      "1       1.0\n",
      "2       1.0\n",
      "3       1.0\n",
      "4       1.0\n",
      "       ... \n",
      "1022    1.0\n",
      "1023    1.0\n",
      "0       1.0\n",
      "1       1.0\n",
      "2       1.0\n",
      "Length: 1027, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201601</th>\n",
       "      <td>0.717415</td>\n",
       "      <td>-0.264619</td>\n",
       "      <td>-0.512345</td>\n",
       "      <td>-0.596061</td>\n",
       "      <td>0.474445</td>\n",
       "      <td>0.534150</td>\n",
       "      <td>-0.046372</td>\n",
       "      <td>-0.033960</td>\n",
       "      <td>0.317819</td>\n",
       "      <td>0.237751</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.131012</td>\n",
       "      <td>0.127058</td>\n",
       "      <td>-0.319972</td>\n",
       "      <td>0.037591</td>\n",
       "      <td>0.106643</td>\n",
       "      <td>-0.352494</td>\n",
       "      <td>-0.615821</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201602</th>\n",
       "      <td>-0.419614</td>\n",
       "      <td>-0.077807</td>\n",
       "      <td>0.419405</td>\n",
       "      <td>-0.042335</td>\n",
       "      <td>0.008382</td>\n",
       "      <td>-0.073435</td>\n",
       "      <td>-0.675073</td>\n",
       "      <td>-0.723629</td>\n",
       "      <td>0.606674</td>\n",
       "      <td>-0.262004</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.122372</td>\n",
       "      <td>-0.760683</td>\n",
       "      <td>-0.018953</td>\n",
       "      <td>-0.522950</td>\n",
       "      <td>-0.092673</td>\n",
       "      <td>0.164985</td>\n",
       "      <td>0.116053</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201603</th>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.118415</td>\n",
       "      <td>-0.330244</td>\n",
       "      <td>-0.239351</td>\n",
       "      <td>-0.325351</td>\n",
       "      <td>0.133311</td>\n",
       "      <td>0.349401</td>\n",
       "      <td>-0.411326</td>\n",
       "      <td>0.111055</td>\n",
       "      <td>0.336141</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.198964</td>\n",
       "      <td>-0.020205</td>\n",
       "      <td>0.130970</td>\n",
       "      <td>0.252293</td>\n",
       "      <td>-0.728723</td>\n",
       "      <td>0.270905</td>\n",
       "      <td>-0.716005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201604</th>\n",
       "      <td>0.529969</td>\n",
       "      <td>-0.509892</td>\n",
       "      <td>0.742719</td>\n",
       "      <td>0.991672</td>\n",
       "      <td>-0.387949</td>\n",
       "      <td>0.454282</td>\n",
       "      <td>0.073106</td>\n",
       "      <td>0.081956</td>\n",
       "      <td>0.118748</td>\n",
       "      <td>-0.125905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509073</td>\n",
       "      <td>-0.501989</td>\n",
       "      <td>0.615657</td>\n",
       "      <td>0.648789</td>\n",
       "      <td>-0.508657</td>\n",
       "      <td>0.017548</td>\n",
       "      <td>-0.717804</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201605</th>\n",
       "      <td>-0.056345</td>\n",
       "      <td>0.191385</td>\n",
       "      <td>-0.106391</td>\n",
       "      <td>0.039488</td>\n",
       "      <td>0.526060</td>\n",
       "      <td>0.189748</td>\n",
       "      <td>-0.747163</td>\n",
       "      <td>-0.488399</td>\n",
       "      <td>0.084417</td>\n",
       "      <td>-0.638029</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096112</td>\n",
       "      <td>-0.216066</td>\n",
       "      <td>-0.146001</td>\n",
       "      <td>0.146645</td>\n",
       "      <td>-0.900364</td>\n",
       "      <td>0.018970</td>\n",
       "      <td>0.224596</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1027 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "201601  0.717415 -0.264619 -0.512345 -0.596061  0.474445  0.534150 -0.046372   \n",
       "201602 -0.419614 -0.077807  0.419405 -0.042335  0.008382 -0.073435 -0.675073   \n",
       "201603  0.000901  0.118415 -0.330244 -0.239351 -0.325351  0.133311  0.349401   \n",
       "201604  0.529969 -0.509892  0.742719  0.991672 -0.387949  0.454282  0.073106   \n",
       "201605 -0.056345  0.191385 -0.106391  0.039488  0.526060  0.189748 -0.747163   \n",
       "\n",
       "               7         8         9  ...      1017      1018      1019  \\\n",
       "201601 -0.033960  0.317819  0.237751  ... -0.131012  0.127058 -0.319972   \n",
       "201602 -0.723629  0.606674 -0.262004  ... -0.122372 -0.760683 -0.018953   \n",
       "201603 -0.411326  0.111055  0.336141  ... -0.198964 -0.020205  0.130970   \n",
       "201604  0.081956  0.118748 -0.125905  ...  0.509073 -0.501989  0.615657   \n",
       "201605 -0.488399  0.084417 -0.638029  ... -0.096112 -0.216066 -0.146001   \n",
       "\n",
       "            1020      1021      1022      1023  0  1  2  \n",
       "201601  0.037591  0.106643 -0.352494 -0.615821  1  0  0  \n",
       "201602 -0.522950 -0.092673  0.164985  0.116053  0  1  0  \n",
       "201603  0.252293 -0.728723  0.270905 -0.716005  0  0  1  \n",
       "201604  0.648789 -0.508657  0.017548 -0.717804  1  0  0  \n",
       "201605  0.146645 -0.900364  0.018970  0.224596  1  0  0  \n",
       "\n",
       "[5 rows x 1027 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_range = (-1, 1)\n",
    "\n",
    "# Scale train:\n",
    "train_df, scalers = normalize_train_features(train_df, feature_range=feature_range, n_labels=n_labels)\n",
    "\n",
    "#print(f'The scalers are: {scalers}')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42742e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Min values are: \n",
      "0      -0.611774\n",
      "1      -0.698647\n",
      "2      -1.492308\n",
      "3      -0.577689\n",
      "4      -0.528444\n",
      "          ...   \n",
      "1022   -0.468700\n",
      "1023   -1.009303\n",
      "0       0.000000\n",
      "1       0.000000\n",
      "2       0.000000\n",
      "Length: 1027, dtype: float64\n",
      " Max values are: \n",
      "0       0.798543\n",
      "1       0.992657\n",
      "2       0.376680\n",
      "3       0.943176\n",
      "4       0.824965\n",
      "          ...   \n",
      "1022    0.451219\n",
      "1023    0.782204\n",
      "0       1.000000\n",
      "1       1.000000\n",
      "2       1.000000\n",
      "Length: 1027, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201821</th>\n",
       "      <td>0.084599</td>\n",
       "      <td>0.542881</td>\n",
       "      <td>-0.384070</td>\n",
       "      <td>-0.080906</td>\n",
       "      <td>0.138302</td>\n",
       "      <td>0.078038</td>\n",
       "      <td>-0.007716</td>\n",
       "      <td>-0.031384</td>\n",
       "      <td>-0.545694</td>\n",
       "      <td>-0.072470</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.699482</td>\n",
       "      <td>0.136318</td>\n",
       "      <td>0.328906</td>\n",
       "      <td>0.342614</td>\n",
       "      <td>0.063277</td>\n",
       "      <td>0.219823</td>\n",
       "      <td>0.294464</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201822</th>\n",
       "      <td>0.798543</td>\n",
       "      <td>0.992657</td>\n",
       "      <td>-0.493325</td>\n",
       "      <td>-0.416277</td>\n",
       "      <td>0.266510</td>\n",
       "      <td>-0.591903</td>\n",
       "      <td>0.565659</td>\n",
       "      <td>-0.179126</td>\n",
       "      <td>0.237211</td>\n",
       "      <td>0.382436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201944</td>\n",
       "      <td>-0.673409</td>\n",
       "      <td>-0.036940</td>\n",
       "      <td>-0.021246</td>\n",
       "      <td>0.060466</td>\n",
       "      <td>0.102064</td>\n",
       "      <td>0.112100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201823</th>\n",
       "      <td>0.247549</td>\n",
       "      <td>-0.247999</td>\n",
       "      <td>0.253891</td>\n",
       "      <td>0.300498</td>\n",
       "      <td>0.187533</td>\n",
       "      <td>-0.202666</td>\n",
       "      <td>-0.067352</td>\n",
       "      <td>-0.504047</td>\n",
       "      <td>0.361369</td>\n",
       "      <td>0.378615</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.290135</td>\n",
       "      <td>0.185387</td>\n",
       "      <td>0.484507</td>\n",
       "      <td>-0.645408</td>\n",
       "      <td>-0.595917</td>\n",
       "      <td>-0.186724</td>\n",
       "      <td>-0.197858</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201824</th>\n",
       "      <td>0.420624</td>\n",
       "      <td>0.373608</td>\n",
       "      <td>-0.799224</td>\n",
       "      <td>0.511320</td>\n",
       "      <td>-0.279726</td>\n",
       "      <td>-0.603021</td>\n",
       "      <td>0.154349</td>\n",
       "      <td>-0.543294</td>\n",
       "      <td>0.365547</td>\n",
       "      <td>0.051451</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053085</td>\n",
       "      <td>-0.549938</td>\n",
       "      <td>0.159301</td>\n",
       "      <td>0.492040</td>\n",
       "      <td>-0.004100</td>\n",
       "      <td>0.447210</td>\n",
       "      <td>-0.103205</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201825</th>\n",
       "      <td>0.155971</td>\n",
       "      <td>-0.698647</td>\n",
       "      <td>0.350023</td>\n",
       "      <td>-0.577689</td>\n",
       "      <td>0.674053</td>\n",
       "      <td>-0.199004</td>\n",
       "      <td>0.069916</td>\n",
       "      <td>-0.071021</td>\n",
       "      <td>0.025623</td>\n",
       "      <td>-0.410628</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.164270</td>\n",
       "      <td>0.157324</td>\n",
       "      <td>-0.432406</td>\n",
       "      <td>0.355685</td>\n",
       "      <td>0.165775</td>\n",
       "      <td>0.352219</td>\n",
       "      <td>0.450566</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1027 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "201821  0.084599  0.542881 -0.384070 -0.080906  0.138302  0.078038 -0.007716   \n",
       "201822  0.798543  0.992657 -0.493325 -0.416277  0.266510 -0.591903  0.565659   \n",
       "201823  0.247549 -0.247999  0.253891  0.300498  0.187533 -0.202666 -0.067352   \n",
       "201824  0.420624  0.373608 -0.799224  0.511320 -0.279726 -0.603021  0.154349   \n",
       "201825  0.155971 -0.698647  0.350023 -0.577689  0.674053 -0.199004  0.069916   \n",
       "\n",
       "               7         8         9  ...      1017      1018      1019  \\\n",
       "201821 -0.031384 -0.545694 -0.072470  ... -0.699482  0.136318  0.328906   \n",
       "201822 -0.179126  0.237211  0.382436  ...  0.201944 -0.673409 -0.036940   \n",
       "201823 -0.504047  0.361369  0.378615  ... -0.290135  0.185387  0.484507   \n",
       "201824 -0.543294  0.365547  0.051451  ... -0.053085 -0.549938  0.159301   \n",
       "201825 -0.071021  0.025623 -0.410628  ... -0.164270  0.157324 -0.432406   \n",
       "\n",
       "            1020      1021      1022      1023  0  1  2  \n",
       "201821  0.342614  0.063277  0.219823  0.294464  1  0  0  \n",
       "201822 -0.021246  0.060466  0.102064  0.112100  1  0  0  \n",
       "201823 -0.645408 -0.595917 -0.186724 -0.197858  1  0  0  \n",
       "201824  0.492040 -0.004100  0.447210 -0.103205  1  0  0  \n",
       "201825  0.355685  0.165775  0.352219  0.450566  1  0  0  \n",
       "\n",
       "[5 rows x 1027 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale test:\n",
    "test_df = normalize_test_features(test_df, scalers=scalers, n_labels=n_labels)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c6d375",
   "metadata": {},
   "source": [
    "### Prepare data for time series supervised learning (function to create sliding window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a0c58bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for time series\n",
    "\n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97412050",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-10)</th>\n",
       "      <th>var2(t-10)</th>\n",
       "      <th>var3(t-10)</th>\n",
       "      <th>var4(t-10)</th>\n",
       "      <th>var5(t-10)</th>\n",
       "      <th>var6(t-10)</th>\n",
       "      <th>var7(t-10)</th>\n",
       "      <th>var8(t-10)</th>\n",
       "      <th>var9(t-10)</th>\n",
       "      <th>var10(t-10)</th>\n",
       "      <th>...</th>\n",
       "      <th>var1018(t)</th>\n",
       "      <th>var1019(t)</th>\n",
       "      <th>var1020(t)</th>\n",
       "      <th>var1021(t)</th>\n",
       "      <th>var1022(t)</th>\n",
       "      <th>var1023(t)</th>\n",
       "      <th>var1024(t)</th>\n",
       "      <th>var1025(t)</th>\n",
       "      <th>var1026(t)</th>\n",
       "      <th>var1027(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201611</th>\n",
       "      <td>0.717415</td>\n",
       "      <td>-0.264619</td>\n",
       "      <td>-0.512345</td>\n",
       "      <td>-0.596061</td>\n",
       "      <td>0.474445</td>\n",
       "      <td>0.534150</td>\n",
       "      <td>-0.046372</td>\n",
       "      <td>-0.033960</td>\n",
       "      <td>0.317819</td>\n",
       "      <td>0.237751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.148737</td>\n",
       "      <td>-0.063537</td>\n",
       "      <td>0.342771</td>\n",
       "      <td>-0.026400</td>\n",
       "      <td>0.267312</td>\n",
       "      <td>-0.061181</td>\n",
       "      <td>-0.022407</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201612</th>\n",
       "      <td>-0.419614</td>\n",
       "      <td>-0.077807</td>\n",
       "      <td>0.419405</td>\n",
       "      <td>-0.042335</td>\n",
       "      <td>0.008382</td>\n",
       "      <td>-0.073435</td>\n",
       "      <td>-0.675073</td>\n",
       "      <td>-0.723629</td>\n",
       "      <td>0.606674</td>\n",
       "      <td>-0.262004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.515570</td>\n",
       "      <td>-0.123022</td>\n",
       "      <td>-0.496992</td>\n",
       "      <td>0.268676</td>\n",
       "      <td>0.079583</td>\n",
       "      <td>0.241669</td>\n",
       "      <td>-0.595634</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201613</th>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.118415</td>\n",
       "      <td>-0.330244</td>\n",
       "      <td>-0.239351</td>\n",
       "      <td>-0.325351</td>\n",
       "      <td>0.133311</td>\n",
       "      <td>0.349401</td>\n",
       "      <td>-0.411326</td>\n",
       "      <td>0.111055</td>\n",
       "      <td>0.336141</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.126848</td>\n",
       "      <td>0.661713</td>\n",
       "      <td>0.153685</td>\n",
       "      <td>0.229164</td>\n",
       "      <td>-0.463973</td>\n",
       "      <td>0.053713</td>\n",
       "      <td>-0.975594</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201614</th>\n",
       "      <td>0.529969</td>\n",
       "      <td>-0.509892</td>\n",
       "      <td>0.742719</td>\n",
       "      <td>0.991672</td>\n",
       "      <td>-0.387949</td>\n",
       "      <td>0.454282</td>\n",
       "      <td>0.073106</td>\n",
       "      <td>0.081956</td>\n",
       "      <td>0.118748</td>\n",
       "      <td>-0.125905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285252</td>\n",
       "      <td>-0.459350</td>\n",
       "      <td>0.118487</td>\n",
       "      <td>0.717821</td>\n",
       "      <td>0.011011</td>\n",
       "      <td>-0.017436</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201615</th>\n",
       "      <td>-0.056345</td>\n",
       "      <td>0.191385</td>\n",
       "      <td>-0.106391</td>\n",
       "      <td>0.039488</td>\n",
       "      <td>0.526060</td>\n",
       "      <td>0.189748</td>\n",
       "      <td>-0.747163</td>\n",
       "      <td>-0.488399</td>\n",
       "      <td>0.084417</td>\n",
       "      <td>-0.638029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.502082</td>\n",
       "      <td>-0.235513</td>\n",
       "      <td>0.015692</td>\n",
       "      <td>0.535678</td>\n",
       "      <td>0.225521</td>\n",
       "      <td>0.046232</td>\n",
       "      <td>0.145397</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201816</th>\n",
       "      <td>0.161418</td>\n",
       "      <td>0.059350</td>\n",
       "      <td>-0.407217</td>\n",
       "      <td>-0.322475</td>\n",
       "      <td>0.280339</td>\n",
       "      <td>0.312166</td>\n",
       "      <td>0.115440</td>\n",
       "      <td>-0.833810</td>\n",
       "      <td>-0.187396</td>\n",
       "      <td>-0.351217</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353747</td>\n",
       "      <td>0.397505</td>\n",
       "      <td>0.451361</td>\n",
       "      <td>-0.138578</td>\n",
       "      <td>-0.306785</td>\n",
       "      <td>0.371796</td>\n",
       "      <td>-0.192488</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201817</th>\n",
       "      <td>0.887821</td>\n",
       "      <td>-0.180743</td>\n",
       "      <td>-0.405007</td>\n",
       "      <td>-0.110293</td>\n",
       "      <td>-0.760965</td>\n",
       "      <td>0.572115</td>\n",
       "      <td>-0.546911</td>\n",
       "      <td>-0.084733</td>\n",
       "      <td>0.133753</td>\n",
       "      <td>-0.301270</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.207863</td>\n",
       "      <td>0.403494</td>\n",
       "      <td>0.488648</td>\n",
       "      <td>-0.299530</td>\n",
       "      <td>-0.063334</td>\n",
       "      <td>0.803492</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201818</th>\n",
       "      <td>0.554046</td>\n",
       "      <td>0.137046</td>\n",
       "      <td>0.084558</td>\n",
       "      <td>0.011125</td>\n",
       "      <td>-0.421474</td>\n",
       "      <td>-0.790012</td>\n",
       "      <td>-0.537559</td>\n",
       "      <td>0.433995</td>\n",
       "      <td>0.491965</td>\n",
       "      <td>0.484942</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.160777</td>\n",
       "      <td>-0.014544</td>\n",
       "      <td>0.017891</td>\n",
       "      <td>0.102530</td>\n",
       "      <td>0.360620</td>\n",
       "      <td>-0.128165</td>\n",
       "      <td>-0.316256</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201819</th>\n",
       "      <td>0.149763</td>\n",
       "      <td>-0.577400</td>\n",
       "      <td>-0.319449</td>\n",
       "      <td>-0.402680</td>\n",
       "      <td>-0.085460</td>\n",
       "      <td>-0.189519</td>\n",
       "      <td>-0.881927</td>\n",
       "      <td>0.317386</td>\n",
       "      <td>-0.189051</td>\n",
       "      <td>0.544778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.255767</td>\n",
       "      <td>-0.741897</td>\n",
       "      <td>0.086524</td>\n",
       "      <td>0.102446</td>\n",
       "      <td>0.620181</td>\n",
       "      <td>0.121715</td>\n",
       "      <td>0.747221</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201820</th>\n",
       "      <td>0.588307</td>\n",
       "      <td>0.007995</td>\n",
       "      <td>0.317992</td>\n",
       "      <td>-0.042756</td>\n",
       "      <td>0.269775</td>\n",
       "      <td>-0.396270</td>\n",
       "      <td>-0.482307</td>\n",
       "      <td>-0.231678</td>\n",
       "      <td>0.376478</td>\n",
       "      <td>0.264857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.502141</td>\n",
       "      <td>-0.403143</td>\n",
       "      <td>-0.062169</td>\n",
       "      <td>-0.114325</td>\n",
       "      <td>-0.087839</td>\n",
       "      <td>0.094620</td>\n",
       "      <td>-0.479982</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 11297 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        var1(t-10)  var2(t-10)  var3(t-10)  var4(t-10)  var5(t-10)  \\\n",
       "201611    0.717415   -0.264619   -0.512345   -0.596061    0.474445   \n",
       "201612   -0.419614   -0.077807    0.419405   -0.042335    0.008382   \n",
       "201613    0.000901    0.118415   -0.330244   -0.239351   -0.325351   \n",
       "201614    0.529969   -0.509892    0.742719    0.991672   -0.387949   \n",
       "201615   -0.056345    0.191385   -0.106391    0.039488    0.526060   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "201816    0.161418    0.059350   -0.407217   -0.322475    0.280339   \n",
       "201817    0.887821   -0.180743   -0.405007   -0.110293   -0.760965   \n",
       "201818    0.554046    0.137046    0.084558    0.011125   -0.421474   \n",
       "201819    0.149763   -0.577400   -0.319449   -0.402680   -0.085460   \n",
       "201820    0.588307    0.007995    0.317992   -0.042756    0.269775   \n",
       "\n",
       "        var6(t-10)  var7(t-10)  var8(t-10)  var9(t-10)  var10(t-10)  ...  \\\n",
       "201611    0.534150   -0.046372   -0.033960    0.317819     0.237751  ...   \n",
       "201612   -0.073435   -0.675073   -0.723629    0.606674    -0.262004  ...   \n",
       "201613    0.133311    0.349401   -0.411326    0.111055     0.336141  ...   \n",
       "201614    0.454282    0.073106    0.081956    0.118748    -0.125905  ...   \n",
       "201615    0.189748   -0.747163   -0.488399    0.084417    -0.638029  ...   \n",
       "...            ...         ...         ...         ...          ...  ...   \n",
       "201816    0.312166    0.115440   -0.833810   -0.187396    -0.351217  ...   \n",
       "201817    0.572115   -0.546911   -0.084733    0.133753    -0.301270  ...   \n",
       "201818   -0.790012   -0.537559    0.433995    0.491965     0.484942  ...   \n",
       "201819   -0.189519   -0.881927    0.317386   -0.189051     0.544778  ...   \n",
       "201820   -0.396270   -0.482307   -0.231678    0.376478     0.264857  ...   \n",
       "\n",
       "        var1018(t)  var1019(t)  var1020(t)  var1021(t)  var1022(t)  \\\n",
       "201611    0.148737   -0.063537    0.342771   -0.026400    0.267312   \n",
       "201612    0.515570   -0.123022   -0.496992    0.268676    0.079583   \n",
       "201613   -0.126848    0.661713    0.153685    0.229164   -0.463973   \n",
       "201614    0.285252   -0.459350    0.118487    0.717821    0.011011   \n",
       "201615    0.502082   -0.235513    0.015692    0.535678    0.225521   \n",
       "...            ...         ...         ...         ...         ...   \n",
       "201816    0.353747    0.397505    0.451361   -0.138578   -0.306785   \n",
       "201817   -1.000000   -0.207863    0.403494    0.488648   -0.299530   \n",
       "201818   -0.160777   -0.014544    0.017891    0.102530    0.360620   \n",
       "201819    0.255767   -0.741897    0.086524    0.102446    0.620181   \n",
       "201820    0.502141   -0.403143   -0.062169   -0.114325   -0.087839   \n",
       "\n",
       "        var1023(t)  var1024(t)  var1025(t)  var1026(t)  var1027(t)  \n",
       "201611   -0.061181   -0.022407           0           1           0  \n",
       "201612    0.241669   -0.595634           0           1           0  \n",
       "201613    0.053713   -0.975594           0           1           0  \n",
       "201614   -0.017436    1.000000           0           0           1  \n",
       "201615    0.046232    0.145397           0           1           0  \n",
       "...            ...         ...         ...         ...         ...  \n",
       "201816    0.371796   -0.192488           1           0           0  \n",
       "201817   -0.063334    0.803492           1           0           0  \n",
       "201818   -0.128165   -0.316256           1           0           0  \n",
       "201819    0.121715    0.747221           1           0           0  \n",
       "201820    0.094620   -0.479982           1           0           0  \n",
       "\n",
       "[114 rows x 11297 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# length of window\n",
    "days = 10\n",
    "\n",
    "# frame as supervised learning\n",
    "train = series_to_supervised(train_df, n_in=days)\n",
    "test = series_to_supervised(test_df, n_in=days)\n",
    "\n",
    "DataFrame(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0016c1",
   "metadata": {},
   "source": [
    "### Features and Labels Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4976bb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_labels_set(timeseries_data, original_df, n_labels):\n",
    "    \n",
    "    \"\"\" Features \"\"\"\n",
    "    # We define the number of features as (features and labels)\n",
    "    n_features = original_df.shape[1]\n",
    "\n",
    "    # The features to train the model will be all except the values of the actual week \n",
    "    # We can't use other variables in week t because whe need to resample a a 3D Array\n",
    "    features_set = DataFrame(timeseries_data.values[:,:-n_features])\n",
    "    # Convert pandas data frame to np.array to reshape as 3D Array\n",
    "    features_set = features_set.to_numpy()\n",
    "    print(f'The shape of the features is {features_set.shape}')\n",
    "    \n",
    "    \"\"\" Labels \"\"\"\n",
    "    # We will use labels in last week \n",
    "    labels_set = DataFrame(timeseries_data.values[:,-n_labels:])\n",
    "    # Convert pandas data frame to np.array\n",
    "    labels_set = labels_set.to_numpy()\n",
    "    print(f'The shape of the labels is {labels_set.shape}')\n",
    "    \n",
    "    return features_set, labels_set, n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a190e92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "The shape of the features is (114, 10270)\n",
      "The shape of the labels is (114, 3)\n",
      "Test:\n",
      "The shape of the features is (22, 10270)\n",
      "The shape of the labels is (22, 3)\n"
     ]
    }
   ],
   "source": [
    "# Train features and labels set\n",
    "print('Train:')\n",
    "train_X, train_y, n_features = features_labels_set(timeseries_data=train, original_df=dengue_df, n_labels=n_labels)\n",
    "\n",
    "# Test features and labels set\n",
    "print('Test:')\n",
    "test_X, test_y, n_features = features_labels_set(timeseries_data=test, original_df=dengue_df, n_labels=n_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe244036",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "059c94b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_tensor(train_X, test_X, n_features):\n",
    "    print('The initial shapes are:')\n",
    "    print(f'The train shape is {train_X.shape}')\n",
    "    print(f'The test shape is {test_X.shape}')\n",
    "    \n",
    "    # reshape input to be 3D [samples, timesteps, features]\n",
    "    train_X = train_X.reshape((train_X.shape[0], days, n_features))\n",
    "    test_X = test_X.reshape((test_X.shape[0], days, n_features))\n",
    "    \n",
    "    print('-----------------------')\n",
    "    print('The Final shapes are:')\n",
    "    print(f'The train shape is {train_X.shape}')\n",
    "    print(f'The test shape is {test_X.shape}')\n",
    "    \n",
    "    return train_X, test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d0b7878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initial shapes are:\n",
      "The train shape is (114, 10270)\n",
      "The test shape is (22, 10270)\n",
      "-----------------------\n",
      "The Final shapes are:\n",
      "The train shape is (114, 10, 1027)\n",
      "The test shape is (22, 10, 1027)\n"
     ]
    }
   ],
   "source": [
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X, test_X = reshape_tensor(train_X, test_X, n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d79596",
   "metadata": {},
   "source": [
    "# Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c576fd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Seed\n",
    "#tf.random.set_seed(0)\n",
    "\n",
    "def create_model():\n",
    "    # design network\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(120, dropout=0.1, input_shape=(train_X.shape[1], train_X.shape[2]), return_sequences=True))\n",
    "    model.add(LSTM(240, dropout=0.1, input_shape=(train_X.shape[1], 120)))\n",
    "    model.add(Dense(60))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    # Compile the model:\n",
    "    opt = keras.optimizers.Adam()\n",
    "    metric = tf.keras.metrics.AUC(name='auc', multi_label=True, num_labels=3)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=metric)\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13877ea",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f045928",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# EarlyStopping:\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=20, \n",
    "        verbose=1, mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "292bf59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zeros: 113, ones: 20, twos: 23, total: 156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 1.3805309734513274, 1: 7.8, 2: 6.782608695652174}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Imbalanced data\n",
    "n_zeros = (labels_df_orig.to_numpy() == 0).sum()\n",
    "n_ones = (labels_df_orig.to_numpy() == 1).sum()\n",
    "n_twos = (labels_df_orig.to_numpy() == 2).sum()\n",
    "n_total = n_zeros + n_ones + n_twos\n",
    "\n",
    "weights = {0: n_total/n_zeros, 1: n_total/n_ones, 2: n_total/n_twos}\n",
    "print(f'zeros: {n_zeros}, ones: {n_ones}, twos: {n_twos}, total: {n_total}')\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "78d30c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit network\n",
    "def train_model(model, monitor, weights, plot=None, epochs=20):\n",
    "    if monitor and weights:\n",
    "        history = model.fit(train_X, train_y, epochs=epochs, batch_size=16, validation_data=(test_X, test_y), verbose=2, shuffle=False, callbacks=[monitor], class_weight=weights)\n",
    "    elif monitor:\n",
    "        history = model.fit(train_X, train_y, epochs=epochs, batch_size=16, validation_data=(test_X, test_y), verbose=2, shuffle=False, callbacks=[monitor])\n",
    "    elif weights:\n",
    "        history = model.fit(train_X, train_y, epochs=epochs, batch_size=16, validation_data=(test_X, test_y), verbose=2, shuffle=False, class_weight=weights)\n",
    "    else:\n",
    "        history = model.fit(train_X, train_y, epochs=epochs, batch_size=16, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "    \n",
    "    if plot:\n",
    "        # plot history\n",
    "        plt.plot(history.history['loss'], label='train')\n",
    "        plt.plot(history.history['val_loss'], label='validation')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae199cf",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72716d36",
   "metadata": {},
   "source": [
    "# AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e64f7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also evaluate or predict on a dataset.\n",
    "def evaluate(model, verbose = None):\n",
    "    if verbose:\n",
    "        print('Evaluate: ')\n",
    "    result = model.evaluate(test_X, test_y)\n",
    "    if verbose:\n",
    "        for i, metric in enumerate(model.metrics_names):\n",
    "            print(f'{metric}: {result[i]}')\n",
    "\n",
    "    auc = result[1]\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27f0995",
   "metadata": {},
   "source": [
    "# Calculate Mean and SD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a90ba6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_std(weights):\n",
    "    aucs = []\n",
    "    for i in range(5):\n",
    "        model = create_model()\n",
    "        train_model(model=model, monitor=monitor, weights=weights)\n",
    "        auc = evaluate(model=model)\n",
    "        aucs.append(auc)\n",
    "\n",
    "    mean = np.array(aucs).mean()\n",
    "    std = np.array(aucs).std()\n",
    "    print(f'The mean AUC is {mean} and SD is {std}')\n",
    "    \n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5296b0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "8/8 - 3s - loss: 0.9461 - auc: 0.5870 - val_loss: 0.6002 - val_auc: 0.6975\n",
      "Epoch 2/20\n",
      "8/8 - 0s - loss: 0.9976 - auc: 0.4684 - val_loss: 0.7408 - val_auc: 0.7882\n",
      "Epoch 3/20\n",
      "8/8 - 0s - loss: 0.6291 - auc: 0.8587 - val_loss: 0.4927 - val_auc: 0.7234\n",
      "Epoch 4/20\n",
      "8/8 - 0s - loss: 0.5726 - auc: 0.8739 - val_loss: 0.4969 - val_auc: 0.6595\n",
      "Epoch 5/20\n",
      "8/8 - 0s - loss: 0.5106 - auc: 0.9001 - val_loss: 0.5419 - val_auc: 0.6678\n",
      "Epoch 6/20\n",
      "8/8 - 0s - loss: 0.4714 - auc: 0.9176 - val_loss: 0.4961 - val_auc: 0.6473\n",
      "Epoch 7/20\n",
      "8/8 - 0s - loss: 0.4383 - auc: 0.9218 - val_loss: 0.4951 - val_auc: 0.6377\n",
      "Epoch 8/20\n",
      "8/8 - 0s - loss: 0.3732 - auc: 0.9531 - val_loss: 0.6305 - val_auc: 0.5905\n",
      "Epoch 9/20\n",
      "8/8 - 0s - loss: 0.3305 - auc: 0.9666 - val_loss: 0.5620 - val_auc: 0.5617\n",
      "Epoch 10/20\n",
      "8/8 - 0s - loss: 0.4247 - auc: 0.9487 - val_loss: 0.6700 - val_auc: 0.5068\n",
      "Epoch 11/20\n",
      "8/8 - 0s - loss: 0.7497 - auc: 0.8993 - val_loss: 0.7800 - val_auc: 0.5734\n",
      "Epoch 12/20\n",
      "8/8 - 0s - loss: 0.5908 - auc: 0.8711 - val_loss: 0.5911 - val_auc: 0.6878\n",
      "Epoch 13/20\n",
      "8/8 - 0s - loss: 0.4173 - auc: 0.9698 - val_loss: 0.5073 - val_auc: 0.6804\n",
      "Epoch 14/20\n",
      "8/8 - 0s - loss: 0.3080 - auc: 0.9696 - val_loss: 0.5660 - val_auc: 0.7120\n",
      "Epoch 15/20\n",
      "8/8 - 0s - loss: 0.2560 - auc: 0.9821 - val_loss: 0.5746 - val_auc: 0.7271\n",
      "Epoch 16/20\n",
      "8/8 - 0s - loss: 0.1892 - auc: 0.9948 - val_loss: 0.7147 - val_auc: 0.7463\n",
      "Epoch 17/20\n",
      "8/8 - 0s - loss: 0.1489 - auc: 0.9975 - val_loss: 0.7879 - val_auc: 0.5759\n",
      "Epoch 18/20\n",
      "8/8 - 0s - loss: 0.1023 - auc: 0.9999 - val_loss: 1.1276 - val_auc: 0.5000\n",
      "Epoch 19/20\n",
      "8/8 - 0s - loss: 0.0716 - auc: 0.9999 - val_loss: 1.1114 - val_auc: 0.5000\n",
      "Epoch 20/20\n",
      "8/8 - 0s - loss: 0.0477 - auc: 1.0000 - val_loss: 1.3013 - val_auc: 0.5000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.3013 - auc: 0.5000\n",
      "Epoch 1/20\n",
      "8/8 - 3s - loss: 0.9252 - auc: 0.6153 - val_loss: 0.6438 - val_auc: 0.4321\n",
      "Epoch 2/20\n",
      "8/8 - 0s - loss: 1.0806 - auc: 0.4343 - val_loss: 0.8007 - val_auc: 0.4931\n",
      "Epoch 3/20\n",
      "8/8 - 0s - loss: 0.6509 - auc: 0.8779 - val_loss: 0.5612 - val_auc: 0.6600\n",
      "Epoch 4/20\n",
      "8/8 - 0s - loss: 0.5619 - auc: 0.8713 - val_loss: 0.4847 - val_auc: 0.7518\n",
      "Epoch 5/20\n",
      "8/8 - 0s - loss: 0.5178 - auc: 0.9014 - val_loss: 0.5325 - val_auc: 0.7084\n",
      "Epoch 6/20\n",
      "8/8 - 0s - loss: 0.4779 - auc: 0.9208 - val_loss: 0.4845 - val_auc: 0.6399\n",
      "Epoch 7/20\n",
      "8/8 - 0s - loss: 0.4341 - auc: 0.9306 - val_loss: 0.5035 - val_auc: 0.6341\n",
      "Epoch 8/20\n",
      "8/8 - 0s - loss: 0.3804 - auc: 0.9537 - val_loss: 0.5131 - val_auc: 0.6416\n",
      "Epoch 9/20\n",
      "8/8 - 0s - loss: 0.4038 - auc: 0.9501 - val_loss: 0.7211 - val_auc: 0.7026\n",
      "Epoch 10/20\n",
      "8/8 - 0s - loss: 0.5453 - auc: 0.9243 - val_loss: 0.5784 - val_auc: 0.7714\n",
      "Epoch 11/20\n",
      "8/8 - 0s - loss: 0.3838 - auc: 0.9524 - val_loss: 0.4761 - val_auc: 0.6132\n",
      "Epoch 12/20\n",
      "8/8 - 0s - loss: 0.3522 - auc: 0.9728 - val_loss: 0.5473 - val_auc: 0.7188\n",
      "Epoch 13/20\n",
      "8/8 - 0s - loss: 0.2840 - auc: 0.9780 - val_loss: 0.5522 - val_auc: 0.7459\n",
      "Epoch 14/20\n",
      "8/8 - 0s - loss: 0.2118 - auc: 0.9948 - val_loss: 0.5310 - val_auc: 0.7284\n",
      "Epoch 15/20\n",
      "8/8 - 0s - loss: 0.1441 - auc: 0.9987 - val_loss: 0.7619 - val_auc: 0.5206\n",
      "Epoch 16/20\n",
      "8/8 - 0s - loss: 0.0957 - auc: 0.9994 - val_loss: 0.9078 - val_auc: 0.4829\n",
      "Epoch 17/20\n",
      "8/8 - 0s - loss: 0.0556 - auc: 1.0000 - val_loss: 1.1548 - val_auc: 0.5000\n",
      "Epoch 18/20\n",
      "8/8 - 0s - loss: 0.0364 - auc: 1.0000 - val_loss: 1.3670 - val_auc: 0.5000\n",
      "Epoch 19/20\n",
      "8/8 - 0s - loss: 0.0170 - auc: 1.0000 - val_loss: 1.5162 - val_auc: 0.5000\n",
      "Epoch 20/20\n",
      "8/8 - 0s - loss: 0.0104 - auc: 1.0000 - val_loss: 1.5896 - val_auc: 0.5000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.5896 - auc: 0.5000\n",
      "Epoch 1/20\n",
      "8/8 - 3s - loss: 0.9315 - auc: 0.5707 - val_loss: 0.6502 - val_auc: 0.1160\n",
      "Epoch 2/20\n",
      "8/8 - 0s - loss: 1.0144 - auc: 0.4931 - val_loss: 0.7378 - val_auc: 0.3921\n",
      "Epoch 3/20\n",
      "8/8 - 0s - loss: 0.6406 - auc: 0.8539 - val_loss: 0.5650 - val_auc: 0.2643\n",
      "Epoch 4/20\n",
      "8/8 - 0s - loss: 0.5580 - auc: 0.8718 - val_loss: 0.5292 - val_auc: 0.2263\n",
      "Epoch 5/20\n",
      "8/8 - 0s - loss: 0.5212 - auc: 0.8992 - val_loss: 0.5582 - val_auc: 0.2689\n",
      "Epoch 6/20\n",
      "8/8 - 0s - loss: 0.4777 - auc: 0.9139 - val_loss: 0.5358 - val_auc: 0.2091\n",
      "Epoch 7/20\n",
      "8/8 - 0s - loss: 0.4334 - auc: 0.9301 - val_loss: 0.5575 - val_auc: 0.2889\n",
      "Epoch 8/20\n",
      "8/8 - 0s - loss: 0.3700 - auc: 0.9576 - val_loss: 0.6218 - val_auc: 0.3698\n",
      "Epoch 9/20\n",
      "8/8 - 0s - loss: 0.3239 - auc: 0.9711 - val_loss: 0.7407 - val_auc: 0.6697\n",
      "Epoch 10/20\n",
      "8/8 - 0s - loss: 0.4210 - auc: 0.9462 - val_loss: 0.7911 - val_auc: 0.3669\n",
      "Epoch 11/20\n",
      "8/8 - 0s - loss: 0.9086 - auc: 0.9102 - val_loss: 0.5462 - val_auc: 0.4818\n",
      "Epoch 12/20\n",
      "8/8 - 0s - loss: 0.4788 - auc: 0.9223 - val_loss: 0.5839 - val_auc: 0.4843\n",
      "Epoch 13/20\n",
      "8/8 - 0s - loss: 0.3416 - auc: 0.9738 - val_loss: 0.5191 - val_auc: 0.4489\n",
      "Epoch 14/20\n",
      "8/8 - 0s - loss: 0.3046 - auc: 0.9761 - val_loss: 0.5235 - val_auc: 0.5252\n",
      "Epoch 15/20\n",
      "8/8 - 0s - loss: 0.2267 - auc: 0.9919 - val_loss: 0.5480 - val_auc: 0.5194\n",
      "Epoch 16/20\n",
      "8/8 - 0s - loss: 0.1668 - auc: 0.9977 - val_loss: 0.6591 - val_auc: 0.5565\n",
      "Epoch 17/20\n",
      "8/8 - 0s - loss: 0.1252 - auc: 0.9987 - val_loss: 0.7779 - val_auc: 0.5644\n",
      "Epoch 18/20\n",
      "8/8 - 0s - loss: 0.0844 - auc: 0.9992 - val_loss: 0.9368 - val_auc: 0.4482\n",
      "Epoch 19/20\n",
      "8/8 - 0s - loss: 0.0543 - auc: 1.0000 - val_loss: 1.1235 - val_auc: 0.5000\n",
      "Epoch 20/20\n",
      "8/8 - 0s - loss: 0.0470 - auc: 1.0000 - val_loss: 1.1769 - val_auc: 0.5000\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.1769 - auc: 0.5000\n",
      "Epoch 1/20\n",
      "8/8 - 3s - loss: 0.9451 - auc: 0.5648 - val_loss: 0.6393 - val_auc: 0.6065\n",
      "Epoch 2/20\n",
      "8/8 - 0s - loss: 1.0409 - auc: 0.4296 - val_loss: 0.7526 - val_auc: 0.7318\n",
      "Epoch 3/20\n",
      "8/8 - 0s - loss: 0.6154 - auc: 0.8634 - val_loss: 0.5162 - val_auc: 0.8741\n",
      "Epoch 4/20\n",
      "8/8 - 0s - loss: 0.5601 - auc: 0.8749 - val_loss: 0.4922 - val_auc: 0.8712\n",
      "Epoch 5/20\n",
      "8/8 - 0s - loss: 0.4987 - auc: 0.9052 - val_loss: 0.5183 - val_auc: 0.8394\n",
      "Epoch 6/20\n",
      "8/8 - 0s - loss: 0.4595 - auc: 0.9190 - val_loss: 0.4764 - val_auc: 0.8694\n",
      "Epoch 7/20\n",
      "8/8 - 0s - loss: 0.4053 - auc: 0.9420 - val_loss: 0.4611 - val_auc: 0.8778\n",
      "Epoch 8/20\n",
      "8/8 - 0s - loss: 0.3515 - auc: 0.9546 - val_loss: 0.4834 - val_auc: 0.8389\n",
      "Epoch 9/20\n",
      "8/8 - 0s - loss: 0.4363 - auc: 0.9110 - val_loss: 0.4464 - val_auc: 0.8990\n",
      "Epoch 10/20\n",
      "8/8 - 0s - loss: 0.4201 - auc: 0.9358 - val_loss: 0.5635 - val_auc: 0.9049\n",
      "Epoch 11/20\n",
      "8/8 - 0s - loss: 0.4071 - auc: 0.9540 - val_loss: 0.4857 - val_auc: 0.9091\n",
      "Epoch 12/20\n",
      "8/8 - 0s - loss: 0.3438 - auc: 0.9720 - val_loss: 0.4391 - val_auc: 0.9032\n",
      "Epoch 13/20\n",
      "8/8 - 0s - loss: 0.2709 - auc: 0.9886 - val_loss: 0.4193 - val_auc: 0.9266\n",
      "Epoch 14/20\n",
      "8/8 - 0s - loss: 0.1820 - auc: 0.9984 - val_loss: 0.4251 - val_auc: 0.9308\n",
      "Epoch 15/20\n",
      "8/8 - 0s - loss: 0.1308 - auc: 0.9983 - val_loss: 0.6026 - val_auc: 0.9078\n",
      "Epoch 16/20\n",
      "8/8 - 0s - loss: 0.0737 - auc: 1.0000 - val_loss: 0.6527 - val_auc: 0.7683\n",
      "Epoch 17/20\n",
      "8/8 - 0s - loss: 0.1371 - auc: 0.9919 - val_loss: 0.8760 - val_auc: 0.7135\n",
      "Epoch 18/20\n",
      "8/8 - 0s - loss: 0.2112 - auc: 0.9768 - val_loss: 0.5236 - val_auc: 0.9479\n",
      "Epoch 19/20\n",
      "8/8 - 0s - loss: 0.0867 - auc: 0.9997 - val_loss: 0.6363 - val_auc: 0.9187\n",
      "Epoch 20/20\n",
      "8/8 - 0s - loss: 0.0503 - auc: 1.0000 - val_loss: 0.7121 - val_auc: 0.6849\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.7121 - auc: 0.6849\n",
      "Epoch 1/20\n",
      "8/8 - 3s - loss: 0.9174 - auc: 0.6043 - val_loss: 0.5289 - val_auc: 0.8690\n",
      "Epoch 2/20\n",
      "8/8 - 0s - loss: 0.9965 - auc: 0.4980 - val_loss: 0.9331 - val_auc: 0.8261\n",
      "Epoch 3/20\n",
      "8/8 - 0s - loss: 0.6835 - auc: 0.8457 - val_loss: 0.5038 - val_auc: 0.8840\n",
      "Epoch 4/20\n",
      "8/8 - 0s - loss: 0.5780 - auc: 0.8794 - val_loss: 0.4586 - val_auc: 0.8953\n",
      "Epoch 5/20\n",
      "8/8 - 0s - loss: 0.5229 - auc: 0.8992 - val_loss: 0.5320 - val_auc: 0.9170\n",
      "Epoch 6/20\n",
      "8/8 - 0s - loss: 0.4722 - auc: 0.9216 - val_loss: 0.4811 - val_auc: 0.9278\n",
      "Epoch 7/20\n",
      "8/8 - 0s - loss: 0.4355 - auc: 0.9256 - val_loss: 0.4276 - val_auc: 0.9408\n",
      "Epoch 8/20\n",
      "8/8 - 0s - loss: 0.3699 - auc: 0.9543 - val_loss: 0.4331 - val_auc: 0.9395\n",
      "Epoch 9/20\n",
      "8/8 - 0s - loss: 0.3089 - auc: 0.9746 - val_loss: 0.3914 - val_auc: 0.9107\n",
      "Epoch 10/20\n",
      "8/8 - 0s - loss: 0.4333 - auc: 0.9466 - val_loss: 0.5856 - val_auc: 0.9599\n",
      "Epoch 11/20\n",
      "8/8 - 0s - loss: 0.7205 - auc: 0.8970 - val_loss: 0.4826 - val_auc: 0.9599\n",
      "Epoch 12/20\n",
      "8/8 - 0s - loss: 0.4984 - auc: 0.8967 - val_loss: 0.5112 - val_auc: 0.9750\n",
      "Epoch 13/20\n",
      "8/8 - 0s - loss: 0.3245 - auc: 0.9772 - val_loss: 0.3899 - val_auc: 0.9750\n",
      "Epoch 14/20\n",
      "8/8 - 0s - loss: 0.2735 - auc: 0.9794 - val_loss: 0.3947 - val_auc: 0.9750\n",
      "Epoch 15/20\n",
      "8/8 - 0s - loss: 0.1920 - auc: 0.9939 - val_loss: 0.3956 - val_auc: 0.9750\n",
      "Epoch 16/20\n",
      "8/8 - 0s - loss: 0.1409 - auc: 0.9973 - val_loss: 0.5222 - val_auc: 0.9679\n",
      "Epoch 17/20\n",
      "8/8 - 0s - loss: 0.0950 - auc: 1.0000 - val_loss: 0.5893 - val_auc: 0.9762\n",
      "Epoch 18/20\n",
      "8/8 - 0s - loss: 0.0695 - auc: 1.0000 - val_loss: 0.7641 - val_auc: 0.8582\n",
      "Epoch 19/20\n",
      "8/8 - 0s - loss: 0.0490 - auc: 1.0000 - val_loss: 0.7462 - val_auc: 0.9137\n",
      "Epoch 20/20\n",
      "8/8 - 0s - loss: 0.0340 - auc: 1.0000 - val_loss: 0.7774 - val_auc: 0.8582\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.7774 - auc: 0.8582\n",
      "The mean AUC is 0.6086257338523865 and SD is 0.14387747975111168\n"
     ]
    }
   ],
   "source": [
    "mean, std = calculate_mean_std(weights=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84f2c0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "8/8 - 3s - loss: 3.7279 - auc: 0.4401 - val_loss: 0.7181 - val_auc: 0.5886\n",
      "Epoch 2/20\n",
      "8/8 - 0s - loss: 3.7115 - auc: 0.6940 - val_loss: 1.0082 - val_auc: 0.7354\n",
      "Epoch 3/20\n",
      "8/8 - 0s - loss: 2.4150 - auc: 0.8536 - val_loss: 0.7804 - val_auc: 0.7913\n",
      "Epoch 4/20\n",
      "8/8 - 0s - loss: 2.2610 - auc: 0.8874 - val_loss: 0.7830 - val_auc: 0.7997\n",
      "Epoch 5/20\n",
      "8/8 - 0s - loss: 1.9304 - auc: 0.9050 - val_loss: 0.5594 - val_auc: 0.7921\n",
      "Epoch 6/20\n",
      "8/8 - 0s - loss: 1.6854 - auc: 0.9259 - val_loss: 0.4568 - val_auc: 0.8021\n",
      "Epoch 7/20\n",
      "8/8 - 0s - loss: 1.4634 - auc: 0.9253 - val_loss: 0.4492 - val_auc: 0.8343\n",
      "Epoch 8/20\n",
      "8/8 - 0s - loss: 1.7465 - auc: 0.9277 - val_loss: 1.2143 - val_auc: 0.6463\n",
      "Epoch 9/20\n",
      "8/8 - 0s - loss: 2.3157 - auc: 0.9059 - val_loss: 0.6438 - val_auc: 0.8702\n",
      "Epoch 10/20\n",
      "8/8 - 0s - loss: 2.5282 - auc: 0.8742 - val_loss: 0.6452 - val_auc: 0.8377\n",
      "Epoch 11/20\n",
      "8/8 - 0s - loss: 1.4576 - auc: 0.9528 - val_loss: 0.5351 - val_auc: 0.8911\n",
      "Epoch 12/20\n",
      "8/8 - 0s - loss: 1.2538 - auc: 0.9620 - val_loss: 0.4343 - val_auc: 0.9015\n",
      "Epoch 13/20\n",
      "8/8 - 0s - loss: 0.9988 - auc: 0.9675 - val_loss: 0.3730 - val_auc: 0.9220\n",
      "Epoch 14/20\n",
      "8/8 - 0s - loss: 0.7952 - auc: 0.9747 - val_loss: 0.4146 - val_auc: 0.9203\n",
      "Epoch 15/20\n",
      "8/8 - 0s - loss: 0.5804 - auc: 0.9918 - val_loss: 0.5488 - val_auc: 0.9078\n",
      "Epoch 16/20\n",
      "8/8 - 0s - loss: 0.4630 - auc: 0.9944 - val_loss: 0.6455 - val_auc: 0.9312\n",
      "Epoch 17/20\n",
      "8/8 - 0s - loss: 0.3853 - auc: 0.9937 - val_loss: 1.0172 - val_auc: 0.5000\n",
      "Epoch 18/20\n",
      "8/8 - 0s - loss: 0.4450 - auc: 0.9905 - val_loss: 0.5095 - val_auc: 0.8277\n",
      "Epoch 19/20\n",
      "8/8 - 0s - loss: 0.4543 - auc: 0.9845 - val_loss: 0.6506 - val_auc: 0.8566\n",
      "Epoch 20/20\n",
      "8/8 - 0s - loss: 0.5066 - auc: 0.9910 - val_loss: 0.6230 - val_auc: 0.7140\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.6230 - auc: 0.7140\n",
      "Epoch 1/20\n",
      "8/8 - 3s - loss: 3.7920 - auc: 0.4195 - val_loss: 0.7908 - val_auc: 0.8260\n",
      "Epoch 2/20\n",
      "8/8 - 0s - loss: 3.3533 - auc: 0.7395 - val_loss: 1.1288 - val_auc: 0.7615\n",
      "Epoch 3/20\n",
      "8/8 - 0s - loss: 2.5344 - auc: 0.8304 - val_loss: 0.9103 - val_auc: 0.9282\n",
      "Epoch 4/20\n",
      "8/8 - 0s - loss: 2.2149 - auc: 0.8896 - val_loss: 0.9591 - val_auc: 0.9124\n",
      "Epoch 5/20\n",
      "8/8 - 0s - loss: 1.9322 - auc: 0.9070 - val_loss: 0.6469 - val_auc: 0.9286\n",
      "Epoch 6/20\n",
      "8/8 - 0s - loss: 1.6397 - auc: 0.9255 - val_loss: 0.4943 - val_auc: 0.8629\n",
      "Epoch 7/20\n",
      "8/8 - 0s - loss: 1.5261 - auc: 0.9245 - val_loss: 0.4681 - val_auc: 0.9353\n",
      "Epoch 8/20\n",
      "8/8 - 0s - loss: 2.1764 - auc: 0.9175 - val_loss: 1.2804 - val_auc: 0.7853\n",
      "Epoch 9/20\n",
      "8/8 - 0s - loss: 1.9583 - auc: 0.9175 - val_loss: 1.2414 - val_auc: 0.7593\n",
      "Epoch 10/20\n",
      "8/8 - 0s - loss: 1.5320 - auc: 0.9318 - val_loss: 0.6989 - val_auc: 0.8098\n",
      "Epoch 11/20\n",
      "8/8 - 0s - loss: 1.2109 - auc: 0.9605 - val_loss: 0.5625 - val_auc: 0.7969\n",
      "Epoch 12/20\n",
      "8/8 - 0s - loss: 0.9404 - auc: 0.9689 - val_loss: 0.4244 - val_auc: 0.8682\n",
      "Epoch 13/20\n",
      "8/8 - 0s - loss: 0.7420 - auc: 0.9794 - val_loss: 0.3837 - val_auc: 0.9015\n",
      "Epoch 14/20\n",
      "8/8 - 0s - loss: 0.6017 - auc: 0.9909 - val_loss: 0.4559 - val_auc: 0.8348\n",
      "Epoch 15/20\n",
      "8/8 - 0s - loss: 0.5464 - auc: 0.9854 - val_loss: 0.5409 - val_auc: 0.8636\n",
      "Epoch 16/20\n",
      "8/8 - 0s - loss: 0.6614 - auc: 0.9796 - val_loss: 1.1917 - val_auc: 0.6091\n",
      "Epoch 17/20\n",
      "8/8 - 0s - loss: 0.6222 - auc: 0.9751 - val_loss: 0.4633 - val_auc: 0.7590\n",
      "Epoch 18/20\n",
      "8/8 - 0s - loss: 0.3420 - auc: 0.9970 - val_loss: 0.5237 - val_auc: 0.8244\n",
      "Epoch 19/20\n",
      "8/8 - 0s - loss: 0.2293 - auc: 0.9996 - val_loss: 0.4585 - val_auc: 0.8211\n",
      "Epoch 20/20\n",
      "8/8 - 0s - loss: 0.2867 - auc: 0.9967 - val_loss: 0.4367 - val_auc: 0.7994\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4367 - auc: 0.7994\n",
      "Epoch 1/20\n",
      "8/8 - 3s - loss: 3.7369 - auc: 0.4096 - val_loss: 0.6446 - val_auc: 0.2679\n",
      "Epoch 2/20\n",
      "8/8 - 0s - loss: 3.6447 - auc: 0.6682 - val_loss: 1.0111 - val_auc: 0.3849\n",
      "Epoch 3/20\n",
      "8/8 - 0s - loss: 2.5541 - auc: 0.8370 - val_loss: 0.8606 - val_auc: 0.3800\n",
      "Epoch 4/20\n",
      "8/8 - 0s - loss: 2.2365 - auc: 0.8826 - val_loss: 0.6661 - val_auc: 0.2777\n",
      "Epoch 5/20\n",
      "8/8 - 0s - loss: 1.8732 - auc: 0.9125 - val_loss: 0.5706 - val_auc: 0.3390\n",
      "Epoch 6/20\n",
      "8/8 - 0s - loss: 1.5336 - auc: 0.9333 - val_loss: 0.6322 - val_auc: 0.4157\n",
      "Epoch 7/20\n",
      "8/8 - 0s - loss: 1.3576 - auc: 0.9377 - val_loss: 0.6600 - val_auc: 0.3272\n",
      "Epoch 8/20\n",
      "8/8 - 0s - loss: 2.9537 - auc: 0.8946 - val_loss: 0.7816 - val_auc: 0.5092\n",
      "Epoch 9/20\n",
      "8/8 - 0s - loss: 2.5168 - auc: 0.8725 - val_loss: 0.5224 - val_auc: 0.4641\n",
      "Epoch 10/20\n",
      "8/8 - 0s - loss: 2.0472 - auc: 0.9043 - val_loss: 0.7969 - val_auc: 0.5914\n",
      "Epoch 11/20\n",
      "8/8 - 0s - loss: 1.6456 - auc: 0.9363 - val_loss: 0.6421 - val_auc: 0.6239\n",
      "Epoch 12/20\n",
      "8/8 - 0s - loss: 1.3764 - auc: 0.9432 - val_loss: 0.4746 - val_auc: 0.6156\n",
      "Epoch 13/20\n",
      "8/8 - 0s - loss: 1.1434 - auc: 0.9538 - val_loss: 0.4722 - val_auc: 0.6218\n",
      "Epoch 14/20\n",
      "8/8 - 0s - loss: 0.8892 - auc: 0.9736 - val_loss: 0.5119 - val_auc: 0.6749\n",
      "Epoch 15/20\n",
      "8/8 - 0s - loss: 0.6956 - auc: 0.9850 - val_loss: 0.6997 - val_auc: 0.6256\n",
      "Epoch 16/20\n",
      "8/8 - 0s - loss: 0.5328 - auc: 0.9928 - val_loss: 0.6319 - val_auc: 0.5860\n",
      "Epoch 17/20\n",
      "8/8 - 0s - loss: 0.4644 - auc: 0.9903 - val_loss: 1.0651 - val_auc: 0.5000\n",
      "Epoch 18/20\n",
      "8/8 - 0s - loss: 0.4114 - auc: 0.9949 - val_loss: 0.6318 - val_auc: 0.5488\n",
      "Epoch 19/20\n",
      "8/8 - 0s - loss: 0.4221 - auc: 0.9907 - val_loss: 0.8209 - val_auc: 0.5576\n",
      "Epoch 20/20\n",
      "8/8 - 0s - loss: 0.2406 - auc: 0.9991 - val_loss: 0.7653 - val_auc: 0.5442\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.7653 - auc: 0.5442\n",
      "Epoch 1/20\n",
      "8/8 - 3s - loss: 3.7555 - auc: 0.4183 - val_loss: 0.6669 - val_auc: 0.8836\n",
      "Epoch 2/20\n",
      "8/8 - 0s - loss: 3.4459 - auc: 0.7359 - val_loss: 1.0406 - val_auc: 0.8631\n",
      "Epoch 3/20\n",
      "8/8 - 0s - loss: 2.4569 - auc: 0.8348 - val_loss: 0.8656 - val_auc: 0.8919\n",
      "Epoch 4/20\n",
      "8/8 - 0s - loss: 2.1849 - auc: 0.8893 - val_loss: 0.6866 - val_auc: 0.9274\n",
      "Epoch 5/20\n",
      "8/8 - 0s - loss: 1.8132 - auc: 0.9188 - val_loss: 0.4328 - val_auc: 0.9558\n",
      "Epoch 6/20\n",
      "8/8 - 0s - loss: 1.5450 - auc: 0.9262 - val_loss: 0.5038 - val_auc: 0.9283\n",
      "Epoch 7/20\n",
      "8/8 - 0s - loss: 1.6911 - auc: 0.9268 - val_loss: 0.3789 - val_auc: 0.9775\n",
      "Epoch 8/20\n",
      "8/8 - 0s - loss: 2.0246 - auc: 0.8942 - val_loss: 0.4934 - val_auc: 0.9416\n",
      "Epoch 9/20\n",
      "8/8 - 0s - loss: 1.5147 - auc: 0.9385 - val_loss: 0.4415 - val_auc: 0.9420\n",
      "Epoch 10/20\n",
      "8/8 - 0s - loss: 1.2596 - auc: 0.9469 - val_loss: 0.3940 - val_auc: 0.9340\n",
      "Epoch 11/20\n",
      "8/8 - 0s - loss: 0.9923 - auc: 0.9721 - val_loss: 0.3180 - val_auc: 0.9340\n",
      "Epoch 12/20\n",
      "8/8 - 0s - loss: 0.8012 - auc: 0.9838 - val_loss: 0.3454 - val_auc: 0.9370\n",
      "Epoch 13/20\n",
      "8/8 - 0s - loss: 0.6497 - auc: 0.9830 - val_loss: 0.5861 - val_auc: 0.7870\n",
      "Epoch 14/20\n",
      "8/8 - 0s - loss: 0.4772 - auc: 0.9899 - val_loss: 0.5510 - val_auc: 0.9191\n",
      "Epoch 15/20\n",
      "8/8 - 0s - loss: 0.4810 - auc: 0.9889 - val_loss: 0.7342 - val_auc: 0.8666\n",
      "Epoch 16/20\n",
      "8/8 - 0s - loss: 0.4799 - auc: 0.9911 - val_loss: 0.5407 - val_auc: 0.7966\n",
      "Epoch 17/20\n",
      "8/8 - 0s - loss: 0.4638 - auc: 0.9886 - val_loss: 0.5749 - val_auc: 0.8883\n",
      "Epoch 18/20\n",
      "8/8 - 0s - loss: 0.3262 - auc: 0.9975 - val_loss: 0.6838 - val_auc: 0.8050\n",
      "Epoch 19/20\n",
      "8/8 - 0s - loss: 0.1343 - auc: 1.0000 - val_loss: 0.8966 - val_auc: 0.6607\n",
      "Epoch 20/20\n",
      "8/8 - 0s - loss: 0.0903 - auc: 1.0000 - val_loss: 0.9893 - val_auc: 0.5385\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.9893 - auc: 0.5385\n",
      "Epoch 1/20\n",
      "8/8 - 3s - loss: 3.7925 - auc: 0.4380 - val_loss: 0.7092 - val_auc: 0.6307\n",
      "Epoch 2/20\n",
      "8/8 - 0s - loss: 3.3357 - auc: 0.7626 - val_loss: 0.9439 - val_auc: 0.7777\n",
      "Epoch 3/20\n",
      "8/8 - 0s - loss: 2.5811 - auc: 0.8282 - val_loss: 0.7640 - val_auc: 0.8511\n",
      "Epoch 4/20\n",
      "8/8 - 0s - loss: 2.2068 - auc: 0.8958 - val_loss: 0.6618 - val_auc: 0.9004\n",
      "Epoch 5/20\n",
      "8/8 - 0s - loss: 1.9047 - auc: 0.9175 - val_loss: 0.4714 - val_auc: 0.9379\n",
      "Epoch 6/20\n",
      "8/8 - 0s - loss: 1.5106 - auc: 0.9337 - val_loss: 0.4466 - val_auc: 0.9520\n",
      "Epoch 7/20\n",
      "8/8 - 0s - loss: 1.2745 - auc: 0.9538 - val_loss: 0.4963 - val_auc: 0.9137\n",
      "Epoch 8/20\n",
      "8/8 - 0s - loss: 1.8340 - auc: 0.9228 - val_loss: 0.6273 - val_auc: 0.7170\n",
      "Epoch 9/20\n",
      "8/8 - 0s - loss: 3.9743 - auc: 0.8299 - val_loss: 1.3331 - val_auc: 0.7433\n",
      "Epoch 10/20\n",
      "8/8 - 0s - loss: 1.9696 - auc: 0.9320 - val_loss: 1.2445 - val_auc: 0.6973\n",
      "Epoch 11/20\n",
      "8/8 - 0s - loss: 2.0417 - auc: 0.8988 - val_loss: 0.8594 - val_auc: 0.5727\n",
      "Epoch 12/20\n",
      "8/8 - 0s - loss: 1.5473 - auc: 0.9448 - val_loss: 0.5574 - val_auc: 0.6168\n",
      "Epoch 13/20\n",
      "8/8 - 0s - loss: 1.1015 - auc: 0.9642 - val_loss: 0.5040 - val_auc: 0.6848\n",
      "Epoch 14/20\n",
      "8/8 - 0s - loss: 0.8892 - auc: 0.9719 - val_loss: 0.4492 - val_auc: 0.7182\n",
      "Epoch 15/20\n",
      "8/8 - 0s - loss: 0.6800 - auc: 0.9852 - val_loss: 0.5075 - val_auc: 0.6856\n",
      "Epoch 16/20\n",
      "8/8 - 0s - loss: 0.5165 - auc: 0.9911 - val_loss: 0.5939 - val_auc: 0.7654\n",
      "Epoch 17/20\n",
      "8/8 - 0s - loss: 0.3958 - auc: 0.9950 - val_loss: 0.8033 - val_auc: 0.6123\n",
      "Epoch 18/20\n",
      "8/8 - 0s - loss: 0.3295 - auc: 0.9980 - val_loss: 0.8093 - val_auc: 0.6039\n",
      "Epoch 19/20\n",
      "8/8 - 0s - loss: 0.6076 - auc: 0.9870 - val_loss: 0.8704 - val_auc: 0.4984\n",
      "Epoch 20/20\n",
      "8/8 - 0s - loss: 0.5269 - auc: 0.9895 - val_loss: 0.6092 - val_auc: 0.6386\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6092 - auc: 0.6386\n",
      "The mean AUC is 0.6469360828399658 and SD is 0.10014097815527023\n"
     ]
    }
   ],
   "source": [
    "mean_2, std_2 = calculate_mean_std(weights=weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:generalml_p37_gpu_v1]",
   "language": "python",
   "name": "conda-env-generalml_p37_gpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
