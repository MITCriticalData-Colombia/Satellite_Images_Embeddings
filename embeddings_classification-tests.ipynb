{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "543c6c8d",
   "metadata": {},
   "source": [
    "# Setup enviorment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb958a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50733c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data reading in Dataframe format and data preprocessing\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Linear algebra operations\n",
    "import numpy as np\n",
    "\n",
    "# Machine learning models and preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Deep learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Sequential, layers, callbacks\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional\n",
    "import keras_tuner\n",
    "\n",
    "# Epiweek\n",
    "from epiweeks import Week, Year\n",
    "\n",
    "# Date\n",
    "from datetime import date as convert_to_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e8d7235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b579891f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = 'Embeddings/embeddings_vae_1024features.csv'\n",
    "labels = 'Tabular_data/Label_CSV_All_Municipality.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f990bb65",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c4c042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epiweek_from_date(image_date):\n",
    "    date = image_date.split('-')\n",
    "    \n",
    "    # Get year as int\n",
    "    year = ''.join(filter(str.isdigit, date[0]))\n",
    "    year = int(year)\n",
    "    \n",
    "    # Get month as int\n",
    "    month = ''.join(filter(str.isdigit, date[1]))\n",
    "    month = int(month)\n",
    "    \n",
    "    # Get day as int\n",
    "    day = ''.join(filter(str.isdigit, date[2]))\n",
    "    day = int(day)\n",
    "    \n",
    "    # Get epiweek:\n",
    "    date = convert_to_date(year, month, day)\n",
    "    epiweek = str(Week.fromdate(date))\n",
    "    epiweek = int(epiweek)\n",
    "    \n",
    "    return epiweek"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f7b0eb",
   "metadata": {},
   "source": [
    "### 1. Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cca0d9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_features(path, Municipality = None):\n",
    "    df = pd.read_csv(path)\n",
    "    #df.Date = pd.to_datetime(df.Date)\n",
    "    \n",
    "    if Municipality:\n",
    "        print('Obtaining dataframe for the city of Medellin only...')\n",
    "        df = df[df['Municipality Code'] == Municipality]\n",
    "        \n",
    "    df.Date = df.Date.apply(epiweek_from_date)\n",
    "    \n",
    "    df = df.sort_values(by=['Date'])\n",
    "    \n",
    "    df = df.set_index('Date')\n",
    "    \n",
    "    if Municipality:\n",
    "        df.drop(columns=['Municipality Code'], inplace=True)\n",
    "        \n",
    "    df.index.name = None\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1169a163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining dataframe for the city of Medellin only...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1014</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201544</th>\n",
       "      <td>-0.046489</td>\n",
       "      <td>-1.407201</td>\n",
       "      <td>-1.148883</td>\n",
       "      <td>0.836687</td>\n",
       "      <td>-0.190778</td>\n",
       "      <td>1.802231</td>\n",
       "      <td>0.517497</td>\n",
       "      <td>-1.146697</td>\n",
       "      <td>0.119171</td>\n",
       "      <td>1.544828</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.678144</td>\n",
       "      <td>-0.036498</td>\n",
       "      <td>-0.303533</td>\n",
       "      <td>0.248490</td>\n",
       "      <td>-0.811357</td>\n",
       "      <td>-0.832925</td>\n",
       "      <td>-0.739305</td>\n",
       "      <td>-0.295200</td>\n",
       "      <td>-0.038603</td>\n",
       "      <td>0.485674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201545</th>\n",
       "      <td>0.327904</td>\n",
       "      <td>-0.701594</td>\n",
       "      <td>0.306197</td>\n",
       "      <td>-0.796750</td>\n",
       "      <td>-1.037395</td>\n",
       "      <td>0.857556</td>\n",
       "      <td>0.167456</td>\n",
       "      <td>1.642044</td>\n",
       "      <td>-0.473234</td>\n",
       "      <td>0.181270</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.897844</td>\n",
       "      <td>-0.661285</td>\n",
       "      <td>-1.146673</td>\n",
       "      <td>-1.234707</td>\n",
       "      <td>-0.184185</td>\n",
       "      <td>-0.140669</td>\n",
       "      <td>-2.367193</td>\n",
       "      <td>-0.463623</td>\n",
       "      <td>-0.668936</td>\n",
       "      <td>-0.233073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201546</th>\n",
       "      <td>-1.634988</td>\n",
       "      <td>-0.882196</td>\n",
       "      <td>0.291420</td>\n",
       "      <td>-2.686286</td>\n",
       "      <td>-0.684004</td>\n",
       "      <td>-0.407912</td>\n",
       "      <td>1.827255</td>\n",
       "      <td>0.327352</td>\n",
       "      <td>0.987357</td>\n",
       "      <td>0.781570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.906685</td>\n",
       "      <td>1.372330</td>\n",
       "      <td>-0.333867</td>\n",
       "      <td>0.728862</td>\n",
       "      <td>-0.005498</td>\n",
       "      <td>-0.743434</td>\n",
       "      <td>0.597319</td>\n",
       "      <td>0.195301</td>\n",
       "      <td>-0.850010</td>\n",
       "      <td>0.492581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201547</th>\n",
       "      <td>1.789035</td>\n",
       "      <td>0.854698</td>\n",
       "      <td>-2.904163</td>\n",
       "      <td>-1.008464</td>\n",
       "      <td>-0.165688</td>\n",
       "      <td>0.597984</td>\n",
       "      <td>0.142369</td>\n",
       "      <td>0.164123</td>\n",
       "      <td>1.069377</td>\n",
       "      <td>0.236612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254610</td>\n",
       "      <td>-0.536157</td>\n",
       "      <td>-0.424962</td>\n",
       "      <td>0.685125</td>\n",
       "      <td>-0.029501</td>\n",
       "      <td>0.095485</td>\n",
       "      <td>0.379560</td>\n",
       "      <td>-0.297148</td>\n",
       "      <td>-1.211405</td>\n",
       "      <td>0.443391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201548</th>\n",
       "      <td>-0.983180</td>\n",
       "      <td>0.145126</td>\n",
       "      <td>0.720849</td>\n",
       "      <td>1.524544</td>\n",
       "      <td>0.620878</td>\n",
       "      <td>-1.807810</td>\n",
       "      <td>0.340521</td>\n",
       "      <td>0.781281</td>\n",
       "      <td>-0.395229</td>\n",
       "      <td>-0.769379</td>\n",
       "      <td>...</td>\n",
       "      <td>1.562922</td>\n",
       "      <td>0.585608</td>\n",
       "      <td>-0.675990</td>\n",
       "      <td>0.232964</td>\n",
       "      <td>0.788353</td>\n",
       "      <td>0.147064</td>\n",
       "      <td>0.094748</td>\n",
       "      <td>-0.206415</td>\n",
       "      <td>1.170020</td>\n",
       "      <td>0.276934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201848</th>\n",
       "      <td>-0.177821</td>\n",
       "      <td>0.800357</td>\n",
       "      <td>0.158949</td>\n",
       "      <td>2.573438</td>\n",
       "      <td>1.615337</td>\n",
       "      <td>-0.998008</td>\n",
       "      <td>1.096824</td>\n",
       "      <td>-0.023870</td>\n",
       "      <td>-0.667530</td>\n",
       "      <td>-1.929526</td>\n",
       "      <td>...</td>\n",
       "      <td>2.209477</td>\n",
       "      <td>0.241274</td>\n",
       "      <td>-1.311355</td>\n",
       "      <td>0.955204</td>\n",
       "      <td>0.006918</td>\n",
       "      <td>0.715542</td>\n",
       "      <td>-0.870650</td>\n",
       "      <td>-0.205803</td>\n",
       "      <td>0.835786</td>\n",
       "      <td>1.692061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201849</th>\n",
       "      <td>-0.306444</td>\n",
       "      <td>1.308680</td>\n",
       "      <td>1.067536</td>\n",
       "      <td>-0.931025</td>\n",
       "      <td>-1.046062</td>\n",
       "      <td>2.075529</td>\n",
       "      <td>-0.501223</td>\n",
       "      <td>-2.267342</td>\n",
       "      <td>0.095569</td>\n",
       "      <td>-0.845871</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.447275</td>\n",
       "      <td>0.293684</td>\n",
       "      <td>-1.791375</td>\n",
       "      <td>-0.086890</td>\n",
       "      <td>0.917567</td>\n",
       "      <td>0.631528</td>\n",
       "      <td>-2.004170</td>\n",
       "      <td>0.267849</td>\n",
       "      <td>1.151415</td>\n",
       "      <td>-1.051147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201850</th>\n",
       "      <td>-0.151392</td>\n",
       "      <td>0.071449</td>\n",
       "      <td>0.356428</td>\n",
       "      <td>0.259774</td>\n",
       "      <td>-0.383608</td>\n",
       "      <td>1.065443</td>\n",
       "      <td>0.450759</td>\n",
       "      <td>0.322183</td>\n",
       "      <td>-1.307717</td>\n",
       "      <td>-0.181305</td>\n",
       "      <td>...</td>\n",
       "      <td>1.033319</td>\n",
       "      <td>0.951084</td>\n",
       "      <td>0.638319</td>\n",
       "      <td>-0.277678</td>\n",
       "      <td>0.032450</td>\n",
       "      <td>-0.329121</td>\n",
       "      <td>-0.322632</td>\n",
       "      <td>-1.898407</td>\n",
       "      <td>-0.602611</td>\n",
       "      <td>-0.267056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201851</th>\n",
       "      <td>-0.793142</td>\n",
       "      <td>-0.539722</td>\n",
       "      <td>-1.165816</td>\n",
       "      <td>-0.199017</td>\n",
       "      <td>2.244849</td>\n",
       "      <td>0.917043</td>\n",
       "      <td>-0.467799</td>\n",
       "      <td>0.353362</td>\n",
       "      <td>1.053764</td>\n",
       "      <td>0.443968</td>\n",
       "      <td>...</td>\n",
       "      <td>0.882802</td>\n",
       "      <td>-0.827243</td>\n",
       "      <td>-0.127070</td>\n",
       "      <td>-1.308614</td>\n",
       "      <td>-1.632518</td>\n",
       "      <td>1.059085</td>\n",
       "      <td>1.047949</td>\n",
       "      <td>-2.762428</td>\n",
       "      <td>-0.955669</td>\n",
       "      <td>0.913588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201852</th>\n",
       "      <td>-0.393870</td>\n",
       "      <td>1.455486</td>\n",
       "      <td>-0.128889</td>\n",
       "      <td>-0.788440</td>\n",
       "      <td>0.381879</td>\n",
       "      <td>0.022924</td>\n",
       "      <td>0.543938</td>\n",
       "      <td>-0.070586</td>\n",
       "      <td>-0.623824</td>\n",
       "      <td>-0.382842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.705277</td>\n",
       "      <td>0.204254</td>\n",
       "      <td>-0.124967</td>\n",
       "      <td>0.008888</td>\n",
       "      <td>0.031512</td>\n",
       "      <td>2.580178</td>\n",
       "      <td>-0.813275</td>\n",
       "      <td>-0.418657</td>\n",
       "      <td>-0.572518</td>\n",
       "      <td>-0.936024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165 rows × 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "201544 -0.046489 -1.407201 -1.148883  0.836687 -0.190778  1.802231  0.517497   \n",
       "201545  0.327904 -0.701594  0.306197 -0.796750 -1.037395  0.857556  0.167456   \n",
       "201546 -1.634988 -0.882196  0.291420 -2.686286 -0.684004 -0.407912  1.827255   \n",
       "201547  1.789035  0.854698 -2.904163 -1.008464 -0.165688  0.597984  0.142369   \n",
       "201548 -0.983180  0.145126  0.720849  1.524544  0.620878 -1.807810  0.340521   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "201848 -0.177821  0.800357  0.158949  2.573438  1.615337 -0.998008  1.096824   \n",
       "201849 -0.306444  1.308680  1.067536 -0.931025 -1.046062  2.075529 -0.501223   \n",
       "201850 -0.151392  0.071449  0.356428  0.259774 -0.383608  1.065443  0.450759   \n",
       "201851 -0.793142 -0.539722 -1.165816 -0.199017  2.244849  0.917043 -0.467799   \n",
       "201852 -0.393870  1.455486 -0.128889 -0.788440  0.381879  0.022924  0.543938   \n",
       "\n",
       "               7         8         9  ...      1014      1015      1016  \\\n",
       "201544 -1.146697  0.119171  1.544828  ... -0.678144 -0.036498 -0.303533   \n",
       "201545  1.642044 -0.473234  0.181270  ... -0.897844 -0.661285 -1.146673   \n",
       "201546  0.327352  0.987357  0.781570  ...  0.906685  1.372330 -0.333867   \n",
       "201547  0.164123  1.069377  0.236612  ...  0.254610 -0.536157 -0.424962   \n",
       "201548  0.781281 -0.395229 -0.769379  ...  1.562922  0.585608 -0.675990   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "201848 -0.023870 -0.667530 -1.929526  ...  2.209477  0.241274 -1.311355   \n",
       "201849 -2.267342  0.095569 -0.845871  ... -2.447275  0.293684 -1.791375   \n",
       "201850  0.322183 -1.307717 -0.181305  ...  1.033319  0.951084  0.638319   \n",
       "201851  0.353362  1.053764  0.443968  ...  0.882802 -0.827243 -0.127070   \n",
       "201852 -0.070586 -0.623824 -0.382842  ...  0.705277  0.204254 -0.124967   \n",
       "\n",
       "            1017      1018      1019      1020      1021      1022      1023  \n",
       "201544  0.248490 -0.811357 -0.832925 -0.739305 -0.295200 -0.038603  0.485674  \n",
       "201545 -1.234707 -0.184185 -0.140669 -2.367193 -0.463623 -0.668936 -0.233073  \n",
       "201546  0.728862 -0.005498 -0.743434  0.597319  0.195301 -0.850010  0.492581  \n",
       "201547  0.685125 -0.029501  0.095485  0.379560 -0.297148 -1.211405  0.443391  \n",
       "201548  0.232964  0.788353  0.147064  0.094748 -0.206415  1.170020  0.276934  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "201848  0.955204  0.006918  0.715542 -0.870650 -0.205803  0.835786  1.692061  \n",
       "201849 -0.086890  0.917567  0.631528 -2.004170  0.267849  1.151415 -1.051147  \n",
       "201850 -0.277678  0.032450 -0.329121 -0.322632 -1.898407 -0.602611 -0.267056  \n",
       "201851 -1.308614 -1.632518  1.059085  1.047949 -2.762428 -0.955669  0.913588  \n",
       "201852  0.008888  0.031512  2.580178 -0.813275 -0.418657 -0.572518 -0.936024  \n",
       "\n",
       "[165 rows x 1024 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df = read_features(path=embeddings, Municipality='Medellín')\n",
    "features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bd263f",
   "metadata": {},
   "source": [
    "### 2. Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2100fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epiweek(name):\n",
    "    \n",
    "    # Get week\n",
    "    week = name.split('/')[1]\n",
    "    week = week.replace('w','')\n",
    "    week = int(week)\n",
    "    \n",
    "    # Year\n",
    "    year = name.split('/')[0]\n",
    "    year = int(year)\n",
    "    \n",
    "    epiweek = Week(year, week)\n",
    "    \n",
    "    epiweek = str(epiweek)\n",
    "    epiweek = int(epiweek)\n",
    "\n",
    "    return epiweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70eed474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_labels(path, Municipality = None):\n",
    "    df = pd.read_csv(path)\n",
    "    if df.shape[1] > 678:\n",
    "        df = pd.concat([df[['Municipality code', 'Municipality']], df.iloc[:,-676:]], axis=1)\n",
    "        cols = df.iloc[:, 2:].columns\n",
    "        new_cols = df.iloc[:, 2:].columns.to_series().apply(get_epiweek)\n",
    "        df = df.rename(columns=dict(zip(cols, new_cols))) \n",
    "        \n",
    "    if 'Label_CSV_All_Municipality' in path:\n",
    "        # Get Columns\n",
    "        df = df[['epiweek', 'Municipality code', 'Municipality', 'final_cases_label']]\n",
    "        \n",
    "        # change epiweek format\n",
    "        df.epiweek = df.epiweek.apply(get_epiweek)\n",
    "        \n",
    "        # Remove duplicates\n",
    "        df = df[df.duplicated(['epiweek','Municipality code','Municipality']) == False]\n",
    "        \n",
    "        # Replace Increase, decrease, stable to numerical:\n",
    "        \"\"\"\n",
    "        - Stable = 0\n",
    "        - Increased = 1 \n",
    "        - Decreased = 2\n",
    "        \"\"\"\n",
    "        df.final_cases_label = df.final_cases_label.replace({'Stable': 0, 'Increased': 1, 'Decreased': 2})\n",
    "        \n",
    "        # Create table\n",
    "        df = df.pivot(index=['Municipality code', 'Municipality'], columns='epiweek', values='final_cases_label')\n",
    "\n",
    "        # Reset Index:\n",
    "        df = df.reset_index()\n",
    "    \n",
    "    if Municipality:\n",
    "        df = df[df['Municipality'] == Municipality]\n",
    "        df.drop(columns=['Municipality code'], inplace=True)\n",
    "        df.rename(columns={'Municipality': 'Municipality Code'}, inplace=True)\n",
    "    \n",
    "        df = df.set_index('Municipality Code')\n",
    "        df = df.T\n",
    "\n",
    "        df.columns.name = None\n",
    "        df.index.name = None\n",
    "        \n",
    "        df.columns = ['Labels']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79a9c417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201601</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201602</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201603</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201604</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201605</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201848</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201849</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201850</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201851</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201852</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0  1  2\n",
       "201601  1  0  0\n",
       "201602  0  1  0\n",
       "201603  0  0  1\n",
       "201604  1  0  0\n",
       "201605  1  0  0\n",
       "...    .. .. ..\n",
       "201848  1  0  0\n",
       "201849  0  0  1\n",
       "201850  0  1  0\n",
       "201851  1  0  0\n",
       "201852  1  0  0\n",
       "\n",
       "[156 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df = read_labels(path=labels, Municipality='Medellín')\n",
    "labels_df_orig = labels_df\n",
    "labels_df = pd.get_dummies(labels_df['Labels'])\n",
    "labels_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6272df7e",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47f07614",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labels = labels_df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d57ccab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201601</th>\n",
       "      <td>1.287487</td>\n",
       "      <td>-0.688955</td>\n",
       "      <td>-0.794426</td>\n",
       "      <td>-1.238838</td>\n",
       "      <td>1.239369</td>\n",
       "      <td>1.784700</td>\n",
       "      <td>-0.000341</td>\n",
       "      <td>0.525795</td>\n",
       "      <td>0.363034</td>\n",
       "      <td>0.825218</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.439056</td>\n",
       "      <td>0.675143</td>\n",
       "      <td>-1.017167</td>\n",
       "      <td>-0.206480</td>\n",
       "      <td>-0.043412</td>\n",
       "      <td>-1.014832</td>\n",
       "      <td>-1.435265</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201602</th>\n",
       "      <td>-1.399851</td>\n",
       "      <td>-0.211775</td>\n",
       "      <td>1.341302</td>\n",
       "      <td>0.132593</td>\n",
       "      <td>-0.097550</td>\n",
       "      <td>0.159015</td>\n",
       "      <td>-1.474547</td>\n",
       "      <td>-1.294940</td>\n",
       "      <td>1.222341</td>\n",
       "      <td>-0.381582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.420181</td>\n",
       "      <td>-1.341189</td>\n",
       "      <td>-0.138499</td>\n",
       "      <td>-1.804684</td>\n",
       "      <td>-0.662659</td>\n",
       "      <td>0.475712</td>\n",
       "      <td>0.201907</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201603</th>\n",
       "      <td>-0.405975</td>\n",
       "      <td>0.289439</td>\n",
       "      <td>-0.377020</td>\n",
       "      <td>-0.355364</td>\n",
       "      <td>-1.054876</td>\n",
       "      <td>0.712196</td>\n",
       "      <td>0.927682</td>\n",
       "      <td>-0.470455</td>\n",
       "      <td>-0.252064</td>\n",
       "      <td>1.062808</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.587504</td>\n",
       "      <td>0.340662</td>\n",
       "      <td>0.299123</td>\n",
       "      <td>0.405674</td>\n",
       "      <td>-2.638784</td>\n",
       "      <td>0.780803</td>\n",
       "      <td>-1.659373</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201604</th>\n",
       "      <td>0.844463</td>\n",
       "      <td>-1.315463</td>\n",
       "      <td>2.082394</td>\n",
       "      <td>2.693551</td>\n",
       "      <td>-1.234441</td>\n",
       "      <td>1.570999</td>\n",
       "      <td>0.279815</td>\n",
       "      <td>0.831815</td>\n",
       "      <td>-0.229177</td>\n",
       "      <td>-0.052932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.959280</td>\n",
       "      <td>-0.753616</td>\n",
       "      <td>1.713913</td>\n",
       "      <td>1.536158</td>\n",
       "      <td>-1.955070</td>\n",
       "      <td>0.051035</td>\n",
       "      <td>-1.663397</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201605</th>\n",
       "      <td>-0.541275</td>\n",
       "      <td>0.475828</td>\n",
       "      <td>0.136089</td>\n",
       "      <td>0.335247</td>\n",
       "      <td>1.387429</td>\n",
       "      <td>0.863202</td>\n",
       "      <td>-1.643587</td>\n",
       "      <td>-0.673929</td>\n",
       "      <td>-0.331307</td>\n",
       "      <td>-1.289601</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.362812</td>\n",
       "      <td>-0.104197</td>\n",
       "      <td>-0.509349</td>\n",
       "      <td>0.104454</td>\n",
       "      <td>-3.172053</td>\n",
       "      <td>0.055130</td>\n",
       "      <td>0.444714</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201848</th>\n",
       "      <td>-0.177821</td>\n",
       "      <td>0.800357</td>\n",
       "      <td>0.158949</td>\n",
       "      <td>2.573438</td>\n",
       "      <td>1.615337</td>\n",
       "      <td>-0.998008</td>\n",
       "      <td>1.096824</td>\n",
       "      <td>-0.023870</td>\n",
       "      <td>-0.667530</td>\n",
       "      <td>-1.929526</td>\n",
       "      <td>...</td>\n",
       "      <td>0.955204</td>\n",
       "      <td>0.006918</td>\n",
       "      <td>0.715542</td>\n",
       "      <td>-0.870650</td>\n",
       "      <td>-0.205803</td>\n",
       "      <td>0.835786</td>\n",
       "      <td>1.692061</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201849</th>\n",
       "      <td>-0.306444</td>\n",
       "      <td>1.308680</td>\n",
       "      <td>1.067536</td>\n",
       "      <td>-0.931025</td>\n",
       "      <td>-1.046062</td>\n",
       "      <td>2.075529</td>\n",
       "      <td>-0.501223</td>\n",
       "      <td>-2.267342</td>\n",
       "      <td>0.095569</td>\n",
       "      <td>-0.845871</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086890</td>\n",
       "      <td>0.917567</td>\n",
       "      <td>0.631528</td>\n",
       "      <td>-2.004170</td>\n",
       "      <td>0.267849</td>\n",
       "      <td>1.151415</td>\n",
       "      <td>-1.051147</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201850</th>\n",
       "      <td>-0.151392</td>\n",
       "      <td>0.071449</td>\n",
       "      <td>0.356428</td>\n",
       "      <td>0.259774</td>\n",
       "      <td>-0.383608</td>\n",
       "      <td>1.065443</td>\n",
       "      <td>0.450759</td>\n",
       "      <td>0.322183</td>\n",
       "      <td>-1.307717</td>\n",
       "      <td>-0.181305</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.277678</td>\n",
       "      <td>0.032450</td>\n",
       "      <td>-0.329121</td>\n",
       "      <td>-0.322632</td>\n",
       "      <td>-1.898407</td>\n",
       "      <td>-0.602611</td>\n",
       "      <td>-0.267056</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201851</th>\n",
       "      <td>-0.793142</td>\n",
       "      <td>-0.539722</td>\n",
       "      <td>-1.165816</td>\n",
       "      <td>-0.199017</td>\n",
       "      <td>2.244849</td>\n",
       "      <td>0.917043</td>\n",
       "      <td>-0.467799</td>\n",
       "      <td>0.353362</td>\n",
       "      <td>1.053764</td>\n",
       "      <td>0.443968</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.308614</td>\n",
       "      <td>-1.632518</td>\n",
       "      <td>1.059085</td>\n",
       "      <td>1.047949</td>\n",
       "      <td>-2.762428</td>\n",
       "      <td>-0.955669</td>\n",
       "      <td>0.913588</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201852</th>\n",
       "      <td>-0.393870</td>\n",
       "      <td>1.455486</td>\n",
       "      <td>-0.128889</td>\n",
       "      <td>-0.788440</td>\n",
       "      <td>0.381879</td>\n",
       "      <td>0.022924</td>\n",
       "      <td>0.543938</td>\n",
       "      <td>-0.070586</td>\n",
       "      <td>-0.623824</td>\n",
       "      <td>-0.382842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008888</td>\n",
       "      <td>0.031512</td>\n",
       "      <td>2.580178</td>\n",
       "      <td>-0.813275</td>\n",
       "      <td>-0.418657</td>\n",
       "      <td>-0.572518</td>\n",
       "      <td>-0.936024</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows × 1027 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "201601  1.287487 -0.688955 -0.794426 -1.238838  1.239369  1.784700 -0.000341   \n",
       "201602 -1.399851 -0.211775  1.341302  0.132593 -0.097550  0.159015 -1.474547   \n",
       "201603 -0.405975  0.289439 -0.377020 -0.355364 -1.054876  0.712196  0.927682   \n",
       "201604  0.844463 -1.315463  2.082394  2.693551 -1.234441  1.570999  0.279815   \n",
       "201605 -0.541275  0.475828  0.136089  0.335247  1.387429  0.863202 -1.643587   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "201848 -0.177821  0.800357  0.158949  2.573438  1.615337 -0.998008  1.096824   \n",
       "201849 -0.306444  1.308680  1.067536 -0.931025 -1.046062  2.075529 -0.501223   \n",
       "201850 -0.151392  0.071449  0.356428  0.259774 -0.383608  1.065443  0.450759   \n",
       "201851 -0.793142 -0.539722 -1.165816 -0.199017  2.244849  0.917043 -0.467799   \n",
       "201852 -0.393870  1.455486 -0.128889 -0.788440  0.381879  0.022924  0.543938   \n",
       "\n",
       "               7         8         9  ...      1017      1018      1019  \\\n",
       "201601  0.525795  0.363034  0.825218  ... -0.439056  0.675143 -1.017167   \n",
       "201602 -1.294940  1.222341 -0.381582  ... -0.420181 -1.341189 -0.138499   \n",
       "201603 -0.470455 -0.252064  1.062808  ... -0.587504  0.340662  0.299123   \n",
       "201604  0.831815 -0.229177 -0.052932  ...  0.959280 -0.753616  1.713913   \n",
       "201605 -0.673929 -0.331307 -1.289601  ... -0.362812 -0.104197 -0.509349   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "201848 -0.023870 -0.667530 -1.929526  ...  0.955204  0.006918  0.715542   \n",
       "201849 -2.267342  0.095569 -0.845871  ... -0.086890  0.917567  0.631528   \n",
       "201850  0.322183 -1.307717 -0.181305  ... -0.277678  0.032450 -0.329121   \n",
       "201851  0.353362  1.053764  0.443968  ... -1.308614 -1.632518  1.059085   \n",
       "201852 -0.070586 -0.623824 -0.382842  ...  0.008888  0.031512  2.580178   \n",
       "\n",
       "            1020      1021      1022      1023  0  1  2  \n",
       "201601 -0.206480 -0.043412 -1.014832 -1.435265  1  0  0  \n",
       "201602 -1.804684 -0.662659  0.475712  0.201907  0  1  0  \n",
       "201603  0.405674 -2.638784  0.780803 -1.659373  0  0  1  \n",
       "201604  1.536158 -1.955070  0.051035 -1.663397  1  0  0  \n",
       "201605  0.104454 -3.172053  0.055130  0.444714  1  0  0  \n",
       "...          ...       ...       ...       ... .. .. ..  \n",
       "201848 -0.870650 -0.205803  0.835786  1.692061  1  0  0  \n",
       "201849 -2.004170  0.267849  1.151415 -1.051147  0  0  1  \n",
       "201850 -0.322632 -1.898407 -0.602611 -0.267056  0  1  0  \n",
       "201851  1.047949 -2.762428 -0.955669  0.913588  1  0  0  \n",
       "201852 -0.813275 -0.418657 -0.572518 -0.936024  1  0  0  \n",
       "\n",
       "[156 rows x 1027 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the two dataframes based on the date values\n",
    "dengue_df = features_df.merge(labels_df, how='inner', left_index=True, right_index=True)\n",
    "dengue_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c204d6",
   "metadata": {},
   "source": [
    "### Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a38ff71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, train_percentage = 80):\n",
    "    # We need a sequence so we can't split randomly\n",
    "    # To divide into Train and test we have to calculate the train percentage of the dataset:\n",
    "    size = df.shape[0]\n",
    "    split = int(size*(train_percentage/100))\n",
    "    \n",
    "    \"\"\" Train \"\"\"\n",
    "    # We will train with 1st percentage % of data and test with the rest\n",
    "    train_df = df.iloc[:split,:] ## percentage % train\n",
    "    \n",
    "    \"\"\" Test \"\"\"\n",
    "    test_df = df.iloc[split:,:] # 100 - percentage % test\n",
    "    \n",
    "    print(f'The train shape is: {train_df.shape}')\n",
    "    print(f'The test shape is: {test_df.shape}')\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1abce2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train shape is: (124, 1027)\n",
      "The test shape is: (32, 1027)\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(dengue_df, train_percentage = 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2146ce8",
   "metadata": {},
   "source": [
    "### Normalize features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91513c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize train data and create the scaler\n",
    "def normalize_train_features(df, feature_range=(-1, 1), n_labels=None):\n",
    "    \n",
    "    if n_labels:\n",
    "        n_features = df.shape[1] - n_labels\n",
    "    \n",
    "    scalers = {}\n",
    "    # For each column in the dataframe\n",
    "    for i, column in enumerate(df.columns):\n",
    "        if n_labels:\n",
    "            if i >= n_features:\n",
    "                break\n",
    "        # Get values of the column\n",
    "        values = df[column].values.reshape(-1,1)\n",
    "        # Generate a new scaler\n",
    "        scaler = MinMaxScaler(feature_range=feature_range)\n",
    "        # Fit the scaler just for that column\n",
    "        scaled_column = scaler.fit_transform(values)\n",
    "        # Add the scaled column to the dataframe\n",
    "        scaled_column = np.reshape(scaled_column, len(scaled_column))\n",
    "        df[column] = scaled_column\n",
    "        \n",
    "        # Save the scaler of the column\n",
    "        scalers['scaler_' + column] = scaler\n",
    "        \n",
    "    print(f' Min values are: ')\n",
    "    print(df.min())\n",
    "    print(f' Max values are: ')\n",
    "    print(df.max())\n",
    "        \n",
    "    return df, scalers\n",
    "\n",
    "\n",
    "\"\"\" If you want to use the same scaler used in train, you can use this function\"\"\"\n",
    "def normalize_test_features(df, scalers=None, n_labels=None):\n",
    "    \n",
    "    if not scalers:\n",
    "        raise TypeError(\"You should provide a list of scalers.\")\n",
    "    \n",
    "    if n_labels:\n",
    "        n_features = df.shape[1] - n_labels\n",
    "    \n",
    "    for i, column in enumerate(df.columns):\n",
    "        if n_labels:\n",
    "            if i >= n_features:\n",
    "                break\n",
    "        # Get values of the column\n",
    "        values = df[column].values.reshape(-1,1)\n",
    "        # Take the scaler of that column\n",
    "        scaler = scalers['scaler_' + column]\n",
    "        # Scale values\n",
    "        scaled_column = scaler.transform(values)\n",
    "        scaled_column = np.reshape(scaled_column,len(scaled_column))\n",
    "        # Add the scaled values to the df\n",
    "        df[column] = scaled_column\n",
    "        \n",
    "    print(f' Min values are: ')\n",
    "    print(df.min())\n",
    "    print(f' Max values are: ')\n",
    "    print(df.max())\n",
    "        \n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aed1529a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Min values are: \n",
      "0      -1.0\n",
      "1      -1.0\n",
      "2      -1.0\n",
      "3      -1.0\n",
      "4      -1.0\n",
      "       ... \n",
      "1022   -1.0\n",
      "1023   -1.0\n",
      "0       0.0\n",
      "1       0.0\n",
      "2       0.0\n",
      "Length: 1027, dtype: float64\n",
      " Max values are: \n",
      "0       1.0\n",
      "1       1.0\n",
      "2       1.0\n",
      "3       1.0\n",
      "4       1.0\n",
      "       ... \n",
      "1022    1.0\n",
      "1023    1.0\n",
      "0       1.0\n",
      "1       1.0\n",
      "2       1.0\n",
      "Length: 1027, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201601</th>\n",
       "      <td>0.717415</td>\n",
       "      <td>-0.264619</td>\n",
       "      <td>-0.512345</td>\n",
       "      <td>-0.596061</td>\n",
       "      <td>0.474445</td>\n",
       "      <td>0.534150</td>\n",
       "      <td>-0.046372</td>\n",
       "      <td>-0.033960</td>\n",
       "      <td>0.317819</td>\n",
       "      <td>0.237751</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.131012</td>\n",
       "      <td>0.127058</td>\n",
       "      <td>-0.319972</td>\n",
       "      <td>0.037591</td>\n",
       "      <td>0.106643</td>\n",
       "      <td>-0.352494</td>\n",
       "      <td>-0.615821</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201602</th>\n",
       "      <td>-0.419614</td>\n",
       "      <td>-0.077807</td>\n",
       "      <td>0.419405</td>\n",
       "      <td>-0.042335</td>\n",
       "      <td>0.008382</td>\n",
       "      <td>-0.073435</td>\n",
       "      <td>-0.675073</td>\n",
       "      <td>-0.723629</td>\n",
       "      <td>0.606674</td>\n",
       "      <td>-0.262004</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.122372</td>\n",
       "      <td>-0.760683</td>\n",
       "      <td>-0.018953</td>\n",
       "      <td>-0.522950</td>\n",
       "      <td>-0.092673</td>\n",
       "      <td>0.164985</td>\n",
       "      <td>0.116053</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201603</th>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.118415</td>\n",
       "      <td>-0.330244</td>\n",
       "      <td>-0.239351</td>\n",
       "      <td>-0.325351</td>\n",
       "      <td>0.133311</td>\n",
       "      <td>0.349401</td>\n",
       "      <td>-0.411326</td>\n",
       "      <td>0.111055</td>\n",
       "      <td>0.336141</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.198964</td>\n",
       "      <td>-0.020205</td>\n",
       "      <td>0.130970</td>\n",
       "      <td>0.252293</td>\n",
       "      <td>-0.728723</td>\n",
       "      <td>0.270905</td>\n",
       "      <td>-0.716005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201604</th>\n",
       "      <td>0.529969</td>\n",
       "      <td>-0.509892</td>\n",
       "      <td>0.742719</td>\n",
       "      <td>0.991672</td>\n",
       "      <td>-0.387949</td>\n",
       "      <td>0.454282</td>\n",
       "      <td>0.073106</td>\n",
       "      <td>0.081956</td>\n",
       "      <td>0.118748</td>\n",
       "      <td>-0.125905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509073</td>\n",
       "      <td>-0.501989</td>\n",
       "      <td>0.615657</td>\n",
       "      <td>0.648789</td>\n",
       "      <td>-0.508657</td>\n",
       "      <td>0.017548</td>\n",
       "      <td>-0.717804</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201605</th>\n",
       "      <td>-0.056345</td>\n",
       "      <td>0.191385</td>\n",
       "      <td>-0.106391</td>\n",
       "      <td>0.039488</td>\n",
       "      <td>0.526060</td>\n",
       "      <td>0.189748</td>\n",
       "      <td>-0.747163</td>\n",
       "      <td>-0.488399</td>\n",
       "      <td>0.084417</td>\n",
       "      <td>-0.638029</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096112</td>\n",
       "      <td>-0.216066</td>\n",
       "      <td>-0.146001</td>\n",
       "      <td>0.146645</td>\n",
       "      <td>-0.900364</td>\n",
       "      <td>0.018970</td>\n",
       "      <td>0.224596</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1027 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "201601  0.717415 -0.264619 -0.512345 -0.596061  0.474445  0.534150 -0.046372   \n",
       "201602 -0.419614 -0.077807  0.419405 -0.042335  0.008382 -0.073435 -0.675073   \n",
       "201603  0.000901  0.118415 -0.330244 -0.239351 -0.325351  0.133311  0.349401   \n",
       "201604  0.529969 -0.509892  0.742719  0.991672 -0.387949  0.454282  0.073106   \n",
       "201605 -0.056345  0.191385 -0.106391  0.039488  0.526060  0.189748 -0.747163   \n",
       "\n",
       "               7         8         9  ...      1017      1018      1019  \\\n",
       "201601 -0.033960  0.317819  0.237751  ... -0.131012  0.127058 -0.319972   \n",
       "201602 -0.723629  0.606674 -0.262004  ... -0.122372 -0.760683 -0.018953   \n",
       "201603 -0.411326  0.111055  0.336141  ... -0.198964 -0.020205  0.130970   \n",
       "201604  0.081956  0.118748 -0.125905  ...  0.509073 -0.501989  0.615657   \n",
       "201605 -0.488399  0.084417 -0.638029  ... -0.096112 -0.216066 -0.146001   \n",
       "\n",
       "            1020      1021      1022      1023  0  1  2  \n",
       "201601  0.037591  0.106643 -0.352494 -0.615821  1  0  0  \n",
       "201602 -0.522950 -0.092673  0.164985  0.116053  0  1  0  \n",
       "201603  0.252293 -0.728723  0.270905 -0.716005  0  0  1  \n",
       "201604  0.648789 -0.508657  0.017548 -0.717804  1  0  0  \n",
       "201605  0.146645 -0.900364  0.018970  0.224596  1  0  0  \n",
       "\n",
       "[5 rows x 1027 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_range = (-1, 1)\n",
    "\n",
    "# Scale train:\n",
    "train_df, scalers = normalize_train_features(train_df, feature_range=feature_range, n_labels=n_labels)\n",
    "\n",
    "#print(f'The scalers are: {scalers}')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccfcb1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Min values are: \n",
      "0      -0.611774\n",
      "1      -0.698647\n",
      "2      -1.492308\n",
      "3      -0.577689\n",
      "4      -0.528444\n",
      "          ...   \n",
      "1022   -0.468700\n",
      "1023   -1.009303\n",
      "0       0.000000\n",
      "1       0.000000\n",
      "2       0.000000\n",
      "Length: 1027, dtype: float64\n",
      " Max values are: \n",
      "0       0.798543\n",
      "1       0.992657\n",
      "2       0.376680\n",
      "3       0.943176\n",
      "4       0.824965\n",
      "          ...   \n",
      "1022    0.451219\n",
      "1023    0.782204\n",
      "0       1.000000\n",
      "1       1.000000\n",
      "2       1.000000\n",
      "Length: 1027, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>201821</th>\n",
       "      <td>0.084599</td>\n",
       "      <td>0.542881</td>\n",
       "      <td>-0.384070</td>\n",
       "      <td>-0.080906</td>\n",
       "      <td>0.138302</td>\n",
       "      <td>0.078038</td>\n",
       "      <td>-0.007716</td>\n",
       "      <td>-0.031384</td>\n",
       "      <td>-0.545694</td>\n",
       "      <td>-0.072470</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.699482</td>\n",
       "      <td>0.136318</td>\n",
       "      <td>0.328906</td>\n",
       "      <td>0.342614</td>\n",
       "      <td>0.063277</td>\n",
       "      <td>0.219823</td>\n",
       "      <td>0.294464</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201822</th>\n",
       "      <td>0.798543</td>\n",
       "      <td>0.992657</td>\n",
       "      <td>-0.493325</td>\n",
       "      <td>-0.416277</td>\n",
       "      <td>0.266510</td>\n",
       "      <td>-0.591903</td>\n",
       "      <td>0.565659</td>\n",
       "      <td>-0.179126</td>\n",
       "      <td>0.237211</td>\n",
       "      <td>0.382436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201944</td>\n",
       "      <td>-0.673409</td>\n",
       "      <td>-0.036940</td>\n",
       "      <td>-0.021246</td>\n",
       "      <td>0.060466</td>\n",
       "      <td>0.102064</td>\n",
       "      <td>0.112100</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201823</th>\n",
       "      <td>0.247549</td>\n",
       "      <td>-0.247999</td>\n",
       "      <td>0.253891</td>\n",
       "      <td>0.300498</td>\n",
       "      <td>0.187533</td>\n",
       "      <td>-0.202666</td>\n",
       "      <td>-0.067352</td>\n",
       "      <td>-0.504047</td>\n",
       "      <td>0.361369</td>\n",
       "      <td>0.378615</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.290135</td>\n",
       "      <td>0.185387</td>\n",
       "      <td>0.484507</td>\n",
       "      <td>-0.645408</td>\n",
       "      <td>-0.595917</td>\n",
       "      <td>-0.186724</td>\n",
       "      <td>-0.197858</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201824</th>\n",
       "      <td>0.420624</td>\n",
       "      <td>0.373608</td>\n",
       "      <td>-0.799224</td>\n",
       "      <td>0.511320</td>\n",
       "      <td>-0.279726</td>\n",
       "      <td>-0.603021</td>\n",
       "      <td>0.154349</td>\n",
       "      <td>-0.543294</td>\n",
       "      <td>0.365547</td>\n",
       "      <td>0.051451</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053085</td>\n",
       "      <td>-0.549938</td>\n",
       "      <td>0.159301</td>\n",
       "      <td>0.492040</td>\n",
       "      <td>-0.004100</td>\n",
       "      <td>0.447210</td>\n",
       "      <td>-0.103205</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201825</th>\n",
       "      <td>0.155971</td>\n",
       "      <td>-0.698647</td>\n",
       "      <td>0.350023</td>\n",
       "      <td>-0.577689</td>\n",
       "      <td>0.674053</td>\n",
       "      <td>-0.199004</td>\n",
       "      <td>0.069916</td>\n",
       "      <td>-0.071021</td>\n",
       "      <td>0.025623</td>\n",
       "      <td>-0.410628</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.164270</td>\n",
       "      <td>0.157324</td>\n",
       "      <td>-0.432406</td>\n",
       "      <td>0.355685</td>\n",
       "      <td>0.165775</td>\n",
       "      <td>0.352219</td>\n",
       "      <td>0.450566</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1027 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4         5         6  \\\n",
       "201821  0.084599  0.542881 -0.384070 -0.080906  0.138302  0.078038 -0.007716   \n",
       "201822  0.798543  0.992657 -0.493325 -0.416277  0.266510 -0.591903  0.565659   \n",
       "201823  0.247549 -0.247999  0.253891  0.300498  0.187533 -0.202666 -0.067352   \n",
       "201824  0.420624  0.373608 -0.799224  0.511320 -0.279726 -0.603021  0.154349   \n",
       "201825  0.155971 -0.698647  0.350023 -0.577689  0.674053 -0.199004  0.069916   \n",
       "\n",
       "               7         8         9  ...      1017      1018      1019  \\\n",
       "201821 -0.031384 -0.545694 -0.072470  ... -0.699482  0.136318  0.328906   \n",
       "201822 -0.179126  0.237211  0.382436  ...  0.201944 -0.673409 -0.036940   \n",
       "201823 -0.504047  0.361369  0.378615  ... -0.290135  0.185387  0.484507   \n",
       "201824 -0.543294  0.365547  0.051451  ... -0.053085 -0.549938  0.159301   \n",
       "201825 -0.071021  0.025623 -0.410628  ... -0.164270  0.157324 -0.432406   \n",
       "\n",
       "            1020      1021      1022      1023  0  1  2  \n",
       "201821  0.342614  0.063277  0.219823  0.294464  1  0  0  \n",
       "201822 -0.021246  0.060466  0.102064  0.112100  1  0  0  \n",
       "201823 -0.645408 -0.595917 -0.186724 -0.197858  1  0  0  \n",
       "201824  0.492040 -0.004100  0.447210 -0.103205  1  0  0  \n",
       "201825  0.355685  0.165775  0.352219  0.450566  1  0  0  \n",
       "\n",
       "[5 rows x 1027 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale test:\n",
    "test_df = normalize_test_features(test_df, scalers=scalers, n_labels=n_labels)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6eabb8",
   "metadata": {},
   "source": [
    "### Features and Labels Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bdfa8216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_labels_set(timeseries_data, original_df, n_labels):\n",
    "    \n",
    "    \"\"\" Features \"\"\"\n",
    "    # We define the number of features as (features and labels)\n",
    "    n_features = original_df.shape[1]\n",
    "\n",
    "    # The features to train the model will be all except the values of the actual week \n",
    "    # We can't use other variables in week t because whe need to resample a a 3D Array\n",
    "    features_set = DataFrame(timeseries_data.values[:,:-n_labels])\n",
    "    # Convert pandas data frame to np.array to reshape as 3D Array\n",
    "    features_set = features_set.to_numpy()\n",
    "    print(f'The shape of the features is {features_set.shape}')\n",
    "    \n",
    "    \"\"\" Labels \"\"\"\n",
    "    # We will use labels in last week \n",
    "    labels_set = DataFrame(timeseries_data.values[:,-n_labels:])\n",
    "    # Convert pandas data frame to np.array\n",
    "    labels_set = labels_set.to_numpy()\n",
    "    print(f'The shape of the labels is {labels_set.shape}')\n",
    "    \n",
    "    return features_set, labels_set, n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ae98520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "The shape of the features is (124, 1024)\n",
      "The shape of the labels is (124, 3)\n",
      "Test:\n",
      "The shape of the features is (32, 1024)\n",
      "The shape of the labels is (32, 3)\n"
     ]
    }
   ],
   "source": [
    "# Train features and labels set\n",
    "print('Train:')\n",
    "train_X, train_y, n_features = features_labels_set(timeseries_data=train_df, original_df=dengue_df, n_labels=n_labels)\n",
    "\n",
    "# Test features and labels set\n",
    "print('Test:')\n",
    "test_X, test_y, n_features = features_labels_set(timeseries_data=test_df, original_df=dengue_df, n_labels=n_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e96360",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d67939",
   "metadata": {},
   "source": [
    "# Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b25c4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Seed\n",
    "#tf.random.set_seed(0)\n",
    "\n",
    "def create_model():\n",
    "    \n",
    "    # design network\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Choose an optimal value between 32-512\n",
    "    #hp_units = hp.Int('units', min_value=512, max_value=1024, step=64)\n",
    "    model.add(Dense(units=1024))\n",
    "    \n",
    "    # Choose an optimal value between 32-512\n",
    "    #hp_units_2 = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "    model.add(Dense(units=512))\n",
    "    \n",
    "    # Out\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    # Compile the model:\n",
    "    \n",
    "    # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "    #hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    opt = keras.optimizers.Adam()\n",
    "    metric = tf.keras.metrics.AUC(name='auc', multi_label=True, num_labels=3)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=metric)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1b390b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_model():\n",
    "    tuner = keras_tuner.RandomSearch(\n",
    "        create_model,\n",
    "        objective='val_loss',\n",
    "        max_trials=15\n",
    "    )\n",
    "    \n",
    "    tuner.search(\n",
    "        train_X,\n",
    "        train_y,\n",
    "        epochs=1,\n",
    "        batch_size=16,\n",
    "        validation_data=(test_X, test_y)\n",
    "    )\n",
    "\n",
    "    return tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be26815",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33ac8e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# EarlyStopping:\n",
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=20, \n",
    "        verbose=1, mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "316c8e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zeros: 113, ones: 20, twos: 23, total: 156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 1.3805309734513274, 1: 7.8, 2: 6.782608695652174}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Imbalanced data\n",
    "n_zeros = (labels_df_orig.to_numpy() == 0).sum()\n",
    "n_ones = (labels_df_orig.to_numpy() == 1).sum()\n",
    "n_twos = (labels_df_orig.to_numpy() == 2).sum()\n",
    "n_total = n_zeros + n_ones + n_twos\n",
    "\n",
    "weights = {0: n_total/n_zeros, 1: n_total/n_ones, 2: n_total/n_twos}\n",
    "print(f'zeros: {n_zeros}, ones: {n_ones}, twos: {n_twos}, total: {n_total}')\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1221d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit network\n",
    "def train_model(model, monitor, weights, plot=None, epochs=100):\n",
    "    if monitor and weights:\n",
    "        history = model.fit(train_X, train_y, epochs=epochs, batch_size=16, validation_data=(test_X, test_y), verbose=2, shuffle=False, callbacks=[monitor], class_weight=weights)\n",
    "    elif monitor:\n",
    "        history = model.fit(train_X, train_y, epochs=epochs, batch_size=16, validation_data=(test_X, test_y), verbose=2, shuffle=False, callbacks=[monitor])\n",
    "    elif weights:\n",
    "        history = model.fit(train_X, train_y, epochs=epochs, batch_size=16, validation_data=(test_X, test_y), verbose=2, shuffle=False, class_weight=weights)\n",
    "    else:\n",
    "        history = model.fit(train_X, train_y, epochs=epochs, batch_size=16, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "    \n",
    "    if plot:\n",
    "        # plot history\n",
    "        plt.plot(history.history['loss'], label='train')\n",
    "        plt.plot(history.history['val_loss'], label='validation')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497c2ee0",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c516e824",
   "metadata": {},
   "source": [
    "# AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eed6a438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also evaluate or predict on a dataset.\n",
    "def evaluate(model, verbose = None):\n",
    "    if verbose:\n",
    "        print('Evaluate: ')\n",
    "    result = model.evaluate(test_X, test_y)\n",
    "    if verbose:\n",
    "        for i, metric in enumerate(model.metrics_names):\n",
    "            print(f'{metric}: {result[i]}')\n",
    "\n",
    "    auc = result[1]\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1818604a",
   "metadata": {},
   "source": [
    "# Calculate Mean and SD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b1a7cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mean_std(weights):\n",
    "    aucs = []\n",
    "    for i in range(5):\n",
    "        model = create_model()\n",
    "        train_model(model=model, monitor=monitor, weights=weights)\n",
    "        auc = evaluate(model=model)\n",
    "        aucs.append(auc)\n",
    "\n",
    "    mean = np.array(aucs).mean()\n",
    "    std = np.array(aucs).std()\n",
    "    print(f'The mean AUC is {mean} and SD is {std}')\n",
    "    \n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06b0b1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 1s - loss: 1.1869 - auc: 0.6672 - val_loss: 0.8876 - val_auc: 0.5910\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 0.1549 - auc: 0.9903 - val_loss: 1.2254 - val_auc: 0.5431\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.0017 - auc: 1.0000 - val_loss: 1.2852 - val_auc: 0.3897\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.0015 - auc: 1.0000 - val_loss: 1.4636 - val_auc: 0.3829\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.0030 - auc: 1.0000 - val_loss: 1.5338 - val_auc: 0.3940\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 1.9801e-04 - auc: 1.0000 - val_loss: 1.5692 - val_auc: 0.3940\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.0543e-04 - auc: 1.0000 - val_loss: 1.5866 - val_auc: 0.3940\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 7.7773e-05 - auc: 1.0000 - val_loss: 1.5950 - val_auc: 0.3940\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 6.4202e-05 - auc: 1.0000 - val_loss: 1.5992 - val_auc: 0.3940\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 5.5864e-05 - auc: 1.0000 - val_loss: 1.6014 - val_auc: 0.3940\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 5.0087e-05 - auc: 1.0000 - val_loss: 1.6026 - val_auc: 0.3940\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 4.5765e-05 - auc: 1.0000 - val_loss: 1.6035 - val_auc: 0.3940\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 4.2334e-05 - auc: 1.0000 - val_loss: 1.6042 - val_auc: 0.3940\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 3.9503e-05 - auc: 1.0000 - val_loss: 1.6049 - val_auc: 0.3940\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 3.7088e-05 - auc: 1.0000 - val_loss: 1.6055 - val_auc: 0.3940\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 3.4982e-05 - auc: 1.0000 - val_loss: 1.6061 - val_auc: 0.3940\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 3.3116e-05 - auc: 1.0000 - val_loss: 1.6066 - val_auc: 0.3940\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 3.1446e-05 - auc: 1.0000 - val_loss: 1.6072 - val_auc: 0.3940\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 2.9939e-05 - auc: 1.0000 - val_loss: 1.6078 - val_auc: 0.3940\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 2.8567e-05 - auc: 1.0000 - val_loss: 1.6084 - val_auc: 0.3940\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 2.7304e-05 - auc: 1.0000 - val_loss: 1.6089 - val_auc: 0.3940\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00021: early stopping\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.8876 - auc: 0.5910\n",
      "Epoch 1/100\n",
      "8/8 - 1s - loss: 1.1849 - auc: 0.5905 - val_loss: 0.8814 - val_auc: 0.4965\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 0.0695 - auc: 1.0000 - val_loss: 1.0640 - val_auc: 0.6945\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.0095 - auc: 1.0000 - val_loss: 1.3606 - val_auc: 0.6562\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 5.1029e-04 - auc: 1.0000 - val_loss: 1.3880 - val_auc: 0.6761\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 5.7974e-04 - auc: 1.0000 - val_loss: 1.4206 - val_auc: 0.5134\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 2.5270e-04 - auc: 1.0000 - val_loss: 1.4459 - val_auc: 0.5226\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.4062e-04 - auc: 1.0000 - val_loss: 1.4614 - val_auc: 0.4476\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 9.9571e-05 - auc: 1.0000 - val_loss: 1.4702 - val_auc: 0.4476\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 7.9566e-05 - auc: 1.0000 - val_loss: 1.4752 - val_auc: 0.4476\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 6.7808e-05 - auc: 1.0000 - val_loss: 1.4782 - val_auc: 0.4476\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 6.0019e-05 - auc: 1.0000 - val_loss: 1.4802 - val_auc: 0.4476\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 5.4378e-05 - auc: 1.0000 - val_loss: 1.4818 - val_auc: 0.4476\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 4.9988e-05 - auc: 1.0000 - val_loss: 1.4831 - val_auc: 0.4476\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 4.6408e-05 - auc: 1.0000 - val_loss: 1.4844 - val_auc: 0.4476\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 4.3366e-05 - auc: 1.0000 - val_loss: 1.4855 - val_auc: 0.4476\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 4.0721e-05 - auc: 1.0000 - val_loss: 1.4867 - val_auc: 0.4476\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 3.8379e-05 - auc: 1.0000 - val_loss: 1.4878 - val_auc: 0.4476\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 3.6293e-05 - auc: 1.0000 - val_loss: 1.4889 - val_auc: 0.4476\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 3.4401e-05 - auc: 1.0000 - val_loss: 1.4900 - val_auc: 0.4476\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 3.2684e-05 - auc: 1.0000 - val_loss: 1.4911 - val_auc: 0.4476\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 3.1116e-05 - auc: 1.0000 - val_loss: 1.4922 - val_auc: 0.4476\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00021: early stopping\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.8814 - auc: 0.4965\n",
      "Epoch 1/100\n",
      "8/8 - 1s - loss: 1.1354 - auc: 0.6613 - val_loss: 0.6387 - val_auc: 0.7886\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 0.1765 - auc: 0.9930 - val_loss: 0.7751 - val_auc: 0.6784\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.0036 - auc: 1.0000 - val_loss: 1.0494 - val_auc: 0.5032\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 9.6502e-04 - auc: 1.0000 - val_loss: 1.1979 - val_auc: 0.4950\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.0013 - auc: 1.0000 - val_loss: 1.2777 - val_auc: 0.3495\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 5.3264e-04 - auc: 1.0000 - val_loss: 1.3161 - val_auc: 0.3495\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 2.6908e-04 - auc: 1.0000 - val_loss: 1.3340 - val_auc: 0.3606\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.7125e-04 - auc: 1.0000 - val_loss: 1.3422 - val_auc: 0.3606\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.2660e-04 - auc: 1.0000 - val_loss: 1.3460 - val_auc: 0.3606\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.0241e-04 - auc: 1.0000 - val_loss: 1.3479 - val_auc: 0.3606\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 8.7478e-05 - auc: 1.0000 - val_loss: 1.3490 - val_auc: 0.3606\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 7.7256e-05 - auc: 1.0000 - val_loss: 1.3498 - val_auc: 0.3606\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 6.9670e-05 - auc: 1.0000 - val_loss: 1.3504 - val_auc: 0.3606\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 6.3705e-05 - auc: 1.0000 - val_loss: 1.3510 - val_auc: 0.3606\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 5.8802e-05 - auc: 1.0000 - val_loss: 1.3517 - val_auc: 0.3606\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 5.4643e-05 - auc: 1.0000 - val_loss: 1.3523 - val_auc: 0.3606\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 5.1049e-05 - auc: 1.0000 - val_loss: 1.3530 - val_auc: 0.3606\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 4.7893e-05 - auc: 1.0000 - val_loss: 1.3537 - val_auc: 0.3606\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 4.5096e-05 - auc: 1.0000 - val_loss: 1.3544 - val_auc: 0.3606\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 4.2589e-05 - auc: 1.0000 - val_loss: 1.3551 - val_auc: 0.3606\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 4.0321e-05 - auc: 1.0000 - val_loss: 1.3558 - val_auc: 0.3606\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00021: early stopping\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.6387 - auc: 0.7886\n",
      "Epoch 1/100\n",
      "8/8 - 1s - loss: 1.2506 - auc: 0.5570 - val_loss: 0.7521 - val_auc: 0.5496\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 0.1094 - auc: 1.0000 - val_loss: 0.9793 - val_auc: 0.5108\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.0067 - auc: 1.0000 - val_loss: 1.3846 - val_auc: 0.3954\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.0017 - auc: 1.0000 - val_loss: 1.3532 - val_auc: 0.4076\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 3.2293e-04 - auc: 1.0000 - val_loss: 1.3193 - val_auc: 0.4333\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 2.5359e-04 - auc: 1.0000 - val_loss: 1.3085 - val_auc: 0.4517\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 1.4718e-04 - auc: 1.0000 - val_loss: 1.3065 - val_auc: 0.4517\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.0605e-04 - auc: 1.0000 - val_loss: 1.3071 - val_auc: 0.4517\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 8.5986e-05 - auc: 1.0000 - val_loss: 1.3085 - val_auc: 0.4517\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 7.3346e-05 - auc: 1.0000 - val_loss: 1.3098 - val_auc: 0.4517\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 6.4497e-05 - auc: 1.0000 - val_loss: 1.3109 - val_auc: 0.4555\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 5.7911e-05 - auc: 1.0000 - val_loss: 1.3118 - val_auc: 0.4555\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 5.2773e-05 - auc: 1.0000 - val_loss: 1.3125 - val_auc: 0.4555\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 4.8601e-05 - auc: 1.0000 - val_loss: 1.3131 - val_auc: 0.4555\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 4.5111e-05 - auc: 1.0000 - val_loss: 1.3136 - val_auc: 0.4555\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 4.2131e-05 - auc: 1.0000 - val_loss: 1.3140 - val_auc: 0.4555\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 3.9533e-05 - auc: 1.0000 - val_loss: 1.3143 - val_auc: 0.4555\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 3.7243e-05 - auc: 1.0000 - val_loss: 1.3147 - val_auc: 0.4555\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 3.5201e-05 - auc: 1.0000 - val_loss: 1.3150 - val_auc: 0.4621\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 3.3369e-05 - auc: 1.0000 - val_loss: 1.3154 - val_auc: 0.4621\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 3.1711e-05 - auc: 1.0000 - val_loss: 1.3157 - val_auc: 0.4621\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00021: early stopping\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.7521 - auc: 0.5496\n",
      "Epoch 1/100\n",
      "8/8 - 1s - loss: 1.1854 - auc: 0.6424 - val_loss: 0.7597 - val_auc: 0.5645\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 0.2610 - auc: 0.9671 - val_loss: 1.0340 - val_auc: 0.5506\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.0011 - auc: 1.0000 - val_loss: 1.0152 - val_auc: 0.4438\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.0407 - auc: 1.0000 - val_loss: 1.0802 - val_auc: 0.5042\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.0081 - auc: 1.0000 - val_loss: 1.1661 - val_auc: 0.5228\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 3.5264e-04 - auc: 1.0000 - val_loss: 1.1989 - val_auc: 0.5256\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 3.0890e-04 - auc: 1.0000 - val_loss: 1.2141 - val_auc: 0.5309\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 1.9956e-04 - auc: 1.0000 - val_loss: 1.2207 - val_auc: 0.5309\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 1.3761e-04 - auc: 1.0000 - val_loss: 1.2238 - val_auc: 0.5309\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 1.0532e-04 - auc: 1.0000 - val_loss: 1.2257 - val_auc: 0.5309\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 8.6463e-05 - auc: 1.0000 - val_loss: 1.2271 - val_auc: 0.5309\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 7.4218e-05 - auc: 1.0000 - val_loss: 1.2283 - val_auc: 0.5309\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 6.5576e-05 - auc: 1.0000 - val_loss: 1.2292 - val_auc: 0.5309\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 5.9067e-05 - auc: 1.0000 - val_loss: 1.2301 - val_auc: 0.5309\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 5.3901e-05 - auc: 1.0000 - val_loss: 1.2309 - val_auc: 0.5309\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 4.9646e-05 - auc: 1.0000 - val_loss: 1.2316 - val_auc: 0.5309\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 4.6034e-05 - auc: 1.0000 - val_loss: 1.2323 - val_auc: 0.5309\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 4.2919e-05 - auc: 1.0000 - val_loss: 1.2329 - val_auc: 0.5309\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 4.0180e-05 - auc: 1.0000 - val_loss: 1.2335 - val_auc: 0.5309\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 3.7762e-05 - auc: 1.0000 - val_loss: 1.2341 - val_auc: 0.5309\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 3.5592e-05 - auc: 1.0000 - val_loss: 1.2346 - val_auc: 0.5309\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00021: early stopping\n",
      "1/1 [==============================] - 0s 176ms/step - loss: 0.7597 - auc: 0.5645\n",
      "The mean AUC is 0.5980336129665375 and SD is 0.10016262780498196\n"
     ]
    }
   ],
   "source": [
    "mean, std = calculate_mean_std(weights=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4f52049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 - 1s - loss: 5.3985 - auc: 0.6200 - val_loss: 0.3345 - val_auc: 0.8614\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.8528 - auc: 0.9437 - val_loss: 2.0999 - val_auc: 0.6886\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.3687 - auc: 1.0000 - val_loss: 1.5644 - val_auc: 0.6201\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.0050 - auc: 1.0000 - val_loss: 1.1342 - val_auc: 0.4658\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.0345 - auc: 1.0000 - val_loss: 1.2011 - val_auc: 0.5271\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 0.0016 - auc: 1.0000 - val_loss: 1.2398 - val_auc: 0.5224\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 0.0025 - auc: 1.0000 - val_loss: 1.2659 - val_auc: 0.5158\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 0.0010 - auc: 1.0000 - val_loss: 1.2812 - val_auc: 0.5158\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 4.9165e-04 - auc: 1.0000 - val_loss: 1.2896 - val_auc: 0.5158\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 3.1009e-04 - auc: 1.0000 - val_loss: 1.2944 - val_auc: 0.5158\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 2.3551e-04 - auc: 1.0000 - val_loss: 1.2974 - val_auc: 0.5158\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.9754e-04 - auc: 1.0000 - val_loss: 1.2993 - val_auc: 0.5158\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.7448e-04 - auc: 1.0000 - val_loss: 1.3008 - val_auc: 0.5158\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.5850e-04 - auc: 1.0000 - val_loss: 1.3020 - val_auc: 0.5158\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.4628e-04 - auc: 1.0000 - val_loss: 1.3031 - val_auc: 0.5158\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.3641e-04 - auc: 1.0000 - val_loss: 1.3041 - val_auc: 0.5158\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.2805e-04 - auc: 1.0000 - val_loss: 1.3050 - val_auc: 0.5158\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.2079e-04 - auc: 1.0000 - val_loss: 1.3060 - val_auc: 0.5158\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.1440e-04 - auc: 1.0000 - val_loss: 1.3068 - val_auc: 0.5158\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.0869e-04 - auc: 1.0000 - val_loss: 1.3077 - val_auc: 0.5158\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.0353e-04 - auc: 1.0000 - val_loss: 1.3086 - val_auc: 0.5158\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00021: early stopping\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.3345 - auc: 0.8614\n",
      "Epoch 1/100\n",
      "8/8 - 1s - loss: 6.2315 - auc: 0.5049 - val_loss: 0.4727 - val_auc: 0.6925\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.6246 - auc: 0.9781 - val_loss: 1.7644 - val_auc: 0.4651\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.7515 - auc: 0.9928 - val_loss: 2.1924 - val_auc: 0.3992\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.0154 - auc: 1.0000 - val_loss: 1.1703 - val_auc: 0.4667\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.0231 - auc: 1.0000 - val_loss: 1.1232 - val_auc: 0.5078\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 0.0172 - auc: 1.0000 - val_loss: 1.1403 - val_auc: 0.5040\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 7.6614e-04 - auc: 1.0000 - val_loss: 1.1566 - val_auc: 0.4948\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 3.6958e-04 - auc: 1.0000 - val_loss: 1.1657 - val_auc: 0.4894\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 2.7779e-04 - auc: 1.0000 - val_loss: 1.1705 - val_auc: 0.4894\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 2.3307e-04 - auc: 1.0000 - val_loss: 1.1730 - val_auc: 0.4894\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 2.0351e-04 - auc: 1.0000 - val_loss: 1.1744 - val_auc: 0.4894\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 1.8222e-04 - auc: 1.0000 - val_loss: 1.1754 - val_auc: 0.4894\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 1.6620e-04 - auc: 1.0000 - val_loss: 1.1761 - val_auc: 0.4894\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 1.5373e-04 - auc: 1.0000 - val_loss: 1.1767 - val_auc: 0.4894\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 1.4370e-04 - auc: 1.0000 - val_loss: 1.1772 - val_auc: 0.4894\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 1.3530e-04 - auc: 1.0000 - val_loss: 1.1778 - val_auc: 0.4894\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.2817e-04 - auc: 1.0000 - val_loss: 1.1783 - val_auc: 0.4894\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.2195e-04 - auc: 1.0000 - val_loss: 1.1789 - val_auc: 0.4894\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.1643e-04 - auc: 1.0000 - val_loss: 1.1794 - val_auc: 0.4894\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.1149e-04 - auc: 1.0000 - val_loss: 1.1800 - val_auc: 0.4894\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.0698e-04 - auc: 1.0000 - val_loss: 1.1806 - val_auc: 0.4894\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00021: early stopping\n",
      "1/1 [==============================] - 0s 178ms/step - loss: 0.4727 - auc: 0.6925\n",
      "Epoch 1/100\n",
      "8/8 - 1s - loss: 6.3558 - auc: 0.4966 - val_loss: 0.3727 - val_auc: 0.7568\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.3481 - auc: 0.9803 - val_loss: 1.3364 - val_auc: 0.6637\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.5656 - auc: 0.9957 - val_loss: 1.4237 - val_auc: 0.5415\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.0052 - auc: 1.0000 - val_loss: 1.0369 - val_auc: 0.5657\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.0430 - auc: 1.0000 - val_loss: 1.0915 - val_auc: 0.5754\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 8.7281e-04 - auc: 1.0000 - val_loss: 1.1483 - val_auc: 0.5679\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 6.9120e-04 - auc: 1.0000 - val_loss: 1.1821 - val_auc: 0.5659\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 5.9937e-04 - auc: 1.0000 - val_loss: 1.1994 - val_auc: 0.5631\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 5.1847e-04 - auc: 1.0000 - val_loss: 1.2071 - val_auc: 0.5573\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 4.4105e-04 - auc: 1.0000 - val_loss: 1.2100 - val_auc: 0.5518\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 3.7571e-04 - auc: 1.0000 - val_loss: 1.2109 - val_auc: 0.5537\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 3.2416e-04 - auc: 1.0000 - val_loss: 1.2108 - val_auc: 0.5667\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 2.8415e-04 - auc: 1.0000 - val_loss: 1.2105 - val_auc: 0.5725\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 2.5288e-04 - auc: 1.0000 - val_loss: 1.2101 - val_auc: 0.5725\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 2.2797e-04 - auc: 1.0000 - val_loss: 1.2098 - val_auc: 0.5620\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 2.0769e-04 - auc: 1.0000 - val_loss: 1.2096 - val_auc: 0.5714\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.9087e-04 - auc: 1.0000 - val_loss: 1.2094 - val_auc: 0.5744\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.7667e-04 - auc: 1.0000 - val_loss: 1.2093 - val_auc: 0.5772\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.6454e-04 - auc: 1.0000 - val_loss: 1.2093 - val_auc: 0.5752\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.5397e-04 - auc: 1.0000 - val_loss: 1.2093 - val_auc: 0.5752\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.4476e-04 - auc: 1.0000 - val_loss: 1.2094 - val_auc: 0.5733\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00021: early stopping\n",
      "1/1 [==============================] - 0s 182ms/step - loss: 0.3727 - auc: 0.7568\n",
      "Epoch 1/100\n",
      "8/8 - 1s - loss: 6.5821 - auc: 0.5269 - val_loss: 0.5348 - val_auc: 0.6082\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 1.8513 - auc: 0.9645 - val_loss: 1.8290 - val_auc: 0.5933\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.7203 - auc: 0.9962 - val_loss: 2.1296 - val_auc: 0.5705\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.0274 - auc: 1.0000 - val_loss: 1.1024 - val_auc: 0.4539\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.1415 - auc: 1.0000 - val_loss: 1.0774 - val_auc: 0.4609\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 0.0031 - auc: 1.0000 - val_loss: 1.1554 - val_auc: 0.4402\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 0.0021 - auc: 1.0000 - val_loss: 1.2320 - val_auc: 0.4364\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 0.0015 - auc: 1.0000 - val_loss: 1.2761 - val_auc: 0.4244\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 9.5160e-04 - auc: 1.0000 - val_loss: 1.2965 - val_auc: 0.4244\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 7.0891e-04 - auc: 1.0000 - val_loss: 1.3050 - val_auc: 0.4244\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 5.8464e-04 - auc: 1.0000 - val_loss: 1.3081 - val_auc: 0.4244\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 5.0644e-04 - auc: 1.0000 - val_loss: 1.3087 - val_auc: 0.4244\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 4.5091e-04 - auc: 1.0000 - val_loss: 1.3083 - val_auc: 0.4244\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 4.0842e-04 - auc: 1.0000 - val_loss: 1.3074 - val_auc: 0.4244\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 3.7425e-04 - auc: 1.0000 - val_loss: 1.3065 - val_auc: 0.4244\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 3.4584e-04 - auc: 1.0000 - val_loss: 1.3055 - val_auc: 0.4244\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 3.2160e-04 - auc: 1.0000 - val_loss: 1.3045 - val_auc: 0.4310\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 3.0055e-04 - auc: 1.0000 - val_loss: 1.3036 - val_auc: 0.4310\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 2.8202e-04 - auc: 1.0000 - val_loss: 1.3027 - val_auc: 0.4310\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 2.6553e-04 - auc: 1.0000 - val_loss: 1.3019 - val_auc: 0.4310\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 2.5077e-04 - auc: 1.0000 - val_loss: 1.3011 - val_auc: 0.4310\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00021: early stopping\n",
      "1/1 [==============================] - 0s 177ms/step - loss: 0.5348 - auc: 0.6082\n",
      "Epoch 1/100\n",
      "8/8 - 1s - loss: 6.8581 - auc: 0.5024 - val_loss: 0.5186 - val_auc: 0.5693\n",
      "Epoch 2/100\n",
      "8/8 - 0s - loss: 2.6676 - auc: 0.9488 - val_loss: 1.5059 - val_auc: 0.4614\n",
      "Epoch 3/100\n",
      "8/8 - 0s - loss: 0.6996 - auc: 0.9889 - val_loss: 2.2600 - val_auc: 0.3963\n",
      "Epoch 4/100\n",
      "8/8 - 0s - loss: 0.0258 - auc: 1.0000 - val_loss: 1.3184 - val_auc: 0.2784\n",
      "Epoch 5/100\n",
      "8/8 - 0s - loss: 0.0156 - auc: 1.0000 - val_loss: 1.2553 - val_auc: 0.2867\n",
      "Epoch 6/100\n",
      "8/8 - 0s - loss: 7.6950e-04 - auc: 1.0000 - val_loss: 1.2558 - val_auc: 0.3089\n",
      "Epoch 7/100\n",
      "8/8 - 0s - loss: 7.3608e-04 - auc: 1.0000 - val_loss: 1.2630 - val_auc: 0.3201\n",
      "Epoch 8/100\n",
      "8/8 - 0s - loss: 6.5038e-04 - auc: 1.0000 - val_loss: 1.2694 - val_auc: 0.3201\n",
      "Epoch 9/100\n",
      "8/8 - 0s - loss: 5.0125e-04 - auc: 1.0000 - val_loss: 1.2741 - val_auc: 0.3201\n",
      "Epoch 10/100\n",
      "8/8 - 0s - loss: 3.9037e-04 - auc: 1.0000 - val_loss: 1.2775 - val_auc: 0.3201\n",
      "Epoch 11/100\n",
      "8/8 - 0s - loss: 3.2361e-04 - auc: 1.0000 - val_loss: 1.2800 - val_auc: 0.3201\n",
      "Epoch 12/100\n",
      "8/8 - 0s - loss: 2.8221e-04 - auc: 1.0000 - val_loss: 1.2820 - val_auc: 0.3201\n",
      "Epoch 13/100\n",
      "8/8 - 0s - loss: 2.5421e-04 - auc: 1.0000 - val_loss: 1.2837 - val_auc: 0.3201\n",
      "Epoch 14/100\n",
      "8/8 - 0s - loss: 2.3354e-04 - auc: 1.0000 - val_loss: 1.2851 - val_auc: 0.3201\n",
      "Epoch 15/100\n",
      "8/8 - 0s - loss: 2.1724e-04 - auc: 1.0000 - val_loss: 1.2865 - val_auc: 0.3201\n",
      "Epoch 16/100\n",
      "8/8 - 0s - loss: 2.0379e-04 - auc: 1.0000 - val_loss: 1.2877 - val_auc: 0.3201\n",
      "Epoch 17/100\n",
      "8/8 - 0s - loss: 1.9226e-04 - auc: 1.0000 - val_loss: 1.2888 - val_auc: 0.3201\n",
      "Epoch 18/100\n",
      "8/8 - 0s - loss: 1.8220e-04 - auc: 1.0000 - val_loss: 1.2899 - val_auc: 0.3201\n",
      "Epoch 19/100\n",
      "8/8 - 0s - loss: 1.7326e-04 - auc: 1.0000 - val_loss: 1.2909 - val_auc: 0.3201\n",
      "Epoch 20/100\n",
      "8/8 - 0s - loss: 1.6524e-04 - auc: 1.0000 - val_loss: 1.2918 - val_auc: 0.3201\n",
      "Epoch 21/100\n",
      "8/8 - 0s - loss: 1.5796e-04 - auc: 1.0000 - val_loss: 1.2928 - val_auc: 0.3201\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00021: early stopping\n",
      "1/1 [==============================] - 0s 175ms/step - loss: 0.5186 - auc: 0.5693\n",
      "The mean AUC is 0.6976442456245422 and SD is 0.10468816692911735\n"
     ]
    }
   ],
   "source": [
    "mean_2, std_2 = calculate_mean_std(weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ee6fe4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:generalml_p37_gpu_v1]",
   "language": "python",
   "name": "conda-env-generalml_p37_gpu_v1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
